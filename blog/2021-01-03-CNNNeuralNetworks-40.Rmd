---
title: "Convolutional Neural Networks"
author: Laxmi K Soni 
description: "Convolutional Neural Networks"
slug: Convolutional Neural Networks
date: 2021-01-03
lastmod: 2021-01-03
categories: ["Convolutional Neural Networks"]
tags: ["Convolutional Neural Networks"]
Summary: "Convolutional Neural Networks"
subtitle: Convolutional Neural Networks
featured: "img/main/cnn-neural-network.jpg"
output:
  html_document:
    highlight: tango
    theme: flatly
    toc: yes
    toc_float: yes
    toc_depth: 4
---

# Convolutional Neural Networks

#### What are Convolutional Neural Networks:

One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks 
works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present. 
CNN algorithms requires to be trained with tons of images and their possible predictor class. CNN are powerful tools for processing data having grid like topology.
CNN involves convolution which means cross-corelation operations (instead of a fully connected layer) as one of its layers. 


These neural networks are successful in many different real-life case studies and applications like:

- Image classification, Object detection, segmentation, face recognition
- Self driving cars that leverage CNN based vision systems
- Classificationof crystal structure using a convolutional neural network


![](/img/main/cnn.png)

<mark>Convolution is the key principle applied:</mark> in convolutional neural network architecture. 
Convolution is a way to identify patterns in data that is directly tied to space or time. Assume we have a one dimentional array of numbers
say Input = [a,b,c,d,e,f,g] and another set of numbers say K = [p,q]. Then convolution involves sliding the lower size list over the higher size list and then
multiplying corresponding values and adding them therefore after convoluting K over Input we get [a*p+b*q, b*p+c*q, c*p+d*q, d*p+e*q, f*p+g*q]. The result identifies 
one of the feature of the Input. The result is known as the convolution of the Input and in practice only non-zero values are choosen for feature selection.
If the input is a grid structure or in matrix form (in case of images) then the kernal is also choosen as the matrix of lower dimension and in this 
case matrix multiplication is perfomed to get the resultant convolution of the input image.

<mark>Computer see images as matrices</mark>:Grayscale images have single channel (gray). 
So, we can represent grayscale images in the form of 2D matrix, where each element represents the intensity of brightness in that particular pixel, 
where 0 means black and 255 means white. Color images have 3 channels RGB (red, green, blue).  
Color images can be  represented as a 3D matrix with the depth of 3.

<mark>For example:</mark> Shape of a matrix representing a 480px by 852px color image will be (480, 852, 3)
Each pixel of the color image has three numbers (ranging from 0 to 255) associated with it. 
These numbers shows the intensity of red, green and blue color in that particular pixel.

```{python}
import os
import cv2
import matplotlib.pyplot as plt # (optional) for plotting and showing images inline
IMAGES_FOLDER = os.path.join('../../static/img/main') # images for visuals
earth_fname = os.path.join(IMAGES_FOLDER,'earth.jpg')
earth_img1 = cv2.imread(earth_fname)
print(earth_img1.shape)
```

<mark>In CIFAR 10 dataset the Input layer</mark> consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. 

![](/img/main/cifar10dataset.png)


#### In a covnolutional neural network:

<mark>Input layer:</mark> Takes an image as input and preserves its spatial structure
<mark>Convolution layer:</mark>	extracts feature maps from the input, each responding to a specific pattern
<mark>ReLU layer:</mark> Introduces non-linearities in the network by setting negative pixels to 0

```{python, eval = FALSE}
from keras.models import Sequential
from keras.layers import Conv2D
model = Sequential()
model.add(Conv2D(filters=16, kernel_size = 3, padding = 'same',activation = 'relu',input_shape=(32,32,3)))
```

The first layer takes input as set of images specified with input_shape. <mark>filters, kernal size, strides and padding </mark> are the most important
parameters to keras Cov2D. The parameter filters denote the number of filters. The task of a filter is to detect a feature in the image.
For example if we have 16 filters then computing a dot product between their weights and a small region they are connected to in the input image. 
This may result in volume such as [32x32x16] if we use 16 filters. Convolutional Neural network learns about the image from the filters. Commonly CNN learns from 32 to 512 filters in parallel for a given input.




<mark>Max-pooling layer:</mark>	Down-samples the rectified feature maps, thus reducing the spatial dimensionality and retaining important features. This prevents overfitting

<mark>Fully-Connected layer:</mark>	Learns non-linear combinations of the features and performs the classification task
 

model.add(Conv2D(32, (3, 3), activation="relu"))




