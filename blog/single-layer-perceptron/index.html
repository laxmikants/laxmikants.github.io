<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Single Layer Perceptron - Data Science Posts and Resources :: Laxmikant Soni</title>

<meta name="viewport" content="width=device-width" />

<meta name="google-site-verification" content="MeRcFEBEyWiTb3NfY4THWxbV_fx3rKOJnvr_Jk398wY" />

<meta name=keywords content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics | Laxmikant Soni, Predictive Analytics, Business, Data, Analytics, Machine Learning, Mining, Python, Intelligence, Big, Modeling, Data Science, Integration, Visualization,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow,Javascript,ReactJS,NodeJS,Posts and Resources on Data Science,Data Science,Hadoop,Java,Spring,Hibernate,Struts,MySQL,Oracle,DB2,Websphere,Weblogic">

<meta name=description content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics :: Laxmikant Soni">

<meta name="robots" content="index">


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>




<meta name="generator" content="Hugo 0.80.0" /><meta itemprop="name" content="Single Layer Perceptron">
<meta itemprop="description" content="A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs.">
<meta itemprop="datePublished" content="2020-12-10T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-12-10T00:00:00+00:00" />
<meta itemprop="wordCount" content="801">



<meta itemprop="keywords" content="Single Layer Perceptron," />
<meta property="og:title" content="Single Layer Perceptron" />
<meta property="og:description" content="A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/single-layer-perceptron/" />
<meta property="article:published_time" content="2020-12-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-10T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Single Layer Perceptron"/>
<meta name="twitter:description" content="A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs."/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.aa4e8165f5b2a16460fcb21582ad412bed8e48e9c5dc49f3b412d1703be4d75d.css" integrity="sha256-qk6BZfWyoWRg/LIVgq1BK&#43;2OSOnF3EnztBLRcDvk110="><link rel="stylesheet" href="/css/add-on.css">
        <link rel="stylesheet" href="/css/main.css">

<title>Single Layer Perceptron : Data Science Posts and Resources</title>

<meta property="og:title" content="Single Layer Perceptron">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/single-layer-perceptron/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs.">
<meta name="description" content="A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs.">
<meta property="og:updated_time" content="2020-12-10T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">

<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2020-12-10T00:00:00Z">
<meta property="article:modified_time" content="2020-12-10T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Single Layer Perceptron",
  "alternativeHeadline": "Single Layer Perceptron",
  "name" : "Data Science Posts and Resources",
  "url": "https://laxmikants.github.io/blog/single-layer-perceptron/",
  "image": "https://laxmikants.github.io/",
  "sameAs":
      [ "https://www.facebook.com/laxmikantsoni09",
        "https://instagram.com/laxmikantsoni09",
        "https://www.linkedin.com/in/laxmikantsoni09",
        "https://twitter.com/laxmikantsoni09",
        "https://github.com/laxmikants",
        "https://www.kaggle.com/laxmikantsoni"
    ],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/single-layer-perceptron/"
  },
  "description": "A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs.",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2020-12-10T00:00:00Z",
  "dateModified": "2020-12-10T00:00:00Z",
  "articleBody": "\r\n\u003cscript src=\"/rmarkdown-libs/header-attrs/header-attrs.js\"\u003e\u003c/script\u003e\r\n\u003clink href=\"/rmarkdown-libs/anchor-sections/anchor-sections.css\" rel=\"stylesheet\" /\u003e\r\n\u003cscript src=\"/rmarkdown-libs/anchor-sections/anchor-sections.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\u003cdiv id=\"single-layer-perceptron\" class=\"section level1\"\u003e\r\n\u003ch1\u003eSingle Layer Perceptron\u003c/h1\u003e\r\n\u003cdiv id=\"what-is-single-layer-perceptron\" class=\"section level4\"\u003e\r\n\u003ch4\u003eWhat is Single Layer Perceptron:\u003c/h4\u003e\r\n\u003cp\u003eA Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input\r\ncan be a vector for example input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The\r\nnode in the next layer takes the weighted sum of all its inputs.\u003c/p\u003e\r\n\u003cp\u003efor example input x = ( I1, I2, I3) = ( 5, 3.2, 0.1 )\u003c/p\u003e\r\n\u003cp\u003e\u003cspan class=\"math display\"\u003e\\[Summedinput = 5 w_1 + 3.2 w_2 + 0.1w_3 \\]\u003c/span\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/perceptronex.jpg\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThe output node having a threshold t. If summed input ≥ threshold, then it outputs y = 1 else it output y = 0.\u003c/p\u003e\r\n\u003cp\u003eThe single layer perceptron does not have a previous knowledge, therefore the initial weights are assign randomly.\r\nSLP adds all of the weighted inputs and if the addition is above the threshold (any predetermined value), SLP is known to be in the activated state i.e output=1.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/Perceptron_3.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThe perceptron receives the input values and does calculations to find the predicted output. If the predicted output is the same as that of the expected output, then the performance is considered satisfactory and no changes to the weights are made. But, if the predicted output does not match the expected output, then the weights need to be adjusted to reduce the error.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/weight_adjestment_perceptron.png\" /\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"the-algorithm-is\" class=\"section level4\"\u003e\r\n\u003ch4\u003eThe algorithm is\u003c/h4\u003e\r\n\u003cp\u003e• Initially, assigning all the weights to some random values\u003c/p\u003e\r\n\u003cp\u003e• Repeating (for many epochs):\u003c/p\u003e\r\n\u003col style=\"list-style-type: lower-alpha\"\u003e\r\n\u003cli\u003e\u003cp\u003eFeed the network with an input from one of the examples in the training set\u003c/p\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eCompute the error between the output of the network and the desired output\u003c/p\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eCorrect the error by adjusting the weights of the nodes\u003c/p\u003e\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e• Until the error is very small\u003c/p\u003e\r\n\u003cp\u003e]\u003c/p\u003e\r\n\u003cp\u003eA single layer percepron is simplest form of network to solve a problem with step or linear activation functions.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"single-layer-perceptron-for-xnor-problem-in-r\" class=\"section level4\"\u003e\r\n\u003ch4\u003eSingle Layer Perceptron for XNOR problem in R\u003c/h4\u003e\r\n\u003cpre class=\"r\"\u003e\u003ccode\u003elibrary(neuralnet)\r\nXOR \u0026lt;- c(0,1,1,0)\r\nxor.data \u0026lt;- data.frame(expand.grid(c(0,1), c(0,1)), XOR)\r\nprint(xor.data)\r\nprint(net.xor \u0026lt;- neuralnet(XOR~Var1+Var2, xor.data, hidden=0, rep=5))\r\nplot(net.xor, rep=\u0026quot;best\u0026quot;)\r\nround(predict(net.xor, data.frame(xor.data)))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/Perceptron_R_XOR.png\" /\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"implementing-single-layer-perceptron-for-xnor-problem-in-python\" class=\"section level4\"\u003e\r\n\u003ch4\u003eImplementing Single Layer Perceptron for XNOR problem in Python\u003c/h4\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport numpy as np\r\nfrom keras.models import Sequential\r\nfrom keras.layers.core import Dense\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe import numpy and alias it as np\u003c/p\u003e\r\n\u003cp\u003eKeras offers two different APIs to construct a model: a functional and a sequential one. We’re using the sequential API hence the second import of Sequential from keras.models.\u003c/p\u003e\r\n\u003cp\u003eNeural networks consist of different layers where input data flows through and gets transformed on its way. There are a bunch of different layer types available in Keras. These different types of layer help us to model individual kinds of neural nets for various machine learning tasks. In our specific case the Dense layer is what we want.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e# the four different states of the XOR gate\r\ntraining_data = np.array([[0,0],[0,1],[1,0],[1,1]], \u0026quot;float32\u0026quot;)\r\n\r\n# the four expected results in the same order\r\ntarget_data = np.array([[0],[1],[1],[0]], \u0026quot;float32\u0026quot;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe initialize training_data as a two-dimensional array (an array of arrays) where each of the inner arrays has exactly two items.\u003c/p\u003e\r\n\u003cp\u003eWe setup target_data as another two-dimensional array. All the inner arrays in target_data contain just a single item though. Each inner array of training_data relates to its counterpart in target_data.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel = Sequential()\r\nmodel.add(Dense(1, input_dim=2, activation=\u0026#39;sigmoid\u0026#39;))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eSets up an empty model using the Sequential API. Add a Dense layer to our model in which We set input_dim=2 because each of our input samples is an array of length 2 ([0, 1], [1, 0] etc.). 1 stand the dimension of the output for this layer. Our model means that we have two input neurons (input_dim=2) spreading into 1 neuron in output layer without any hidden layer as we are trying to mimic a single layer perceptron.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel.compile(loss=\u0026#39;mean_squared_error\u0026#39;,\r\n              optimizer=\u0026#39;adam\u0026#39;,\r\n              metrics=[\u0026#39;binary_accuracy\u0026#39;])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e]\u003c/p\u003e\r\n\u003cp\u003eWith neural nets we always want to calculate a number (loss) that tells us how bad our model performs and then try to get that number lower.\r\nMean_squared_error works as our loss function simply because it’s a well proven loss function. Then adam optimizer is usded to find the right adjustments for the weights. Last parameter metrics is the binary_accuracy which gives us access to a number that tells us exactly how accurate our predictions are.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel.fit(training_data, target_data, nb_epoch=500, verbose=2)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe kick off the training by calling model.fit(…) which require first two params, which are training and target data, the third one is the number of epochs (learning iterations), the last one tells keras how much info to print out during the training.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eprint(model.predict(training_data).round())\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eUsing model.predict we can do predictions.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"summary\" class=\"section level4\"\u003e\r\n\u003ch4\u003eSummary:\u003c/h4\u003e\r\n\u003cp\u003eMcCulloch-Pitts neurons networks are computational devices, which are capable of performing any logical function. Single-Layer Perceptrons\r\nwith step activation functions are constrained in what they can do. Adding additional hidden layers to the network will make it more powerful such that even non-linear relations can be predicted using such a neural network.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  
</head>
  <body>
    
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5KFS4C"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
      
    


<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
        
          
          <a href="/contact/" class="nav link"><i class='far fa-envelope'></i> Contact</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
 
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  
  
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu">
  </div></menu>
  
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Single%20Layer%20Perceptron&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f&amp;title=Single%20Layer%20Perceptron" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </menu>
  
</header>

      
    <div id="wrapper">
    
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    <p>Articles on Data Science</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>



      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/single-layer-perceptron/">Single Layer Perceptron</a></h2>
    
    
      <p>A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input  can be a vector for example  input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The node in the next layer takes the weighted sum of all its inputs.</p>
    
  </div>
  <div class="meta">
    <time datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
    <p>Laxmi K Soni</p>
    <p>4-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Single%20Layer%20Perceptron&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsingle-layer-perceptron%2f&amp;title=Single%20Layer%20Perceptron" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </div>
  
    <div class="content">
      <a href="/blog/single-layer-perceptron/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg');">
    <img src="https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg" alt="">
  </a>
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="single-layer-perceptron" class="section level1">
<h1>Single Layer Perceptron</h1>
<div id="what-is-single-layer-perceptron" class="section level4">
<h4>What is Single Layer Perceptron:</h4>
<p>A Single layer perceptron is a type of neuron having multiple inputs and one output. Input has many dimensions i.e input
can be a vector for example input x = ( I1, I2, .., In). Input nodes are connected to a node in the next layer. The
node in the next layer takes the weighted sum of all its inputs.</p>
<p>for example input x = ( I1, I2, I3) = ( 5, 3.2, 0.1 )</p>
<p><span class="math display">\[Summedinput = 5 w_1 + 3.2 w_2 + 0.1w_3 \]</span></p>
<p><img src="/img/main/perceptronex.jpg" /></p>
<p>The output node having a threshold t. If summed input ≥ threshold, then it outputs y = 1 else it output y = 0.</p>
<p>The single layer perceptron does not have a previous knowledge, therefore the initial weights are assign randomly.
SLP adds all of the weighted inputs and if the addition is above the threshold (any predetermined value), SLP is known to be in the activated state i.e output=1.</p>
<p><img src="/img/main/Perceptron_3.png" /></p>
<p>The perceptron receives the input values and does calculations to find the predicted output. If the predicted output is the same as that of the expected output, then the performance is considered satisfactory and no changes to the weights are made. But, if the predicted output does not match the expected output, then the weights need to be adjusted to reduce the error.</p>
<p><img src="/img/main/weight_adjestment_perceptron.png" /></p>
</div>
<div id="the-algorithm-is" class="section level4">
<h4>The algorithm is</h4>
<p>• Initially, assigning all the weights to some random values</p>
<p>• Repeating (for many epochs):</p>
<ol style="list-style-type: lower-alpha">
<li><p>Feed the network with an input from one of the examples in the training set</p></li>
<li><p>Compute the error between the output of the network and the desired output</p></li>
<li><p>Correct the error by adjusting the weights of the nodes</p></li>
</ol>
<p>• Until the error is very small</p>
<p>]</p>
<p>A single layer percepron is simplest form of network to solve a problem with step or linear activation functions.</p>
</div>
<div id="single-layer-perceptron-for-xnor-problem-in-r" class="section level4">
<h4>Single Layer Perceptron for XNOR problem in R</h4>
<pre class="r"><code>library(neuralnet)
XOR &lt;- c(0,1,1,0)
xor.data &lt;- data.frame(expand.grid(c(0,1), c(0,1)), XOR)
print(xor.data)
print(net.xor &lt;- neuralnet(XOR~Var1+Var2, xor.data, hidden=0, rep=5))
plot(net.xor, rep=&quot;best&quot;)
round(predict(net.xor, data.frame(xor.data)))</code></pre>
<p><img src="/img/main/Perceptron_R_XOR.png" /></p>
</div>
<div id="implementing-single-layer-perceptron-for-xnor-problem-in-python" class="section level4">
<h4>Implementing Single Layer Perceptron for XNOR problem in Python</h4>
<pre class="python"><code>import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense</code></pre>
<p>We import numpy and alias it as np</p>
<p>Keras offers two different APIs to construct a model: a functional and a sequential one. We’re using the sequential API hence the second import of Sequential from keras.models.</p>
<p>Neural networks consist of different layers where input data flows through and gets transformed on its way. There are a bunch of different layer types available in Keras. These different types of layer help us to model individual kinds of neural nets for various machine learning tasks. In our specific case the Dense layer is what we want.</p>
<pre class="python"><code># the four different states of the XOR gate
training_data = np.array([[0,0],[0,1],[1,0],[1,1]], &quot;float32&quot;)

# the four expected results in the same order
target_data = np.array([[0],[1],[1],[0]], &quot;float32&quot;)</code></pre>
<p>We initialize training_data as a two-dimensional array (an array of arrays) where each of the inner arrays has exactly two items.</p>
<p>We setup target_data as another two-dimensional array. All the inner arrays in target_data contain just a single item though. Each inner array of training_data relates to its counterpart in target_data.</p>
<pre class="python"><code>model = Sequential()
model.add(Dense(1, input_dim=2, activation=&#39;sigmoid&#39;))</code></pre>
<p>Sets up an empty model using the Sequential API. Add a Dense layer to our model in which We set input_dim=2 because each of our input samples is an array of length 2 ([0, 1], [1, 0] etc.). 1 stand the dimension of the output for this layer. Our model means that we have two input neurons (input_dim=2) spreading into 1 neuron in output layer without any hidden layer as we are trying to mimic a single layer perceptron.</p>
<pre class="python"><code>model.compile(loss=&#39;mean_squared_error&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;binary_accuracy&#39;])</code></pre>
<p>]</p>
<p>With neural nets we always want to calculate a number (loss) that tells us how bad our model performs and then try to get that number lower.
Mean_squared_error works as our loss function simply because it’s a well proven loss function. Then adam optimizer is usded to find the right adjustments for the weights. Last parameter metrics is the binary_accuracy which gives us access to a number that tells us exactly how accurate our predictions are.</p>
<pre class="python"><code>model.fit(training_data, target_data, nb_epoch=500, verbose=2)</code></pre>
<p>We kick off the training by calling model.fit(…) which require first two params, which are training and target data, the third one is the number of epochs (learning iterations), the last one tells keras how much info to print out during the training.</p>
<pre class="python"><code>print(model.predict(training_data).round())</code></pre>
<p>Using model.predict we can do predictions.</p>
</div>
<div id="summary" class="section level4">
<h4>Summary:</h4>
<p>McCulloch-Pitts neurons networks are computational devices, which are capable of performing any logical function. Single-Layer Perceptrons
with step activation functions are constrained in what they can do. Adding additional hidden layers to the network will make it more powerful such that even non-linear relations can be predicted using such a neural network.</p>
</div>
</div>

      <div align = "center">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        
        <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-3804322353139756"
         data-ad-slot="3387213493"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
        <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
        </script>
    </div>            
    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/single-layer-perceptron/">Single Layer Perceptron</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/single-layer-perceptron/">Single Layer Perceptron</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    

  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="2ef4e9882c2df46b70b7745b49eb03f3">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/neural-network-using-make-moons-dataset/" class="button left"><span>Neural Network using Make Moons dataset</span></a>
    
    
      <a href="/blog/neural-networks/" class="button right"><span>Neural Networks</span></a>
    
  </div>
  

      </main>
      
<section id="site-sidebar">

  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-29 00:00:00 &#43;0000 UTC">January 29, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/neural-network-using-make-moons-dataset/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg');">
    <img src="https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/neural-network-using-make-moons-dataset/">Neural Network using Make Moons dataset</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/single-layer-perceptron/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg');">
    <img src="https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/single-layer-perceptron/">Single Layer Perceptron</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      

      
    </section>
  

  <div align="center">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      
    <ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3804322353139756"
     data-ad-slot="3115024406"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
    <script>
        $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
    </script>
  </div>
  
  
    
      <section id="categories">
        
   
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/convolutional-neural-networks/">convolutional-neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
        <div align="center">
          <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
          
            <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-3804322353139756"
             data-ad-slot="5736252654"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
          <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
          </script>             
        </div>             
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>about</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    © 2021 Data Science Posts and Resources
      <br>
  </p>
</footer>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.daca826145adfcf5004b4b16d74010eff217a0382fad56b874f5630927a20c4e.js" integrity="sha256-2sqCYUWt/PUAS0sW10AQ7/IXoDgvrVa4dPVjCSeiDE4="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
  
</html>
