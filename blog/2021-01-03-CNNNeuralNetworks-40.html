---
title: "Convolutional Neural Networks"
author: Laxmi K Soni 
description: "Convolutional Neural Networks"
slug: Convolutional Neural Networks
date: 2021-01-03
lastmod: 2021-01-03
categories: ["Convolutional Neural Networks"]
tags: ["Convolutional Neural Networks"]
Summary: "Convolutional Neural Networks"
subtitle: Convolutional Neural Networks
featured: "img/main/cnn-neural-network.jpg"
output:
  html_document:
    highlight: tango
    theme: flatly
    toc: yes
    toc_float: yes
    toc_depth: 4
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="convolutional-neural-networks" class="section level1">
<h1>Convolutional Neural Networks</h1>
<div id="what-are-convolutional-neural-networks" class="section level4">
<h4>What are Convolutional Neural Networks:</h4>
<p>One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks
works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.
CNN algorithms requires to be trained with tons of images and their possible predictor class. CNN are powerful tools for processing data having grid like topology.
CNN involves convolution which means cross-corelation operations (instead of a fully connected layer) as one of its layers.</p>
<p>These neural networks are successful in many different real-life case studies and applications like:</p>
<ul>
<li>Image classification, Object detection, segmentation, face recognition</li>
<li>Self driving cars that leverage CNN based vision systems</li>
<li>Classificationof crystal structure using a convolutional neural network</li>
</ul>
<p><img src="/img/main/cnn.png" /></p>
<p><mark>Convolution is the key principle applied:</mark> in convolutional neural network architecture.
Convolution is a way to identify patterns in data that is directly tied to space or time. Assume we have a one dimentional array of numbers
say Input = [a,b,c,d,e,f,g] and another set of numbers say K = [p,q]. Then convolution involves sliding the lower size list over the higher size list and then multiplying corresponding values and adding them therefore after convoluting K over Input we get [a<em>p+b</em>q, b<em>p+c</em>q, c<em>p+d</em>q, d<em>p+e</em>q, f<em>p+g</em>q]. The result identifies one of the feature of the Input. The result is known as the convolution of the Input and in practice only non-zero values are choosen for feature selection.If the input is a grid structure or in matrix form (in case of images) then the kernal is also choosen as the matrix of lower dimension and in this case matrix multiplication is perfomed to get the resultant convolution of the input image.</p>
<p><mark>Computer see images as matrices</mark>:Grayscale images have single channel (gray).
So, we can represent grayscale images in the form of 2D matrix, where each element represents the intensity of brightness in that particular pixel,
where 0 means black and 255 means white. Color images have 3 channels RGB (red, green, blue).<br />
Color images can be represented as a 3D matrix with the depth of 3.</p>
<p><mark>For example:</mark> Shape of a matrix representing a 480px by 852px color image will be (480, 852, 3)
Each pixel of the color image has three numbers (ranging from 0 to 255) associated with it.
These numbers shows the intensity of red, green and blue color in that particular pixel.</p>
<pre class="python"><code>import os
import cv2
import matplotlib.pyplot as plt # (optional) for plotting and showing images inline
IMAGES_FOLDER = os.path.join(&#39;../../static/img/main&#39;) # images for visuals
earth_fname = os.path.join(IMAGES_FOLDER,&#39;earth.jpg&#39;)
earth_img1 = cv2.imread(earth_fname)
print(earth_img1.shape)</code></pre>
<pre><code>## (480, 852, 3)</code></pre>
<p><mark>The CIFAR 10 dataset has the Input layer</mark> of 60000 32x32 colour images in 10 categories, with 6000 images per class.</p>
<p><img src="/img/main/cifar10dataset.png" /></p>
</div>
<div id="in-a-covnolutional-neural-network" class="section level4">
<h4>In a covnolutional neural network:</h4>
<p><mark>Input layer:</mark> Takes an image as input and preserves its spatial structure
<mark>Convolution layer:</mark> extracts feature maps from the input, each responding to a specific pattern
<mark>ReLU layer:</mark> Introduces non-linearities in the network by putting the negative pixels to 0.</p>
<p><mark>Kernel, stride and padding</mark></p>
<p><img src="/img/main/convolution_schematic.gif" /></p>
<p>Filters also known as kernals, convolve square blocks of pixels into scalars in subsequent convolutional layers. In the animation above, we have a 3 x 3 filter with ones running on the diagonal and off-diagonal, scanning an image from left to right, top to bottom.</p>
<p>Throughout the process, the filter performs element-wise multiplication and sums up all products, into a single value passed to the subsequent convolutional layer. Note that the filter is moving a pixel at a time. This is the stride, the stepsize of the sliding window the filter uses to convolve. Larger size of strides indicates more granular and smaller convolved features.</p>
<p><mark>Example Convolution layer in Python</mark></p>
<p>The first layer takes input as set of images specified with input_shape. <mark>filters, kernal size, strides and padding </mark> are the most important
parameters to keras Cov2D. The parameter filters denote the number of filters. The task of a filter is to detect a feature in the image.</p>
<script src="https://gist.github.com/laxmikants/d7b849d1a9d926bc2cbc06f9f2090521.js?slice=0:1"></script>
<pre><code>## Using TensorFlow backend.
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])</code></pre>
<pre><code>## Model: &quot;sequential_1&quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       
## =================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## _________________________________________________________________</code></pre>
<p><mark>Example Convolution layer in R</mark></p>
<pre class="r"><code>library(tensorflow)
library(keras)
model &lt;- keras_model_sequential()
model%&gt;% 
  layer_conv_2d(filters = 16, kernel_size = c(3,3),activation = &#39;relu&#39;,input_shape = c(32,32,3))
summary(model)</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## conv2d (Conv2D)                     (None, 30, 30, 16)              448         
## ================================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<p><mark>pooling layer:</mark> Down-samples the rectified feature maps, thus reducing the spatial dimensionality and retaining important features.
This prevents overfitting.</p>
<p><mark>Example max pooling layer in R</mark></p>
<pre class="r"><code>model %&gt;% 
  layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%
  layer_dropout(0.25)
summary(model)</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## conv2d (Conv2D)                     (None, 30, 30, 16)              448         
## ________________________________________________________________________________
## max_pooling2d (MaxPooling2D)        (None, 15, 15, 16)              0           
## ________________________________________________________________________________
## dropout (Dropout)                   (None, 15, 15, 16)              0           
## ================================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<p><mark>Example max pooling layer in Python</mark></p>
<pre class="python"><code>from keras.layers import MaxPooling2D
from keras.layers import Dropout
model.add(MaxPooling2D(pool_size=(2, 2)))</code></pre>
<pre><code>## WARNING:tensorflow:From C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\keras\backend\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.</code></pre>
<pre class="python"><code>model.add(Dropout(0.25))
model.summary()</code></pre>
<pre><code>## Model: &quot;sequential_1&quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       
## _________________________________________________________________
## max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         
## _________________________________________________________________
## dropout_1 (Dropout)          (None, 16, 16, 16)        0         
## =================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## _________________________________________________________________</code></pre>
<p><mark>Fully-Connected layer:</mark> Learns non-linear combinations of the features and performs the classification task</p>
<p><mark>Flattening</mark>Flattening converts last convolutional layer into a one-dimensional NN layer.</p>
</div>
</div>
