<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Convolutional Neural Networks - Data Science Posts and Resources :: Laxmikant Soni</title>

<meta name="viewport" content="width=device-width" />

<meta name="google-site-verification" content="MeRcFEBEyWiTb3NfY4THWxbV_fx3rKOJnvr_Jk398wY" />

<meta name=keywords content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics | Laxmikant Soni, Predictive Analytics, Business, Data, Analytics, Machine Learning, Mining, Python, Intelligence, Big, Modeling, Data Science, Integration, Visualization,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow,Javascript,ReactJS,NodeJS,Posts and Resources on Data Science,Data Science,Hadoop,Java,Spring,Hibernate,Struts,MySQL,Oracle,DB2,Websphere,Weblogic">

<meta name=description content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics :: Laxmikant Soni">

<meta name="robots" content="index">


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>




<meta name="generator" content="Hugo 0.80.0" /><meta itemprop="name" content="Convolutional Neural Networks">
<meta itemprop="description" content="One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.">
<meta itemprop="datePublished" content="2021-01-29T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-01-29T00:00:00+00:00" />
<meta itemprop="wordCount" content="2472">



<meta itemprop="keywords" content="Convolutional Neural Networks," />
<meta property="og:title" content="Convolutional Neural Networks" />
<meta property="og:description" content="One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/convolutional-neural-networks/" />
<meta property="article:published_time" content="2021-01-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-01-29T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Convolutional Neural Networks"/>
<meta name="twitter:description" content="One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present."/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.aa4e8165f5b2a16460fcb21582ad412bed8e48e9c5dc49f3b412d1703be4d75d.css" integrity="sha256-qk6BZfWyoWRg/LIVgq1BK&#43;2OSOnF3EnztBLRcDvk110="><link rel="stylesheet" href="/css/add-on.css">
        <link rel="stylesheet" href="/css/main.css">

<title>Convolutional Neural Networks : Data Science Posts and Resources</title>

<meta property="og:title" content="Convolutional Neural Networks">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/convolutional-neural-networks/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.">
<meta name="description" content="One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.">
<meta property="og:updated_time" content="2021-01-29T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">
<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2021-01-29T00:00:00Z">
<meta property="article:modified_time" content="2021-01-29T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Convolutional Neural Networks",
  "alternativeHeadline": "Convolutional Neural Networks",
  "url": "https://laxmikants.github.io/blog/convolutional-neural-networks/",
  "image": "https://laxmikants.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/convolutional-neural-networks/"
  },
  "description": "One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2021-01-29T00:00:00Z",
  "dateModified": "2021-01-29T00:00:00Z",
  "articleBody": "\r\n\u003cscript src=\"/rmarkdown-libs/header-attrs/header-attrs.js\"\u003e\u003c/script\u003e\r\n\u003clink href=\"/rmarkdown-libs/anchor-sections/anchor-sections.css\" rel=\"stylesheet\" /\u003e\r\n\u003cscript src=\"/rmarkdown-libs/anchor-sections/anchor-sections.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\u003cdiv id=\"convolutional-neural-networks\" class=\"section level1\"\u003e\r\n\u003ch1\u003eConvolutional Neural Networks\u003c/h1\u003e\r\n\u003cdiv id=\"what-are-convolutional-neural-networks\" class=\"section level4\"\u003e\r\n\u003ch4\u003eWhat are Convolutional Neural Networks:\u003c/h4\u003e\r\n\u003cp\u003eOne of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present. CNN algorithms requires to be trained with tons of images and their possible predictor class. CNN are powerful tools for processing data having grid like topology. CNN involves convolution which means cross-corelation operations (instead of a fully connected layer) as one of its layers.\u003c/p\u003e\r\n\u003cp\u003eThese neural networks are successful in many different real-life case studies and applications like:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eImage classification, Object detection, segmentation, face recognition\u003c/li\u003e\r\n\u003cli\u003eSelf driving cars that leverage CNN based vision systems\u003c/li\u003e\r\n\u003cli\u003eClassificationof crystal structure using a convolutional neural network\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/cnn.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eConvolution is the key principle applied:\u003c/mark\u003e in convolutional neural network architecture.\r\nConvolution is a way to identify patterns in data that is directly tied to space or time. Assume we have a one dimentional array of numbers\r\nsay Input = [a,b,c,d,e,f,g] and another set of numbers say K = [p,q]. Then convolution involves sliding the lower size list over the higher size list and then multiplying corresponding values and adding them therefore after convoluting K over Input we get [a\u003cem\u003ep+b\u003c/em\u003eq, b\u003cem\u003ep+c\u003c/em\u003eq, c\u003cem\u003ep+d\u003c/em\u003eq, d\u003cem\u003ep+e\u003c/em\u003eq, f\u003cem\u003ep+g\u003c/em\u003eq]. The result identifies one of the feature of the Input. The result is known as the convolution of the Input and in practice only non-zero values are choosen for feature selection.If the input is a grid structure or in matrix form (in case of images) then the kernal is also choosen as the matrix of lower dimension and in this case matrix multiplication is perfomed to get the resultant convolution of the input image.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eComputer see images as matrices\u003c/mark\u003e:Grayscale images have single channel (gray).\r\nSo, we can represent grayscale images in the form of 2D matrix, where each element represents the intensity of brightness in that particular pixel,\r\nwhere 0 means black and 255 means white. Color images have 3 channels RGB (red, green, blue).\u003cbr /\u003e\r\nColor images can be represented as a 3D matrix with the depth of 3.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eFor example:\u003c/mark\u003e Shape of a matrix representing a 480px by 852px color image will be (480, 852, 3)\r\nEach pixel of the color image has three numbers (ranging from 0 to 255) associated with it.\r\nThese numbers shows the intensity of red, green and blue color in that particular pixel.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport os\r\nimport cv2\r\nimport matplotlib.pyplot as plt # (optional) for plotting and showing images inline\r\nIMAGES_FOLDER = os.path.join(\u0026#39;../../static/img/main\u0026#39;) # images for visuals\r\nearth_fname = os.path.join(IMAGES_FOLDER,\u0026#39;earth.jpg\u0026#39;)\r\nearth_img1 = cv2.imread(earth_fname)\r\nprint(earth_img1.shape)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## (480, 852, 3)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003eThe CIFAR 10 dataset has the Input layer\u003c/mark\u003e of 60000 32x32 colour images in 10 categories, with 6000 images per class.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/cifar10dataset.png\" /\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"in-a-covnolutional-neural-network\" class=\"section level4\"\u003e\r\n\u003ch4\u003eIn a covnolutional neural network:\u003c/h4\u003e\r\n\u003cp\u003e\u003cmark\u003eInput layer:\u003c/mark\u003e Takes an image as input and preserves its spatial structure\r\n\u003cmark\u003eConvolution layer:\u003c/mark\u003e extracts feature maps from the input, each responding to a specific pattern\r\n\u003cmark\u003eReLU layer:\u003c/mark\u003e Introduces non-linearities in the network by putting the negative pixels to 0.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eKernel, stride and padding\u003c/mark\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/convolution_schematic.gif\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eFilters also known as kernals, convolve square blocks of pixels into scalars in subsequent convolutional layers. In the animation above, we have a 3 x 3 filter with ones running on the diagonal and off-diagonal, scanning an image from left to right, top to bottom.\u003c/p\u003e\r\n\u003cp\u003eThroughout the process, the filter performs element-wise multiplication and sums up all products, into a single value passed to the subsequent convolutional layer. Note that the filter is moving a pixel at a time. This is the stride, the stepsize of the sliding window the filter uses to convolve. Larger size of strides indicates more granular and smaller convolved features.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eExample Convolution layer in Python\u003c/mark\u003e\u003c/p\u003e\r\n\u003cp\u003eThe first layer takes input as set of images specified with input_shape. \u003cmark\u003efilters, kernal size, strides and padding \u003c/mark\u003e are the most important\r\nparameters to keras Cov2D. The parameter filters denote the number of filters. The task of a filter is to detect a feature in the image.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom keras.models import Sequential\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Using TensorFlow backend.\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint8 = np.dtype([(\u0026quot;qint8\u0026quot;, np.int8, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_quint8 = np.dtype([(\u0026quot;quint8\u0026quot;, np.uint8, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint16 = np.dtype([(\u0026quot;qint16\u0026quot;, np.int16, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_quint16 = np.dtype([(\u0026quot;quint16\u0026quot;, np.uint16, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint32 = np.dtype([(\u0026quot;qint32\u0026quot;, np.int32, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   np_resource = np.dtype([(\u0026quot;resource\u0026quot;, np.ubyte, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint8 = np.dtype([(\u0026quot;qint8\u0026quot;, np.int8, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_quint8 = np.dtype([(\u0026quot;quint8\u0026quot;, np.uint8, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint16 = np.dtype([(\u0026quot;qint16\u0026quot;, np.int16, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_quint16 = np.dtype([(\u0026quot;quint16\u0026quot;, np.uint16, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   _np_qint32 = np.dtype([(\u0026quot;qint32\u0026quot;, np.int32, 1)])\r\n## C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or \u0026#39;1type\u0026#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \u0026#39;(1,)type\u0026#39;.\r\n##   np_resource = np.dtype([(\u0026quot;resource\u0026quot;, np.ubyte, 1)])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom keras.layers import Conv2D\r\nmodel = Sequential()\r\nmodel.add(Conv2D(filters=16, kernel_size = 3, padding = \u0026#39;same\u0026#39;,activation = \u0026#39;relu\u0026#39;,input_shape=(32,32,3)))\r\nmodel.summary()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Model: \u0026quot;sequential_1\u0026quot;\r\n## _________________________________________________________________\r\n## Layer (type)                 Output Shape              Param #   \r\n## =================================================================\r\n## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       \r\n## =================================================================\r\n## Total params: 448\r\n## Trainable params: 448\r\n## Non-trainable params: 0\r\n## _________________________________________________________________\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003eExample Convolution layer in R\u003c/mark\u003e\u003c/p\u003e\r\n\u003cpre class=\"r\"\u003e\u003ccode\u003elibrary(tensorflow)\r\nlibrary(keras)\r\nmodel \u0026lt;- keras_model_sequential()\r\nmodel%\u0026gt;% \r\n  layer_conv_2d(filters = 16, kernel_size = c(3,3),activation = \u0026#39;relu\u0026#39;,input_shape = c(32,32,3))\r\nsummary(model)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Model: \u0026quot;sequential\u0026quot;\r\n## ________________________________________________________________________________\r\n## Layer (type)                        Output Shape                    Param #     \r\n## ================================================================================\r\n## conv2d (Conv2D)                     (None, 30, 30, 16)              448         \r\n## ================================================================================\r\n## Total params: 448\r\n## Trainable params: 448\r\n## Non-trainable params: 0\r\n## ________________________________________________________________________________\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003epooling layer:\u003c/mark\u003e Down-samples the rectified feature maps, thus reducing the spatial dimensionality and retaining important features.\r\nThis prevents overfitting.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eExample max pooling layer in R\u003c/mark\u003e\u003c/p\u003e\r\n\u003cpre class=\"r\"\u003e\u003ccode\u003emodel %\u0026gt;% \r\n  layer_max_pooling_2d(pool_size = c(2,2)) %\u0026gt;%\r\n  layer_dropout(0.25)\r\nsummary(model)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Model: \u0026quot;sequential\u0026quot;\r\n## ________________________________________________________________________________\r\n## Layer (type)                        Output Shape                    Param #     \r\n## ================================================================================\r\n## conv2d (Conv2D)                     (None, 30, 30, 16)              448         \r\n## ________________________________________________________________________________\r\n## max_pooling2d (MaxPooling2D)        (None, 15, 15, 16)              0           \r\n## ________________________________________________________________________________\r\n## dropout (Dropout)                   (None, 15, 15, 16)              0           \r\n## ================================================================================\r\n## Total params: 448\r\n## Trainable params: 448\r\n## Non-trainable params: 0\r\n## ________________________________________________________________________________\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003eExample max pooling layer in Python\u003c/mark\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom keras.layers import MaxPooling2D\r\nfrom keras.layers import Dropout\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## WARNING:tensorflow:From C:\\Users\\slaxm\\AppData\\Local\\R-MINI~1\\envs\\R-RETI~1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel.add(Dropout(0.25))\r\nmodel.summary()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Model: \u0026quot;sequential_1\u0026quot;\r\n## _________________________________________________________________\r\n## Layer (type)                 Output Shape              Param #   \r\n## =================================================================\r\n## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       \r\n## _________________________________________________________________\r\n## max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \r\n## _________________________________________________________________\r\n## dropout_1 (Dropout)          (None, 16, 16, 16)        0         \r\n## =================================================================\r\n## Total params: 448\r\n## Trainable params: 448\r\n## Non-trainable params: 0\r\n## _________________________________________________________________\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003eFully-Connected layer:\u003c/mark\u003e Learns non-linear combinations of the features and performs the classification task\r\n\u003cmark\u003eFlattening\u003c/mark\u003eFlattening converts last convolutional layer into a one-dimensional NN layer.\u003c/p\u003e\r\n\u003cp\u003e\u003cmark\u003eExample\u003c/mark\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom keras.layers import Dense, Flatten\r\nfrom keras.layers.normalization import BatchNormalization\r\nfrom keras.layers import Dense, Activation\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(512, kernel_initializer=\u0026quot;uniform\u0026quot;))\r\nmodel.add(Activation(\u0026quot;relu\u0026quot;))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Dropout(0.5))\r\n# softmax classifier\r\nmodel.add(Activation(\u0026quot;softmax\u0026quot;))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cmark\u003eObject Detection using Convolutional Neural Network\u003c/mark\u003e\u003c/p\u003e\r\n\u003cp\u003eWe are going to use another Keras dataset, which contains numerous images of ten different categories. These are the following:\u003c/p\u003e\r\n\u003cp\u003e[‘Plane’ , ‘Car’ , ‘Bird’ , ‘Cat’ , ‘Deer’ , ‘Dog’ , ‘Frog’ , ‘Horse’ , ‘Ship’ , ‘Truck’ ]\u003c/p\u003e\r\n\u003cp\u003eThis dataset contains tens of thousands of images of different objects with their respective class. Our goal here is to train a convolutional neural network on that data, in order to then classify other images that the model has never seen before.\u003c/p\u003e\r\n\u003cp\u003eImporting libraries\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport cv2 as cv\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow.keras import datasets, layers, models\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\ntrain_images, test_images = train_images / 255.0 , test_images / 255.0\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThis time we load the cifat10 dataset with the load_data method. We also normalize this data immediately after that, by dividing all values by 255. Since we are dealing with RGB values, and all values lie in between 0 and 255, we end up with values in between 0 and 1.\u003c/p\u003e\r\n\u003cp\u003eNext, we define the possible class names in a list, so that we can label the final numerical results later on. The neural network will again produce a softmax result, which means that we will use the argmax function, to figure out the class name.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eclass_names = [ \u0026#39;Plane\u0026#39; , \u0026#39;Car\u0026#39; , \u0026#39;Bird\u0026#39; , \u0026#39;Cat\u0026#39; , \u0026#39;Deer\u0026#39; ,\r\n                \u0026#39;Dog\u0026#39; , \u0026#39;Frog\u0026#39; , \u0026#39;Horse\u0026#39; , \u0026#39;Ship\u0026#39; , \u0026#39;Truck\u0026#39; ]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNow we can visualize a section of the data, to see what this dataset looks like.\u003c/p\u003e\r\n\u003cp\u003eFor this we run a for loop with 16 iterations and create a 4x4 grid of subplots. The x-ticks and the y-ticks will be set to empty lists, so that we don’t have annoying coordinates. After that, we use the imshow method, to visualize the individual images. The label of the image will then be the respective class name.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/cifar10objectsdetection.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThis dataset contains a lot of images.\u003c/p\u003e\r\n\u003cp\u003eHere for example we only use the first 20,000 of the training images and the first 4,000 of the test images. Of course your model will be way more accurate if you use all the images. However, for weak computers this might take forever.\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eBUILDING NEURAL NETWORK\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003eNow that we have prepared our data, we can start building the neural network.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel = models.Sequential()\r\nmodel.add(layers.Conv2D( 32 , ( 3 , 3 ), activation = \u0026#39;relu\u0026#39; ,\r\n                         input_shape =( 32 , 32 , 3 )))\r\nmodel.add(layers.MaxPooling2D(( 2 , 2 )))\r\nmodel.add(layers.Conv2D( 64 , ( 3 , 3 ), activation = \u0026#39;relu\u0026#39; ))\r\nmodel.add(layers.MaxPooling2D(( 2 , 2 )))\r\nmodel.add(layers.Conv2D( 64 , ( 3 , 3 ), activation = \u0026#39;relu\u0026#39; ))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense( 64 , activation = \u0026#39;relu\u0026#39; ))\r\nmodel.add(layers.Dense( 10 , activation = \u0026#39;softmax\u0026#39; ))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHere we again define a Sequential model. Our inputs go directly into a convolutional layer (Conv2D ). This layer has 32 filters or channels in the shape of 3x3 matrices. The activation function is the ReLU function, which we already know and the input shape is 32x32x3. This is because we our images have a resolution of 32x32 pixels and three layers because of the RGB colors. The result is then forwarded into a MaxPooling2D layer that simplifies the output. Then the simplified output is again forwarded into the next convolutional layer. After that into another max-pooling layer and into another convolutional layer. This result is then being flattened by the Flatten layer, which means that it is transformed into a one-dimensional vector format. Then we forward the results into one dense hidden layer before it finally comes to the softmax output layer. There we find the final classification probabilities.\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eTRAINING AND TESTING\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003eNow we are almost done. We just need to train and test the model before we can use it.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel.compile( optimizer = \u0026#39;adam\u0026#39; ,\r\n               loss = \u0026#39;sparse_categorical_crossentropy\u0026#39; ,\r\n               metrics =[ \u0026#39;accuracy\u0026#39; ])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eHere we again use the adam optimizer and the sparse categorical crossentropy loss function.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel.fit(train_images,\r\n          train_labels,\r\n           epochs = 10 ,\r\n           validation_data =(test_images, test_labels))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe now train our model on our training data in ten epochs. Remember: This means that our model is going to see the same data ten times over and over again.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etest_loss, test_acc = model.evaluate(test_images,\r\n                                     test_labels,\r\n                                      verbose = 2 )\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe use the evaluate function to test our model and get the loss and accuracy values. We set the parameter verbose to 2, so that we get as much information as possible.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e1s - loss: 0.8139 - acc: 0.7090\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003ccode\u003eCLASSIFYING OWN IMAGES\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003eHowever, the interesting part starts now. Since our model is trained, we can now go ahead and use our own images of cars, planes, horses etc. for classification.\u003c/p\u003e\r\n\u003cp\u003eThe important thing is that we get these images down to 32x32 pixels because this is the required input format of our model. For this you can use any software like Gimp or Paint. You can either crop the images or scale them.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/cnntestimages.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eNow we just have to load these images into our script, using OpenCV.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimg1 = cv.imread( \u0026#39;car.jpg\u0026#39; )\r\nimg1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\r\nimg2 = cv.imread( \u0026#39;horse.jpg\u0026#39; )\r\nimg2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\r\nplt.imshow(img1, cmap =plt.cm.binary)\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe function imread loads the image into our script. Then we use the cvtColor method, in order to change the default color scheme of BGR (blue, green, red) to RGB (red, green, blue).\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eplt.imshow(img1, cmap =plt.cm.binary)\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWith the imshow function, we can show the image in our script, using Matplotlib.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/horse.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eWe can now use the loaded images as the input for our model, in order to get a prediction.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eprediction = model.predict(np.array([img1]) / 255 )\r\nindex = np.argmax(prediction)\r\nprint (class_names[index])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eFirst we use the predict function to get the softmax result. Notice that we are converting our image into a NumPy array and dividing it by 255. This is because we need to normalize it, since our model was trained on normalized values. Then we use the argmax function to get the index of the highest softmax activation value. Finally, we print the class name of that index as a result.\u003c/p\u003e\r\n\u003cp\u003eCar Horse\u003c/p\u003e\r\n\u003cp\u003eThe results speak for themselves. These pictures were classified absolutely correct.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  
</head>
  <body>
    
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5KFS4C"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
      
    


<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
        
          
          <a href="/contact/" class="nav link"><i class='far fa-envelope'></i> Contact</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
 
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  
  
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu">

  </div></menu>
  
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Convolutional%20Neural%20Networks&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f&amp;title=Convolutional%20Neural%20Networks" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    <p>Articles on Data Science</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>



      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
    
    
      <p>One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present.</p>
    
  </div>
  <div class="meta">
    <time datetime="2021-01-29 00:00:00 &#43;0000 UTC">January 29, 2021</time>
    <p>Laxmi K Soni</p>
    <p>12-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Convolutional%20Neural%20Networks&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fconvolutional-neural-networks%2f&amp;title=Convolutional%20Neural%20Networks" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </div>
    <div align = "center">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        
        <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-3804322353139756"
         data-ad-slot="3387213493"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
        <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
        </script>
    </div>
    <div class="content">
      <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="convolutional-neural-networks" class="section level1">
<h1>Convolutional Neural Networks</h1>
<div id="what-are-convolutional-neural-networks" class="section level4">
<h4>What are Convolutional Neural Networks:</h4>
<p>One of the important areas of Deep learning is Convolutional Neural Network. CNN deals in analysing visual images. These types of neural networks works by processing, classifying and segmenting images. CNN algorithm learns about images and then are able to predict about a given image when present. CNN algorithms requires to be trained with tons of images and their possible predictor class. CNN are powerful tools for processing data having grid like topology. CNN involves convolution which means cross-corelation operations (instead of a fully connected layer) as one of its layers.</p>
<p>These neural networks are successful in many different real-life case studies and applications like:</p>
<ul>
<li>Image classification, Object detection, segmentation, face recognition</li>
<li>Self driving cars that leverage CNN based vision systems</li>
<li>Classificationof crystal structure using a convolutional neural network</li>
</ul>
<p><img src="/img/main/cnn.png" /></p>
<p><mark>Convolution is the key principle applied:</mark> in convolutional neural network architecture.
Convolution is a way to identify patterns in data that is directly tied to space or time. Assume we have a one dimentional array of numbers
say Input = [a,b,c,d,e,f,g] and another set of numbers say K = [p,q]. Then convolution involves sliding the lower size list over the higher size list and then multiplying corresponding values and adding them therefore after convoluting K over Input we get [a<em>p+b</em>q, b<em>p+c</em>q, c<em>p+d</em>q, d<em>p+e</em>q, f<em>p+g</em>q]. The result identifies one of the feature of the Input. The result is known as the convolution of the Input and in practice only non-zero values are choosen for feature selection.If the input is a grid structure or in matrix form (in case of images) then the kernal is also choosen as the matrix of lower dimension and in this case matrix multiplication is perfomed to get the resultant convolution of the input image.</p>
<p><mark>Computer see images as matrices</mark>:Grayscale images have single channel (gray).
So, we can represent grayscale images in the form of 2D matrix, where each element represents the intensity of brightness in that particular pixel,
where 0 means black and 255 means white. Color images have 3 channels RGB (red, green, blue).<br />
Color images can be represented as a 3D matrix with the depth of 3.</p>
<p><mark>For example:</mark> Shape of a matrix representing a 480px by 852px color image will be (480, 852, 3)
Each pixel of the color image has three numbers (ranging from 0 to 255) associated with it.
These numbers shows the intensity of red, green and blue color in that particular pixel.</p>
<pre class="python"><code>import os
import cv2
import matplotlib.pyplot as plt # (optional) for plotting and showing images inline
IMAGES_FOLDER = os.path.join(&#39;../../static/img/main&#39;) # images for visuals
earth_fname = os.path.join(IMAGES_FOLDER,&#39;earth.jpg&#39;)
earth_img1 = cv2.imread(earth_fname)
print(earth_img1.shape)</code></pre>
<pre><code>## (480, 852, 3)</code></pre>
<p><mark>The CIFAR 10 dataset has the Input layer</mark> of 60000 32x32 colour images in 10 categories, with 6000 images per class.</p>
<p><img src="/img/main/cifar10dataset.png" /></p>
</div>
<div id="in-a-covnolutional-neural-network" class="section level4">
<h4>In a covnolutional neural network:</h4>
<p><mark>Input layer:</mark> Takes an image as input and preserves its spatial structure
<mark>Convolution layer:</mark> extracts feature maps from the input, each responding to a specific pattern
<mark>ReLU layer:</mark> Introduces non-linearities in the network by putting the negative pixels to 0.</p>
<p><mark>Kernel, stride and padding</mark></p>
<p><img src="/img/main/convolution_schematic.gif" /></p>
<p>Filters also known as kernals, convolve square blocks of pixels into scalars in subsequent convolutional layers. In the animation above, we have a 3 x 3 filter with ones running on the diagonal and off-diagonal, scanning an image from left to right, top to bottom.</p>
<p>Throughout the process, the filter performs element-wise multiplication and sums up all products, into a single value passed to the subsequent convolutional layer. Note that the filter is moving a pixel at a time. This is the stride, the stepsize of the sliding window the filter uses to convolve. Larger size of strides indicates more granular and smaller convolved features.</p>
<p><mark>Example Convolution layer in Python</mark></p>
<p>The first layer takes input as set of images specified with input_shape. <mark>filters, kernal size, strides and padding </mark> are the most important
parameters to keras Cov2D. The parameter filters denote the number of filters. The task of a filter is to detect a feature in the image.</p>
<pre class="python"><code>from keras.models import Sequential</code></pre>
<pre><code>## Using TensorFlow backend.
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint8 = np.dtype([(&quot;qint8&quot;, np.int8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint8 = np.dtype([(&quot;quint8&quot;, np.uint8, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint16 = np.dtype([(&quot;qint16&quot;, np.int16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_quint16 = np.dtype([(&quot;quint16&quot;, np.uint16, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   _np_qint32 = np.dtype([(&quot;qint32&quot;, np.int32, 1)])
## C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
##   np_resource = np.dtype([(&quot;resource&quot;, np.ubyte, 1)])</code></pre>
<pre class="python"><code>from keras.layers import Conv2D
model = Sequential()
model.add(Conv2D(filters=16, kernel_size = 3, padding = &#39;same&#39;,activation = &#39;relu&#39;,input_shape=(32,32,3)))
model.summary()</code></pre>
<pre><code>## Model: &quot;sequential_1&quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       
## =================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## _________________________________________________________________</code></pre>
<p><mark>Example Convolution layer in R</mark></p>
<pre class="r"><code>library(tensorflow)
library(keras)
model &lt;- keras_model_sequential()
model%&gt;% 
  layer_conv_2d(filters = 16, kernel_size = c(3,3),activation = &#39;relu&#39;,input_shape = c(32,32,3))
summary(model)</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## conv2d (Conv2D)                     (None, 30, 30, 16)              448         
## ================================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<p><mark>pooling layer:</mark> Down-samples the rectified feature maps, thus reducing the spatial dimensionality and retaining important features.
This prevents overfitting.</p>
<p><mark>Example max pooling layer in R</mark></p>
<pre class="r"><code>model %&gt;% 
  layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%
  layer_dropout(0.25)
summary(model)</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## conv2d (Conv2D)                     (None, 30, 30, 16)              448         
## ________________________________________________________________________________
## max_pooling2d (MaxPooling2D)        (None, 15, 15, 16)              0           
## ________________________________________________________________________________
## dropout (Dropout)                   (None, 15, 15, 16)              0           
## ================================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<p><mark>Example max pooling layer in Python</mark></p>
<pre class="python"><code>from keras.layers import MaxPooling2D
from keras.layers import Dropout
model.add(MaxPooling2D(pool_size=(2, 2)))</code></pre>
<pre><code>## WARNING:tensorflow:From C:\Users\slaxm\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\keras\backend\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.</code></pre>
<pre class="python"><code>model.add(Dropout(0.25))
model.summary()</code></pre>
<pre><code>## Model: &quot;sequential_1&quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d_1 (Conv2D)            (None, 32, 32, 16)        448       
## _________________________________________________________________
## max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         
## _________________________________________________________________
## dropout_1 (Dropout)          (None, 16, 16, 16)        0         
## =================================================================
## Total params: 448
## Trainable params: 448
## Non-trainable params: 0
## _________________________________________________________________</code></pre>
<p><mark>Fully-Connected layer:</mark> Learns non-linear combinations of the features and performs the classification task
<mark>Flattening</mark>Flattening converts last convolutional layer into a one-dimensional NN layer.</p>
<p><mark>Example</mark></p>
<pre class="python"><code>from keras.layers import Dense, Flatten
from keras.layers.normalization import BatchNormalization
from keras.layers import Dense, Activation

model.add(Flatten())
model.add(Dense(512, kernel_initializer=&quot;uniform&quot;))
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization())
model.add(Dropout(0.5))
# softmax classifier
model.add(Activation(&quot;softmax&quot;))</code></pre>
<p><mark>Object Detection using Convolutional Neural Network</mark></p>
<p>We are going to use another Keras dataset, which contains numerous images of ten different categories. These are the following:</p>
<p>[‘Plane’ , ‘Car’ , ‘Bird’ , ‘Cat’ , ‘Deer’ , ‘Dog’ , ‘Frog’ , ‘Horse’ , ‘Ship’ , ‘Truck’ ]</p>
<p>This dataset contains tens of thousands of images of different objects with their respective class. Our goal here is to train a convolutional neural network on that data, in order to then classify other images that the model has never seen before.</p>
<p>Importing libraries</p>
<pre class="python"><code>import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layers, models</code></pre>
<pre class="python"><code>(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0 , test_images / 255.0</code></pre>
<p>This time we load the cifat10 dataset with the load_data method. We also normalize this data immediately after that, by dividing all values by 255. Since we are dealing with RGB values, and all values lie in between 0 and 255, we end up with values in between 0 and 1.</p>
<p>Next, we define the possible class names in a list, so that we can label the final numerical results later on. The neural network will again produce a softmax result, which means that we will use the argmax function, to figure out the class name.</p>
<pre class="python"><code>class_names = [ &#39;Plane&#39; , &#39;Car&#39; , &#39;Bird&#39; , &#39;Cat&#39; , &#39;Deer&#39; ,
                &#39;Dog&#39; , &#39;Frog&#39; , &#39;Horse&#39; , &#39;Ship&#39; , &#39;Truck&#39; ]</code></pre>
<p>Now we can visualize a section of the data, to see what this dataset looks like.</p>
<p>For this we run a for loop with 16 iterations and create a 4x4 grid of subplots. The x-ticks and the y-ticks will be set to empty lists, so that we don’t have annoying coordinates. After that, we use the imshow method, to visualize the individual images. The label of the image will then be the respective class name.</p>
<p><img src="/img/main/cifar10objectsdetection.png" /></p>
<p>This dataset contains a lot of images.</p>
<p>Here for example we only use the first 20,000 of the training images and the first 4,000 of the test images. Of course your model will be way more accurate if you use all the images. However, for weak computers this might take forever.</p>
<p><code>BUILDING NEURAL NETWORK</code></p>
<p>Now that we have prepared our data, we can start building the neural network.</p>
<pre class="python"><code>model = models.Sequential()
model.add(layers.Conv2D( 32 , ( 3 , 3 ), activation = &#39;relu&#39; ,
                         input_shape =( 32 , 32 , 3 )))
model.add(layers.MaxPooling2D(( 2 , 2 )))
model.add(layers.Conv2D( 64 , ( 3 , 3 ), activation = &#39;relu&#39; ))
model.add(layers.MaxPooling2D(( 2 , 2 )))
model.add(layers.Conv2D( 64 , ( 3 , 3 ), activation = &#39;relu&#39; ))
model.add(layers.Flatten())
model.add(layers.Dense( 64 , activation = &#39;relu&#39; ))
model.add(layers.Dense( 10 , activation = &#39;softmax&#39; ))</code></pre>
<p>Here we again define a Sequential model. Our inputs go directly into a convolutional layer (Conv2D ). This layer has 32 filters or channels in the shape of 3x3 matrices. The activation function is the ReLU function, which we already know and the input shape is 32x32x3. This is because we our images have a resolution of 32x32 pixels and three layers because of the RGB colors. The result is then forwarded into a MaxPooling2D layer that simplifies the output. Then the simplified output is again forwarded into the next convolutional layer. After that into another max-pooling layer and into another convolutional layer. This result is then being flattened by the Flatten layer, which means that it is transformed into a one-dimensional vector format. Then we forward the results into one dense hidden layer before it finally comes to the softmax output layer. There we find the final classification probabilities.</p>
<p><code>TRAINING AND TESTING</code></p>
<p>Now we are almost done. We just need to train and test the model before we can use it.</p>
<pre class="python"><code>model.compile( optimizer = &#39;adam&#39; ,
               loss = &#39;sparse_categorical_crossentropy&#39; ,
               metrics =[ &#39;accuracy&#39; ])</code></pre>
<p>Here we again use the adam optimizer and the sparse categorical crossentropy loss function.</p>
<pre class="python"><code>model.fit(train_images,
          train_labels,
           epochs = 10 ,
           validation_data =(test_images, test_labels))</code></pre>
<p>We now train our model on our training data in ten epochs. Remember: This means that our model is going to see the same data ten times over and over again.</p>
<pre class="python"><code>test_loss, test_acc = model.evaluate(test_images,
                                     test_labels,
                                      verbose = 2 )</code></pre>
<p>We use the evaluate function to test our model and get the loss and accuracy values. We set the parameter verbose to 2, so that we get as much information as possible.</p>
<ul>
<li>1s - loss: 0.8139 - acc: 0.7090</li>
</ul>
<p><code>CLASSIFYING OWN IMAGES</code></p>
<p>However, the interesting part starts now. Since our model is trained, we can now go ahead and use our own images of cars, planes, horses etc. for classification.</p>
<p>The important thing is that we get these images down to 32x32 pixels because this is the required input format of our model. For this you can use any software like Gimp or Paint. You can either crop the images or scale them.</p>
<p><img src="/img/main/cnntestimages.png" /></p>
<p>Now we just have to load these images into our script, using OpenCV.</p>
<pre class="python"><code>img1 = cv.imread( &#39;car.jpg&#39; )
img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)
img2 = cv.imread( &#39;horse.jpg&#39; )
img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)
plt.imshow(img1, cmap =plt.cm.binary)
plt.show()</code></pre>
<p>The function imread loads the image into our script. Then we use the cvtColor method, in order to change the default color scheme of BGR (blue, green, red) to RGB (red, green, blue).</p>
<pre class="python"><code>plt.imshow(img1, cmap =plt.cm.binary)
plt.show()</code></pre>
<p>With the imshow function, we can show the image in our script, using Matplotlib.</p>
<p><img src="/img/main/horse.png" /></p>
<p>We can now use the loaded images as the input for our model, in order to get a prediction.</p>
<pre class="python"><code>prediction = model.predict(np.array([img1]) / 255 )
index = np.argmax(prediction)
print (class_names[index])</code></pre>
<p>First we use the predict function to get the softmax result. Notice that we are converting our image into a NumPy array and dividing it by 255. This is because we need to normalize it, since our model was trained on normalized values. Then we use the argmax function to get the index of the highest softmax activation value. Finally, we print the class name of that index as a result.</p>
<p>Car Horse</p>
<p>The results speak for themselves. These pictures were classified absolutely correct.</p>
</div>
</div>

    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/convolutional-neural-networks/">Convolutional Neural Networks</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/convolutional-neural-networks/">Convolutional Neural Networks</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    

  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="5d69b45a66b46af850e235f658043f16">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
    
      <a href="/blog/convolutional-neural-networks/" class="button right"><span>Convolutional Neural Networks</span></a>
    
  </div>
  

      </main>
      

<section id="site-sidebar">
 
  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-29 00:00:00 &#43;0000 UTC">January 29, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-03 00:00:00 &#43;0000 UTC">January 3, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/neural-network-using-make-moons-dataset/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg');">
    <img src="https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/neural-network-using-make-moons-dataset/">Neural Network using Make Moons dataset</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      

      
    </section>
  


  
    
      <section id="categories">
        
   
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/convolutional-neural-networks/">convolutional-neural-networks<span class="count">2</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
      </section>
    
  



  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>about</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    © 2021 Data Science Posts and Resources
      <br>
  </p>
</footer>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.daca826145adfcf5004b4b16d74010eff217a0382fad56b874f5630927a20c4e.js" integrity="sha256-2sqCYUWt/PUAS0sW10AQ7/IXoDgvrVa4dPVjCSeiDE4="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
  
</html>
