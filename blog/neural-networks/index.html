<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Neural Networks - Data Science Posts and Resources :: Laxmikant Soni</title>

<meta name="viewport" content="width=device-width" />

<meta name="google-site-verification" content="MeRcFEBEyWiTb3NfY4THWxbV_fx3rKOJnvr_Jk398wY" />

<meta name=keywords content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics | Laxmikant Soni, Predictive Analytics, Business, Data, Analytics, Machine Learning, Data Mining, Neural Network with Python, Neural Network, Predict Stock price movement using Neural Networks, Intelligence, Big, Modeling, Data Science, Integration, Visualization,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow">

<meta name=description content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics :: Laxmikant Soni">

<meta name="robots" content="index">


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>




<meta name="generator" content="Hugo 0.91.2" /><meta itemprop="name" content="Neural Networks">
<meta itemprop="description" content="Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle."><meta itemprop="datePublished" content="2020-12-05T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-12-05T00:00:00+00:00" />
<meta itemprop="wordCount" content="1462">
<meta itemprop="keywords" content="Neural Networks," /><meta property="og:title" content="Neural Networks" />
<meta property="og:description" content="Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/neural-networks/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2020-12-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Neural Networks"/>
<meta name="twitter:description" content="Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle."/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.aa4e8165f5b2a16460fcb21582ad412bed8e48e9c5dc49f3b412d1703be4d75d.css" integrity=""><link rel="stylesheet" href="/css/add-on.css">
        <link rel="stylesheet" href="/css/main.css">

<title>Neural Networks : Data Science Posts and Resources</title>

<meta property="og:title" content="Neural Networks">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/neural-networks/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.">
<meta name="description" content="Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.">
<meta property="og:updated_time" content="2020-12-05T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">

<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2020-12-05T00:00:00Z">
<meta property="article:modified_time" content="2020-12-05T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Neural Networks",
  "alternativeHeadline": "Neural Networks",
  "name" : "Data Science Posts and Resources",
  "url": "https://laxmikants.github.io/blog/neural-networks/",
  "image": "https://laxmikants.github.io/",
  "sameAs":
      [ "https://www.facebook.com/laxmikantsoni09",
        "https://instagram.com/laxmikantsoni09",
        "https://www.linkedin.com/in/laxmikantsoni09",
        "https://twitter.com/laxmikantsoni09",
        "https://github.com/laxmikants",
        "https://www.kaggle.com/laxmikantsoni"
    ],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/neural-networks/"
  },
  "description": "Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2020-12-05T00:00:00Z",
  "dateModified": "2020-12-05T00:00:00Z",
  "articleBody": "\u003ch2 id=\"artificial-neural-networks\"\u003eArtificial Neural Networks\u003c/h2\u003e\n\u003cp\u003eArtificial neural networks are mathematical structures that are inspired by the human brain\nThey consist of so-called neurons , which are interconnected with each other. \nThe human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.\u003c/p\u003e\n\u003ch4 id=\"structure-of-a-neural-network\"\u003eSTRUCTURE OF A NEURAL NETWORK\u003c/h4\u003e\n\u003cp\u003eThe structure of a neural network is quite simple. In the figure below, we can see multiple layers. \nThe first one is the input layer and the last one is the output layer . In between we have multiple so-called hidden layers .\nThe input layer is for the data that we want to feed into the neural network in order to get a result. \nHere we put all of the things that are “perceived” by or put into the neural network. \nFor example, if we want to know if a picture shows a cat or a dog, we would put all the values of the individual pixels into the input layer. \nIf we want to know if a person is overweight or not, we would enter parameters like height, weight etc.\nThe output layer then contains the results. There we can see the values generated by the neural network based on our inputs. \nFor example the classification of an animal or a prediction value for something.\nEverything in between are abstraction layers that we call hidden layers. \nThese increase the complexity and the sophistication of the model and they expand the internal decision making. \nAs a rule of thumb we could say that the more hidden layers and the more neurons we have, the more complex our model is\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/nnstructure.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eIn the figure above, we can see three layers. First the input layer , at the end the output layer and in between the hidden layer .\u003c/p\u003e\n\u003cp\u003eObviously the input layer is where our inputs go. There we put all the things which are being entered or sensed by the script or the machine. Basically these are our features.\u003c/p\u003e\n\u003cp\u003eWe can use neural networks to classify data or to act on inputs and the output layer is where we get our results. These results might be a class or action steps. Maybe when we input a high temperature into our model, the output will be the action of cooling down the machine.\u003c/p\u003e\n\u003cp\u003eAll the layers between input and output are called hidden layers . They make the model more abstract and more complex. They extend the internal logic.\u003c/p\u003e\n\u003cp\u003eThe more hidden layers and neurons you add, the more sophisticated the model gets.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/nnstructure1.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eHere for example we have two hidden layers, one with four neurons and one with three neurons. Notice that every neuron of a layer is connected to every neuron of the next layer.\u003c/p\u003e\n\u003ch4 id=\"structure-of-a-neuron\"\u003eSTRUCTURE OF A NEURON\u003c/h4\u003e\n\u003cp\u003eIn order to understand how a neural network works in general, we need to understand how the individual neurons work.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/neuronstructure.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see every neuron gets a certain input, which is either the output of a previous neuron or the raw input of the input layer.\nThis input is a numerical value and it then gets multiplied by each individual weight (w1, w2, w3…) . \nAt the end we then subtract the bias (b) .\u003c/p\u003e\n\u003cp\u003eThe result is the output of that particular connection.\u003c/p\u003e\n\u003cp\u003eThese outputs are that forwarded to the next layer of neurons.\u003c/p\u003e\n\u003cp\u003eThe diagram below shows the neural network for computing the square root of a given number.\u003c/p\u003e\n\u003ch4 id=\"activation-functions\"\u003eACTIVATION FUNCTIONS\u003c/h4\u003e\n\u003cp\u003eThere are a lot of different so-called activation functions which make everything more complex.\nThese functions determine the output of a neuron. Basically what we do is: We take the input of our neuron and feed \nthe value into an activation function. This function then returns the output value.\u003c/p\u003e\n\u003ch4 id=\"sigmoid-activation-function\"\u003eSIGMOID ACTIVATION FUNCTION\u003c/h4\u003e\n\u003cp\u003eA commonly used and popular activation function is the so-called sigmoid activation function . \nThis function always returns a value between zero and one, no matter what the input is.\nThe smaller the input, the closer the output will be to zero. The greater the input, the closer the output will be to one.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/sigmoid.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eThe mathematical formula looks like this:\u003c/p\u003e\n\u003cp\u003e$g(z) = \\dfrac{1}{1 + e^{-z}}$\u003c/p\u003e\n\u003cp\u003eExample in Python:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e keras.models \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Sequential\nmodel \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Sequential()\n\u003cspan style=\"color:#f92672\"\u003e..\u003c/span\u003e\n\u003cspan style=\"color:#f92672\"\u003e..\u003c/span\u003e\nmodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eadd(Activation(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;sigmoid\u0026#39;\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eExample in R:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-r\" data-lang=\"r\"\u003emodel \u003cspan style=\"color:#f92672\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ekeras_model_sequential\u003c/span\u003e()\n\nmodel \u003cspan style=\"color:#f92672\"\u003e%\u0026gt;%\u003c/span\u003e \n    \u003cspan style=\"color:#a6e22e\"\u003elayer_dense\u003c/span\u003e(units \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e, activation \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;sigmoid\u0026#39;\u003c/span\u003e, input_shape \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ec\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e)) \u003cspan style=\"color:#f92672\"\u003e%\u0026gt;%\u003c/span\u003e \n    \u003cspan style=\"color:#a6e22e\"\u003elayer_dense\u003c/span\u003e(units \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e, activation \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;softmax\u0026#39;\u003c/span\u003e)\n\nOutput layer creates \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e output values, one for each Iris class. \nThe first layer, which contains \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e hidden notes, on the other hand, has an input_shape of \u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e. \nThis is because your training data has \u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e columns.    \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"relu-activation-function\"\u003eRELU ACTIVATION FUNCTION\u003c/h4\u003e\n\u003cp\u003eThe probably most commonly used activation function is the so-called ReLU function . \nThis stands for rectified linear unit . This function is very simple but also very useful. Whenever the input value is \nnegative, it will return zero. Whenever it is positive, the output will just be the input.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/relu.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e$g(z) = \\max(0,z)$\u003c/p\u003e\n\u003cp\u003eExample in Python:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e keras.models \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Sequential\n(Creates a sequential keras model \u003cspan style=\"color:#f92672\"\u003eand\u003c/span\u003e add an activation function to it)\n\nmodel \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Sequential()\n\u003cspan style=\"color:#f92672\"\u003e..\u003c/span\u003e\n\u003cspan style=\"color:#f92672\"\u003e..\u003c/span\u003e\nmodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eadd(Activation(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;relu\u0026#39;\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eExample in R:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-r\" data-lang=\"r\"\u003emodel \u003cspan style=\"color:#f92672\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ekeras_model_sequential\u003c/span\u003e()\n\n(Output layer creates \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e output values, one for each class. \nThe first layer, which contains \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e hidden notes, on the other hand, has an input_shape of \u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e. \nThis is because your training data has \u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e columns.)\n\nmodel \u003cspan style=\"color:#f92672\"\u003e%\u0026gt;%\u003c/span\u003e \n    \u003cspan style=\"color:#a6e22e\"\u003elayer_dense\u003c/span\u003e(units \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e, activation \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;relu\u0026#39;\u003c/span\u003e, input_shape \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ec\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e4\u003c/span\u003e)) \u003cspan style=\"color:#f92672\"\u003e%\u0026gt;%\u003c/span\u003e \n    \u003cspan style=\"color:#a6e22e\"\u003elayer_dense\u003c/span\u003e(units \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e, activation \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;softmax\u0026#39;\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"types-of-neural-networks\"\u003eTYPES OF NEURAL NETWORKS\u003c/h4\u003e\n\u003cp\u003eNeural networks are not only different because of the activation functions of their individual layers. \nThere are also different types of layers and networks\u003c/p\u003e\n\u003ch5 id=\"feed-forward-neural-networks\"\u003eFEED FORWARD NEURAL NETWORKS\u003c/h5\u003e\n\u003cp\u003eThe so-called feed forward neural networks could be seen as the classic neural networks. Up until now we have primarily talked about these. \nIn this type of network the information only flows into one direction – from the input layer to the output layer. There are no circles or cycles.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/ffnn.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch5 id=\"recurrent-neural-networks\"\u003eRECURRENT NEURAL NETWORKS\u003c/h5\u003e\n\u003cp\u003eSo-called recurrent neural networks on the other hand work differently. In these networks we have layers with neurons that not only connect \nto the neurons next layer but also to neurons of the previous or of their own layer. This can also be called feedback .If we take the output of a neuron and use it as an input of the same neuron, we are talking about direct feedback . Connecting the output to neurons of the same layer is called lateral feedback . And if we take the output and feed it into neurons of the previous layer, we are talking about indirect feedback\n\u003cimg src=\"/img/main/rrnn.png\" alt=\"\"\u003e\nThe advantage of such a recurrent neural network is that it has a little memory and doesn’t only take the immediate present data into account. We could say that it “looks back” a couple of iterations.\u003c/p\u003e\n\u003cp\u003eThis kind of neural networks is oftentimes used when the tasks requires the processing of sequential data like text or speech. The feedback is very useful in this kind of tasks. However it is not very useful when dealing with image recognition or image processing.\u003c/p\u003e\n\u003ch5 id=\"convolutional-neural-networks\"\u003eCONVOLUTIONAL NEURAL NETWORKS\u003c/h5\u003e\n\u003cp\u003eFor this purpose we have the so-called convolutional neural networks . This type is primarily used for processing images and sound. It is especially useful when pattern recognition in noisy data is needed. This data may be image data, sound data or video data. It doesn’t matter.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/img/main/cnn.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eLet’s look at a simple example above. Here we have multiple Xs and Os as examples in a 16x16 pixels format. Each pixel is an input neuron and will be processed. At the end our neural network shall classify the image as either an X or an O.\u003c/p\u003e\n\u003ch4 id=\"summary\"\u003eSUMMARY\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eActivation functions determine the activation of a neuron which then influences the outputs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe classic neural networks are feed forward neural networks. The information only flows into one direction.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIn recurrent neural networks we work with feedback and it is possible to take the output of future layers as the input of neurons. This creates something like a memory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eConvolutional neural networks are primarily used for images, audio data and other data which requires pattern recognition. They split the data into features.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUsually we use 80% of the data we have as training data and 20% as testing data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe error indicates how much percent of the data was classified incorrectly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe loss is a numerical value which is calculated with a loss function. This is the value that we want to minimize in order to optimize our model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFor the minimization of the output we use the gradient descent algorithm. It finds the local minimum of a function.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBackpropagation is the algorithm which calculates the gradient for the gradient descent algorithm. This is done by starting from the output layer and reverse engineering the desired changes.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  
</head>
  <body>
    
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5KFS4C"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
      
    


<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
        
          
          <a href="/contact/" class="nav link"><i class='far fa-envelope'></i> Contact</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
 
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  
  
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu">
  </div></menu>
  
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Neural%20Networks&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f&amp;title=Neural%20Networks" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </menu>
  
</header>

      
    <div id="wrapper">
    
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    <p>Articles on Data Science</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>



      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/neural-networks/">Neural Networks</a></h2>
    
    
      <p>Artificial neural networks are mathematical structures that are inspired by the human brain They consist of so-called neurons , which are interconnected with each other. The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.</p>
    
  </div>
  <div class="meta">
    <time datetime="2020-12-05 00:00:00 &#43;0000 UTC">December 5, 2020</time>
    <p>Laxmi K Soni</p>
    <p>7-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Neural%20Networks&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fneural-networks%2f&amp;title=Neural%20Networks" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </div>
      <div class="content">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      
      <ins class="adsbygoogle"
           style="display:block"
           data-ad-client="ca-pub-3804322353139756"
           data-ad-slot="1652057437"
           data-ad-format="auto"
           data-full-width-responsive="false"></ins>
      <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
      </script>
      </div>
    <div class="content">
      <a href="/blog/neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Neural-Networks-32.jpg');">
    <img src="https://laxmikants.github.io/img/main/Neural-Networks-32.jpg" alt="">
  </a>
      <h2 id="artificial-neural-networks">Artificial Neural Networks</h2>
<p>Artificial neural networks are mathematical structures that are inspired by the human brain
They consist of so-called neurons , which are interconnected with each other. 
The human brain consists of multiple billions of such neurons. Artificial neural networks use a similar principle.</p>
<h4 id="structure-of-a-neural-network">STRUCTURE OF A NEURAL NETWORK</h4>
<p>The structure of a neural network is quite simple. In the figure below, we can see multiple layers. 
The first one is the input layer and the last one is the output layer . In between we have multiple so-called hidden layers .
The input layer is for the data that we want to feed into the neural network in order to get a result. 
Here we put all of the things that are “perceived” by or put into the neural network. 
For example, if we want to know if a picture shows a cat or a dog, we would put all the values of the individual pixels into the input layer. 
If we want to know if a person is overweight or not, we would enter parameters like height, weight etc.
The output layer then contains the results. There we can see the values generated by the neural network based on our inputs. 
For example the classification of an animal or a prediction value for something.
Everything in between are abstraction layers that we call hidden layers. 
These increase the complexity and the sophistication of the model and they expand the internal decision making. 
As a rule of thumb we could say that the more hidden layers and the more neurons we have, the more complex our model is</p>
<p><img src="/img/main/nnstructure.png" alt=""></p>
<p>In the figure above, we can see three layers. First the input layer , at the end the output layer and in between the hidden layer .</p>
<p>Obviously the input layer is where our inputs go. There we put all the things which are being entered or sensed by the script or the machine. Basically these are our features.</p>
<p>We can use neural networks to classify data or to act on inputs and the output layer is where we get our results. These results might be a class or action steps. Maybe when we input a high temperature into our model, the output will be the action of cooling down the machine.</p>
<p>All the layers between input and output are called hidden layers . They make the model more abstract and more complex. They extend the internal logic.</p>
<p>The more hidden layers and neurons you add, the more sophisticated the model gets.</p>
<p><img src="/img/main/nnstructure1.png" alt=""></p>
<p>Here for example we have two hidden layers, one with four neurons and one with three neurons. Notice that every neuron of a layer is connected to every neuron of the next layer.</p>
<h4 id="structure-of-a-neuron">STRUCTURE OF A NEURON</h4>
<p>In order to understand how a neural network works in general, we need to understand how the individual neurons work.</p>
<p><img src="/img/main/neuronstructure.png" alt=""></p>
<p>As you can see every neuron gets a certain input, which is either the output of a previous neuron or the raw input of the input layer.
This input is a numerical value and it then gets multiplied by each individual weight (w1, w2, w3…) . 
At the end we then subtract the bias (b) .</p>
<p>The result is the output of that particular connection.</p>
<p>These outputs are that forwarded to the next layer of neurons.</p>
<p>The diagram below shows the neural network for computing the square root of a given number.</p>
<h4 id="activation-functions">ACTIVATION FUNCTIONS</h4>
<p>There are a lot of different so-called activation functions which make everything more complex.
These functions determine the output of a neuron. Basically what we do is: We take the input of our neuron and feed 
the value into an activation function. This function then returns the output value.</p>
<h4 id="sigmoid-activation-function">SIGMOID ACTIVATION FUNCTION</h4>
<p>A commonly used and popular activation function is the so-called sigmoid activation function . 
This function always returns a value between zero and one, no matter what the input is.
The smaller the input, the closer the output will be to zero. The greater the input, the closer the output will be to one.</p>
<p><img src="/img/main/sigmoid.png" alt=""></p>
<p>The mathematical formula looks like this:</p>
<p>$g(z) = \dfrac{1}{1 + e^{-z}}$</p>
<p>Example in Python:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
model <span style="color:#f92672">=</span> Sequential()
<span style="color:#f92672">..</span>
<span style="color:#f92672">..</span>
model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;sigmoid&#39;</span>))
</code></pre></div><p>Example in R:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">keras_model_sequential</span>()

model <span style="color:#f92672">%&gt;%</span> 
    <span style="color:#a6e22e">layer_dense</span>(units <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;sigmoid&#39;</span>, input_shape <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">4</span>)) <span style="color:#f92672">%&gt;%</span> 
    <span style="color:#a6e22e">layer_dense</span>(units <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;softmax&#39;</span>)

Output layer creates <span style="color:#ae81ff">3</span> output values, one for each Iris class. 
The first layer, which contains <span style="color:#ae81ff">8</span> hidden notes, on the other hand, has an input_shape of <span style="color:#ae81ff">4</span>. 
This is because your training data has <span style="color:#ae81ff">4</span> columns.    
</code></pre></div><h4 id="relu-activation-function">RELU ACTIVATION FUNCTION</h4>
<p>The probably most commonly used activation function is the so-called ReLU function . 
This stands for rectified linear unit . This function is very simple but also very useful. Whenever the input value is 
negative, it will return zero. Whenever it is positive, the output will just be the input.</p>
<p><img src="/img/main/relu.png" alt=""></p>
<p>$g(z) = \max(0,z)$</p>
<p>Example in Python:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
(Creates a sequential keras model <span style="color:#f92672">and</span> add an activation function to it)

model <span style="color:#f92672">=</span> Sequential()
<span style="color:#f92672">..</span>
<span style="color:#f92672">..</span>
model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
</code></pre></div><p>Example in R:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">model <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">keras_model_sequential</span>()

(Output layer creates <span style="color:#ae81ff">3</span> output values, one for each class. 
The first layer, which contains <span style="color:#ae81ff">8</span> hidden notes, on the other hand, has an input_shape of <span style="color:#ae81ff">4</span>. 
This is because your training data has <span style="color:#ae81ff">4</span> columns.)

model <span style="color:#f92672">%&gt;%</span> 
    <span style="color:#a6e22e">layer_dense</span>(units <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;relu&#39;</span>, input_shape <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">4</span>)) <span style="color:#f92672">%&gt;%</span> 
    <span style="color:#a6e22e">layer_dense</span>(units <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, activation <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;softmax&#39;</span>)
</code></pre></div><h4 id="types-of-neural-networks">TYPES OF NEURAL NETWORKS</h4>
<p>Neural networks are not only different because of the activation functions of their individual layers. 
There are also different types of layers and networks</p>
<h5 id="feed-forward-neural-networks">FEED FORWARD NEURAL NETWORKS</h5>
<p>The so-called feed forward neural networks could be seen as the classic neural networks. Up until now we have primarily talked about these. 
In this type of network the information only flows into one direction – from the input layer to the output layer. There are no circles or cycles.</p>
<p><img src="/img/main/ffnn.png" alt=""></p>
<h5 id="recurrent-neural-networks">RECURRENT NEURAL NETWORKS</h5>
<p>So-called recurrent neural networks on the other hand work differently. In these networks we have layers with neurons that not only connect 
to the neurons next layer but also to neurons of the previous or of their own layer. This can also be called feedback .If we take the output of a neuron and use it as an input of the same neuron, we are talking about direct feedback . Connecting the output to neurons of the same layer is called lateral feedback . And if we take the output and feed it into neurons of the previous layer, we are talking about indirect feedback
<img src="/img/main/rrnn.png" alt="">
The advantage of such a recurrent neural network is that it has a little memory and doesn’t only take the immediate present data into account. We could say that it “looks back” a couple of iterations.</p>
<p>This kind of neural networks is oftentimes used when the tasks requires the processing of sequential data like text or speech. The feedback is very useful in this kind of tasks. However it is not very useful when dealing with image recognition or image processing.</p>
<h5 id="convolutional-neural-networks">CONVOLUTIONAL NEURAL NETWORKS</h5>
<p>For this purpose we have the so-called convolutional neural networks . This type is primarily used for processing images and sound. It is especially useful when pattern recognition in noisy data is needed. This data may be image data, sound data or video data. It doesn’t matter.</p>
<p><img src="/img/main/cnn.png" alt=""></p>
<p>Let’s look at a simple example above. Here we have multiple Xs and Os as examples in a 16x16 pixels format. Each pixel is an input neuron and will be processed. At the end our neural network shall classify the image as either an X or an O.</p>
<h4 id="summary">SUMMARY</h4>
<ul>
<li>
<p>Activation functions determine the activation of a neuron which then influences the outputs.</p>
</li>
<li>
<p>The classic neural networks are feed forward neural networks. The information only flows into one direction.</p>
</li>
<li>
<p>In recurrent neural networks we work with feedback and it is possible to take the output of future layers as the input of neurons. This creates something like a memory.</p>
</li>
<li>
<p>Convolutional neural networks are primarily used for images, audio data and other data which requires pattern recognition. They split the data into features.</p>
</li>
<li>
<p>Usually we use 80% of the data we have as training data and 20% as testing data.</p>
</li>
<li>
<p>The error indicates how much percent of the data was classified incorrectly.</p>
</li>
<li>
<p>The loss is a numerical value which is calculated with a loss function. This is the value that we want to minimize in order to optimize our model.</p>
</li>
<li>
<p>For the minimization of the output we use the gradient descent algorithm. It finds the local minimum of a function.</p>
</li>
<li>
<p>Backpropagation is the algorithm which calculates the gradient for the gradient descent algorithm. This is done by starting from the output layer and reverse engineering the desired changes.</p>
</li>
</ul>

      <div align = "center">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        
        <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-3804322353139756"
         data-ad-slot="3387213493"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
        <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
        </script>
    </div>            
    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/neural-networks/">Neural Networks</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/neural-networks/">Neural Networks</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    

  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="3a1641e470b07107ff4f74603e67ba45">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/single-layer-perceptron/" class="button left"><span>Single Layer Perceptron</span></a>
    
    
      <a href="/blog/react-native/" class="button right"><span>React Native</span></a>
    
  </div>
  

      </main>
      
<section id="site-sidebar">

  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/handwritten-digit-recognition/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/2021-04-02-HandwrittenDigits.jpg');">
    <img src="https://laxmikants.github.io/img/main/2021-04-02-HandwrittenDigits.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/handwritten-digit-recognition/">Handwritten Digit Recognition</a></h2>
          <time class="published" datetime="2021-04-02 00:00:00 &#43;0000 UTC">April 2, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-29 00:00:00 &#43;0000 UTC">January 29, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/stock-price-technical-analysis/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/logistic-stock-8.jpg');">
    <img src="https://laxmikants.github.io/img/main/logistic-stock-8.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/stock-price-technical-analysis/">Stock Price Technical Analysis</a></h2>
          <time class="published" datetime="2020-12-25 00:00:00 &#43;0000 UTC">December 25, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      

      
    </section>
  

  <div align="center">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      
    <ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3804322353139756"
     data-ad-slot="3115024406"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
    <script>
        $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
    </script>
  </div>
  
  
    
      <section id="categories">
        
   
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/convolutional-neural-networks/">convolutional-neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/handwritten-digit-recognition/">handwritten-digit-recognition<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/mobile-application-development/">mobile-application-development<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-technical-analysis/">stock-technical-analysis<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
        <div align="center">
          <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
          
            <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-3804322353139756"
             data-ad-slot="5736252654"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
          <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
          </script>             
        </div>             
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>about</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    © 2021 Data Science Posts and Resources
      <br>
  </p>
</footer>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/yaml.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.a1ad7ccb559a1034b77cf4c6e6b63e769c07e3433b17bf31cd5d2893c74db6f1.js" integrity="sha256-oa18y1WaEDS3fPTG5rY&#43;dpwH40M7F78xzV0ok8dNtvE="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
  
</html>
