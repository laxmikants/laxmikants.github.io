<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Text analytics - Data Science Posts and Resources :: Laxmikant Soni</title>

<meta name="viewport" content="width=device-width" />

<meta name="google-site-verification" content="MeRcFEBEyWiTb3NfY4THWxbV_fx3rKOJnvr_Jk398wY" />

<meta name=keywords content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics | Laxmikant Soni, Predictive Analytics, Business, Data, Analytics, Machine Learning, Data Mining, Neural Network with Python, Neural Network, Predict Stock price movement using Neural Networks, Intelligence, Big, Modeling, Data Science, Integration, Visualization,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow">

<meta name=description content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics :: Laxmikant Soni">

<meta name="robots" content="index">


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>




<meta name="generator" content="Hugo 0.85.0" /><meta itemprop="name" content="Text analytics">
<meta itemprop="description" content="The analysis of text data gives useful insigths. This post uses news group data set to investigate text data"><meta itemprop="datePublished" content="2020-02-29T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-02-29T00:00:00+00:00" />
<meta itemprop="wordCount" content="1673">
<meta itemprop="keywords" content="Text analytics,nltk," /><meta property="og:title" content="Text analytics" />
<meta property="og:description" content="The analysis of text data gives useful insigths. This post uses news group data set to investigate text data" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/text-analytics/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2020-02-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-02-29T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Text analytics"/>
<meta name="twitter:description" content="The analysis of text data gives useful insigths. This post uses news group data set to investigate text data"/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.aa4e8165f5b2a16460fcb21582ad412bed8e48e9c5dc49f3b412d1703be4d75d.css" integrity="sha256-qk6BZfWyoWRg/LIVgq1BK&#43;2OSOnF3EnztBLRcDvk110="><link rel="stylesheet" href="/css/add-on.css">
        <link rel="stylesheet" href="/css/main.css">

<title>Text analytics : Data Science Posts and Resources</title>

<meta property="og:title" content="Text analytics">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/text-analytics/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="The analysis of text data gives useful insigths. This post uses news group data set to investigate text data">
<meta name="description" content="The analysis of text data gives useful insigths. This post uses news group data set to investigate text data">
<meta property="og:updated_time" content="2020-02-29T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">

<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2020-02-29T00:00:00Z">
<meta property="article:modified_time" content="2020-02-29T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Text analytics",
  "alternativeHeadline": "Text analytics",
  "name" : "Data Science Posts and Resources",
  "url": "https://laxmikants.github.io/blog/text-analytics/",
  "image": "https://laxmikants.github.io/",
  "sameAs":
      [ "https://www.facebook.com/laxmikantsoni09",
        "https://instagram.com/laxmikantsoni09",
        "https://www.linkedin.com/in/laxmikantsoni09",
        "https://twitter.com/laxmikantsoni09",
        "https://github.com/laxmikants",
        "https://www.kaggle.com/laxmikantsoni"
    ],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/text-analytics/"
  },
  "description": "The analysis of text data gives useful insigths. This post uses news group data set to investigate text data",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2020-02-29T00:00:00Z",
  "dateModified": "2020-02-29T00:00:00Z",
  "articleBody": "\r\n\u003cscript src=\"/rmarkdown-libs/header-attrs/header-attrs.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\u003cp\u003eProcessing large amounts text data is an important area in natural language processing. The analysis of text data with machine learning tools can give us important insights. Given a text data such as a book, posts or tweets, one may ask questions such as list of common words.\u003c/p\u003e\r\n\u003cp\u003eIn this post we are going to analyse 20 news groups dataset. The \u003ccode\u003eNewsgroups\u003c/code\u003e dataset comprises around 18000 newsgroups posts on 20 topics. The dataset can by obtained by using \u003ccode\u003efetch_20newsgroups\u003c/code\u003e in \u003ccode\u003esklearn.datasets\u003c/code\u003e as \u003ccode\u003efetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\u003c/code\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e1: First step is to get the dataset and look into it to get understanding about how it is organizedâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom sklearn.datasets import fetch_20newsgroups\r\nnewsgroups_full = fetch_20newsgroups(subset=\u0026#39;all\u0026#39;, remove=(\u0026#39;headers\u0026#39;, \u0026#39;footers\u0026#39;, \u0026#39;quotes\u0026#39;), shuffle=True, random_state=42)\r\nprint(newsgroups_full.keys())\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## dict_keys([\u0026#39;data\u0026#39;, \u0026#39;filenames\u0026#39;, \u0026#39;target_names\u0026#39;, \u0026#39;target\u0026#39;, \u0026#39;DESCR\u0026#39;])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe \u003ccode\u003enewsgroups_full\u003c/code\u003e dataset has properties and function such as \u003ccode\u003ekeys()\u003c/code\u003e which important keys for fetching the details of different types.\r\nFor example \u003ccode\u003etarget_names\u003c/code\u003e specifies various names of the newsgroups, \u003ccode\u003etarget\u003c/code\u003e is 20 different unique index corresponding to target_names\r\nthe key \u003ccode\u003edata\u003c/code\u003e is used to get actual data stored in different files having some \u003ccode\u003efilenames\u003c/code\u003e. Lets see how go use different \u003ccode\u003ekeys\u003c/code\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e# The target names are the names of the news groups\r\nprint(newsgroups_full.target_names)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## [\u0026#39;alt.atheism\u0026#39;, \u0026#39;comp.graphics\u0026#39;, \u0026#39;comp.os.ms-windows.misc\u0026#39;, \u0026#39;comp.sys.ibm.pc.hardware\u0026#39;, \u0026#39;comp.sys.mac.hardware\u0026#39;, \u0026#39;comp.windows.x\u0026#39;, \u0026#39;misc.forsale\u0026#39;, \u0026#39;rec.autos\u0026#39;, \u0026#39;rec.motorcycles\u0026#39;, \u0026#39;rec.sport.baseball\u0026#39;, \u0026#39;rec.sport.hockey\u0026#39;, \u0026#39;sci.crypt\u0026#39;, \u0026#39;sci.electronics\u0026#39;, \u0026#39;sci.med\u0026#39;, \u0026#39;sci.space\u0026#39;, \u0026#39;soc.religion.christian\u0026#39;, \u0026#39;talk.politics.guns\u0026#39;, \u0026#39;talk.politics.mideast\u0026#39;, \u0026#39;talk.politics.misc\u0026#39;, \u0026#39;talk.religion.misc\u0026#39;]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e# The data is actual data stred as list\r\nprint(newsgroups_full.target_names[newsgroups_full.target[1]])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## comp.sys.ibm.pc.hardware\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eprint(newsgroups_full.data[1])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## My brother is in the market for a high-performance video card that supports\r\n## VESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\r\n## \r\n##   - Diamond Stealth Pro Local Bus\r\n## \r\n##   - Orchid Farenheit 1280\r\n## \r\n##   - ATI Graphics Ultra Pro\r\n## \r\n##   - Any other high-performance VLB card\r\n## \r\n## \r\n## Please post or email.  Thank you!\r\n## \r\n##   - Matt\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eAs we can se the above two statements give us the data about \u003ccode\u003epost\u003c/code\u003e belonging to \u003ccode\u003ecomp.sys.ibm.pc.hardware\u003c/code\u003e which contains:\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e\r\n# Putting the words in the dictionary\r\n\r\nnewsgroups_full_dnry = dict()\r\nfor ind in range(len(newsgroups_full.data)):\r\n    grp_name = newsgroups_full.target_names[newsgroups_full.target[ind]]\r\n    if grp_name in newsgroups_full_dnry:\r\n        newsgroups_full_dnry[grp_name] += 1\r\n    else:\r\n        newsgroups_full_dnry[grp_name] = 1\r\nprint(\u0026quot;Total number of articles in dataset \u0026quot; + str(len(newsgroups_full.data)))        \u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Total number of articles in dataset 18846\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eprint(\u0026quot;Number of articles category wise: \u0026quot;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Number of articles category wise:\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eprint(newsgroups_full_dnry)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## {\u0026#39;rec.sport.hockey\u0026#39;: 999, \u0026#39;comp.sys.ibm.pc.hardware\u0026#39;: 982, \u0026#39;talk.politics.mideast\u0026#39;: 940, \u0026#39;comp.sys.mac.hardware\u0026#39;: 963, \u0026#39;sci.electronics\u0026#39;: 984, \u0026#39;talk.religion.misc\u0026#39;: 628, \u0026#39;sci.crypt\u0026#39;: 991, \u0026#39;sci.med\u0026#39;: 990, \u0026#39;alt.atheism\u0026#39;: 799, \u0026#39;rec.motorcycles\u0026#39;: 996, \u0026#39;rec.autos\u0026#39;: 990, \u0026#39;comp.windows.x\u0026#39;: 988, \u0026#39;comp.graphics\u0026#39;: 973, \u0026#39;sci.space\u0026#39;: 987, \u0026#39;talk.politics.guns\u0026#39;: 910, \u0026#39;misc.forsale\u0026#39;: 975, \u0026#39;rec.sport.baseball\u0026#39;: 994, \u0026#39;talk.politics.misc\u0026#39;: 775, \u0026#39;comp.os.ms-windows.misc\u0026#39;: 985, \u0026#39;soc.religion.christian\u0026#39;: 997}\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003ePie chart of distribution of the articles\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport matplotlib.pyplot as plt\r\n\r\n\r\nlabels = newsgroups_full.target_names\r\n\r\nslices = []\r\n\r\nfor key in newsgroups_full_dnry:\r\n    slices.append(newsgroups_full_dnry[key])\r\n    \r\nfig , ax = plt.subplots()\r\n\r\nax.pie(slices, labels = labels , autopct = \u0026#39;%1.1f%%\u0026#39;, shadow = True, startangle = 90)\r\n\r\nax.axis(\u0026quot;equal\u0026quot;)\r\nax.set_title(\u0026quot;News groups messages distribution\u0026quot;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/ngpie.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThe distribution of messages posted in different newsgroups is almost similar. The sports groups have most number of messages\u003c/p\u003e\r\n\u003cp\u003eViewing the data as tabular form. We can put the data in the dataframe and see the top ten records\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport pandas as pd\r\ndata_labels_map = dict(enumerate(newsgroups_full.target_names))\r\nmessage, target_labels, target_names = (newsgroups_full.data, newsgroups_full.target, [data_labels_map[label] for label in newsgroups_full.target])\r\nnewsgroups_full_df = pd.DataFrame({\u0026#39;text\u0026#39;: message, \u0026#39;source\u0026#39;: target_labels, \u0026#39;source_name\u0026#39;: target_names})\r\nprint(newsgroups_full_df.shape)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## (18846, 3)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003enewsgroups_full_df.head(10)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##                                                 text  ...               source_name\r\n## 0  \\n\\nI am sure some bashers of Pens fans are pr...  ...          rec.sport.hockey\r\n## 1  My brother is in the market for a high-perform...  ...  comp.sys.ibm.pc.hardware\r\n## 2  \\n\\n\\n\\n\\tFinally you said what you dream abou...  ...     talk.politics.mideast\r\n## 3  \\nThink!\\n\\nIt\u0026#39;s the SCSI card doing the DMA t...  ...  comp.sys.ibm.pc.hardware\r\n## 4  1)    I have an old Jasmine drive which I cann...  ...     comp.sys.mac.hardware\r\n## 5  \\n\\nBack in high school I worked as a lab assi...  ...           sci.electronics\r\n## 6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...  ...     comp.sys.mac.hardware\r\n## 7  \\n[stuff deleted]\\n\\nOk, here\u0026#39;s the solution t...  ...          rec.sport.hockey\r\n## 8  \\n\\n\\nYeah, it\u0026#39;s the second one.  And I believ...  ...          rec.sport.hockey\r\n## 9  \\nIf a Christian means someone who believes in...  ...        talk.religion.misc\r\n## \r\n## [10 rows x 3 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e2: Next step is cleaning the textâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eTo clean the large amounts of text we use \u003ccode\u003enltk\u003c/code\u003e tools such as \u003ccode\u003eWordNetLemmatizer\u003c/code\u003e, \u003ccode\u003ePorterStemmer\u003c/code\u003e, \u003ccode\u003estopwords\u003c/code\u003e, \u003ccode\u003enames\u003c/code\u003e.\r\nLets import them first\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eimport nltk\r\nfrom nltk.corpus import names\r\nfrom nltk.stem import WordNetLemmatizer\r\nfrom nltk.stem import PorterStemmer\r\nfrom nltk.corpus import stopwords\r\nfrom nltk.tokenize import word_tokenize\r\nimport re\r\n\r\nstopWords = set(stopwords.words(\u0026#39;english\u0026#39;))\r\nvalidwords = set(nltk.corpus.words.words())\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ccode\u003ere\u003c/code\u003e is regular expression library in python. We need to first define few functions such as \u003ccode\u003etext_tokenizer\u003c/code\u003e. The main aim is to clean the posts first by removing the alpha-numeric, numeric and non-alphabatic characters then by applying \u003ccode\u003estemming\u003c/code\u003e and \u003ccode\u003elemmmatizing\u003c/code\u003e techiniques so that we are left with only the words which are meaningful for the analysis. Lets write the functions for the same\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eporter_stemmer = PorterStemmer()\r\nlemmatizer = WordNetLemmatizer()\r\ndef text_tokenizer(str_input):\r\n    words = re.sub(r\u0026quot;[^A-Za-z\\-]\u0026quot;, \u0026quot; \u0026quot;, str_input).lower().split()\r\n    words = [porter_stemmer.stem(word) for word in words if len(word) \u0026gt; 2 ]\r\n    words = [lemmatizer.lemmatize(word) for word in words if len(word) \u0026gt; 2 and word in validwords and word not in stopWords]\r\n    return \u0026#39; \u0026#39;.join(words)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e2.1: Next is to apply \u003ccode\u003etext_tokenizer\u003c/code\u003e function to get a new column having clean textâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003enewsgroups_full_df[\u0026#39;clean_text\u0026#39;] = newsgroups_full_df.text.apply(lambda x: text_tokenizer(x))\r\nnewsgroups_full_df.sort_values(by=[\u0026#39;source\u0026#39;],inplace=True)\r\nnewsgroups_full_df.head(5)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##                                                     text  ...                                         clean_text\r\n## 8501   \\nI could give much the same testimonial about...  ...  could give much scout back gay thank well put ...\r\n## 14285  \\nFine... THE ILLIAD IS THE WORD OF GOD(tm)  (...  ...              fine word god matter prove wrong west\r\n## 17533  Hello Gang,\\n\\nThere have been some notes rece...  ...  hello gang note recent ask obtain fish questio...\r\n## 1527   \\n  Sorry, gotta disagree with you on this one...  ...  one bill prefer half bake bob vice said queen ...\r\n## 14271  The latest news seems to be that Koresh will g...  ...          latest news seem give finish write sequel\r\n## \r\n## [5 rows x 4 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e2.3:Creating a dictionary of newsgroup cleaned text\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003ewordlst = list()\r\nnewsgroup_dic = dict()\r\nlabel = \u0026#39;\u0026#39;\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efor i in range(0,20):\r\n    newsgroups_full_df_1 = newsgroups_full_df.loc[newsgroups_full_df[\u0026#39;source\u0026#39;] == i]\r\n    for row in newsgroups_full_df_1[[\u0026#39;source_name\u0026#39;, \u0026#39;clean_text\u0026#39;]].iterrows():\r\n        r = row[1]\r\n        label = r.source_name\r\n        wordlst.append(\u0026#39;\u0026#39;.join(map(str,r.clean_text)))\r\n        wordstr = \u0026#39; \u0026#39;.join(map(str, wordlst))\r\n    newsgroup_dic[label] = wordstr\r\n    label = \u0026#39;\u0026#39;\r\n    wordstr = \u0026#39;\u0026#39;\r\n    wordlst.clear() \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNext steps will create the features out of the dictionary of the newsgroups words just created in the previous steps. In natural language processing feature extraction is an important step. In this case the words themselves becomes the features. To extract the features python provides an important library called \u003ccode\u003eCountVectorizer\u003c/code\u003e. We need to transform our \u003ccode\u003ecleaned_text\u003c/code\u003e using \u003ccode\u003esklearn.feature_extraction.text\u003c/code\u003e and \u003ccode\u003eCountVectorizer\u003c/code\u003e library. Lets apply it to our newsgroup data.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e3: Feature extractionâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eThe feature vector can be created with \u003ccode\u003esklearn\u003c/code\u003e \u003ccode\u003eCountVectorizer\u003c/code\u003e. When creating the feature vectors we can decide the number of features, as well as set limits for the minimum and maximum number of documents a word can appear.\u003c/p\u003e\r\n\u003cp\u003eNote that the transformed data is stored in a \u003ccode\u003esparse matrix\u003c/code\u003e (which is much more efficient for large data sets).\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e# First lets import it\r\nfrom  sklearn.feature_extraction.text import CountVectorizer\r\ncount_vectorizer = CountVectorizer(stop_words = \u0026#39;english\u0026#39;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe function \u003ccode\u003eget_word_freq_dict_sorted\u003c/code\u003e returns a sorted dictionary of words counts. It taks a dataframe as its argument.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003edef get_word_freq_dict_sorted(ng_X_df):\r\n    wordfreq = ng_X_df.sum(axis=0)\r\n    features = ng_X_df.columns.tolist()\r\n    counts = wordfreq.tolist()\r\n    wordfreq_df = pd.DataFrame()\r\n    wordfreq_df[\u0026#39;word\u0026#39;] = features\r\n    wordfreq_df[\u0026#39;count\u0026#39;] = counts\r\n    wordfreq_dict = dict(wordfreq_df.values.tolist())\r\n    wordfreqdict_sorted = dict(sorted(wordfreq_dict.items(), key=lambda x: x[1],reverse=True))\r\n    return wordfreqdict_sorted\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNow iterate over the newsgroup dictionary obtained from the newsgroups dataframe and create another dictionary where keys are the newsgroups and values are another dictionary of word counts in that newsgroup.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eng_dict_of_words = dict()\r\n\r\nfor key in newsgroup_dic:\r\n    ng_X = count_vectorizer.fit_transform([newsgroup_dic[key]])\r\n    ng_X_df = pd.DataFrame(ng_X.toarray(), columns=count_vectorizer.get_feature_names())\r\n    ng_dict_of_words[key] = get_word_freq_dict_sorted(ng_X_df)\r\n    \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e4: Exploring words in the news groups..\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eQUESTION: What are the top words in newsgroup \u003ccode\u003ecomp.sys.ibm.pc.hardware\u003c/code\u003e by their count ?\u003c/p\u003e\r\n\u003cp\u003eANSWER: Iterating over the dictionary corresponding to \u003ccode\u003ecomp.sys.ibm.pc.hardware\u003c/code\u003e we get the top ten words as {space orbit launch use like time mission year earth moon}. Like wise we get the most common words in each newsgroup by their count.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eword_dic = ng_dict_of_words[\u0026#39;comp.sys.ibm.pc.hardware\u0026#39;] \r\nword_df = pd.DataFrame.from_dict(word_dic, orient=\u0026#39;index\u0026#39;)\r\nprint(word_df.T.iloc[0:1,0:10])\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##    drive  use  card  ani  control  disk  work  problem  know  ide\r\n## 0    990  792   537  476      441   384   369      356   333  309\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eVarious other approaches to explore words in news groups include graphical methods, which help us visualize the distribution of words across news groups. We can use \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e to draw differnt graphs.\u003c/p\u003e\r\n\u003cp\u003eNext we will explore various algorithms for text classification.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e5 Text Classificationâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eText classification is done using various machine learning algorithms. The most popular ones are\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eMultinomialNB\u003c/li\u003e\r\n\u003cli\u003eLogisticRegression\u003c/li\u003e\r\n\u003cli\u003eSVC\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eThe goal of the \u003ccode\u003etext classification\u003c/code\u003e is to predict which newsgroup a post belongs to based on the post text.\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eBOW\u003c/code\u003e and \u003ccode\u003eTF-IDF\u003c/code\u003e are two different techniques for text classification\u003c/p\u003e\r\n\u003cp\u003eBag of Words (BoW) is an algorithm that counts frequency of a word in newsgroups. Those word counts allow us to compare different newsgroups and gauge their similarities for applications like search, topic modeling etc.\u003c/p\u003e\r\n\u003cp\u003eIn \u003ccode\u003eTF-IDF\u003c/code\u003e, words are given weight. TF-IDF measures relevance, not frequency. That is, wordcounts are replaced with TF-IDF scores across the whole dataset.\u003c/p\u003e\r\n\u003cp\u003eTo use text classification algorithm we need to randomly separates data into training and testing dataset and \u003ccode\u003efit\u003c/code\u003e the classifier with selected training data. A \u003ccode\u003eclassifer\u003c/code\u003e defines model for text classification. The \u003ccode\u003escore\u003c/code\u003e gives us the accuracy for testing data.\u003c/p\u003e\r\n\u003cp\u003eDifferent classifiers can give us different results for accuracy. Accuracy depends on the specific problem, number of categories and differences between them, etc.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e6 Evaluationâ€¦\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\r\n\u003cp\u003eEvaluation of the model can be done using the confusion matrix which can be ploted using the heatmap plot. A basic heatmap is shown below\u003c/p\u003e\r\n\u003cdiv class=\"figure\"\u003e\r\n\u003cimg src=\"/img/main/newgroupsheatmap.png\" alt=\"\" /\u003e\r\n\u003cp class=\"caption\"\u003enewgroupsheatmap.png\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cp\u003eThe confusion matrix depicts the wrongly classified records. For example 4 articles from comp.graphics are wrongly classified as comp.windows.x.\u003c/p\u003e\r\n\u003cp\u003e***7 Slide show\u003c/p\u003e\r\n\u003cpre class=\"r\"\u003e\u003ccode\u003eknitr::include_url(\u0026#39;/slides/NewsGroupsAnalysis.html\u0026#39;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003ciframe src=\"/slides/NewsGroupsAnalysis.html\" width=\"672\" height=\"400px\"\u003e\r\n\u003c/iframe\u003e\r\n\u003cp\u003e\u003ccode\u003eSummary:\u003c/code\u003e Text classifcation has usefull applications in detection of spam pages, personal email sorting, tagging products or document filtering, automatic classification of the text based on its contents, sentiment analysis etc. There are different methods and models availble in \u003ccode\u003esklearn\u003c/code\u003e and \u003ccode\u003enltp\u003c/code\u003e libraries in python which can be utilized for text classification and natural language processing applications.\u003c/p\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  
</head>
  <body>
    
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5KFS4C"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
      
    


<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
        
          
          <a href="/contact/" class="nav link"><i class='far fa-envelope'></i> Contact</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
 
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  
  
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu">
  </div></menu>
  
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Text%20analytics&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f&amp;title=Text%20analytics" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </menu>
  
</header>

      
    <div id="wrapper">
    
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    <p>Articles on Data Science</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>



      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/text-analytics/">Text analytics</a></h2>
    
    
      <p>The analysis of text data gives useful insigths. This post uses news group data set to investigate text data</p>
    
  </div>
  <div class="meta">
    <time datetime="2020-02-29 00:00:00 &#43;0000 UTC">February 29, 2020</time>
    <p>Laxmi K Soni</p>
    <p>8-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Text%20analytics&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2ftext-analytics%2f&amp;title=Text%20analytics" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </div>
      <div class="content">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      
      <ins class="adsbygoogle"
           style="display:block"
           data-ad-client="ca-pub-3804322353139756"
           data-ad-slot="1652057437"
           data-ad-format="auto"
           data-full-width-responsive="false"></ins>
      <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
      </script>
      </div>
    <div class="content">
      <a href="/blog/text-analytics/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/text-analytics06.jpg');">
    <img src="https://laxmikants.github.io/img/main/text-analytics06.jpg" alt="">
  </a>
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Processing large amounts text data is an important area in natural language processing. The analysis of text data with machine learning tools can give us important insights. Given a text data such as a book, posts or tweets, one may ask questions such as list of common words.</p>
<p>In this post we are going to analyse 20 news groups dataset. The <code>Newsgroups</code> dataset comprises around 18000 newsgroups posts on 20 topics. The dataset can by obtained by using <code>fetch_20newsgroups</code> in <code>sklearn.datasets</code> as <code>fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)</code></p>
<p><strong><em>1: First step is to get the dataset and look into it to get understanding about how it is organizedâ€¦</em></strong></p>
<pre class="python"><code>from sklearn.datasets import fetch_20newsgroups
newsgroups_full = fetch_20newsgroups(subset=&#39;all&#39;, remove=(&#39;headers&#39;, &#39;footers&#39;, &#39;quotes&#39;), shuffle=True, random_state=42)
print(newsgroups_full.keys())</code></pre>
<pre><code>## dict_keys([&#39;data&#39;, &#39;filenames&#39;, &#39;target_names&#39;, &#39;target&#39;, &#39;DESCR&#39;])</code></pre>
<p>The <code>newsgroups_full</code> dataset has properties and function such as <code>keys()</code> which important keys for fetching the details of different types.
For example <code>target_names</code> specifies various names of the newsgroups, <code>target</code> is 20 different unique index corresponding to target_names
the key <code>data</code> is used to get actual data stored in different files having some <code>filenames</code>. Lets see how go use different <code>keys</code></p>
<pre class="python"><code># The target names are the names of the news groups
print(newsgroups_full.target_names)</code></pre>
<pre><code>## [&#39;alt.atheism&#39;, &#39;comp.graphics&#39;, &#39;comp.os.ms-windows.misc&#39;, &#39;comp.sys.ibm.pc.hardware&#39;, &#39;comp.sys.mac.hardware&#39;, &#39;comp.windows.x&#39;, &#39;misc.forsale&#39;, &#39;rec.autos&#39;, &#39;rec.motorcycles&#39;, &#39;rec.sport.baseball&#39;, &#39;rec.sport.hockey&#39;, &#39;sci.crypt&#39;, &#39;sci.electronics&#39;, &#39;sci.med&#39;, &#39;sci.space&#39;, &#39;soc.religion.christian&#39;, &#39;talk.politics.guns&#39;, &#39;talk.politics.mideast&#39;, &#39;talk.politics.misc&#39;, &#39;talk.religion.misc&#39;]</code></pre>
<pre class="python"><code># The data is actual data stred as list
print(newsgroups_full.target_names[newsgroups_full.target[1]])</code></pre>
<pre><code>## comp.sys.ibm.pc.hardware</code></pre>
<pre class="python"><code>print(newsgroups_full.data[1])</code></pre>
<pre><code>## My brother is in the market for a high-performance video card that supports
## VESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:
## 
##   - Diamond Stealth Pro Local Bus
## 
##   - Orchid Farenheit 1280
## 
##   - ATI Graphics Ultra Pro
## 
##   - Any other high-performance VLB card
## 
## 
## Please post or email.  Thank you!
## 
##   - Matt</code></pre>
<p>As we can se the above two statements give us the data about <code>post</code> belonging to <code>comp.sys.ibm.pc.hardware</code> which contains:</p>
<pre class="python"><code>
# Putting the words in the dictionary

newsgroups_full_dnry = dict()
for ind in range(len(newsgroups_full.data)):
    grp_name = newsgroups_full.target_names[newsgroups_full.target[ind]]
    if grp_name in newsgroups_full_dnry:
        newsgroups_full_dnry[grp_name] += 1
    else:
        newsgroups_full_dnry[grp_name] = 1
print(&quot;Total number of articles in dataset &quot; + str(len(newsgroups_full.data)))        </code></pre>
<pre><code>## Total number of articles in dataset 18846</code></pre>
<pre class="python"><code>print(&quot;Number of articles category wise: &quot;)</code></pre>
<pre><code>## Number of articles category wise:</code></pre>
<pre class="python"><code>print(newsgroups_full_dnry)</code></pre>
<pre><code>## {&#39;rec.sport.hockey&#39;: 999, &#39;comp.sys.ibm.pc.hardware&#39;: 982, &#39;talk.politics.mideast&#39;: 940, &#39;comp.sys.mac.hardware&#39;: 963, &#39;sci.electronics&#39;: 984, &#39;talk.religion.misc&#39;: 628, &#39;sci.crypt&#39;: 991, &#39;sci.med&#39;: 990, &#39;alt.atheism&#39;: 799, &#39;rec.motorcycles&#39;: 996, &#39;rec.autos&#39;: 990, &#39;comp.windows.x&#39;: 988, &#39;comp.graphics&#39;: 973, &#39;sci.space&#39;: 987, &#39;talk.politics.guns&#39;: 910, &#39;misc.forsale&#39;: 975, &#39;rec.sport.baseball&#39;: 994, &#39;talk.politics.misc&#39;: 775, &#39;comp.os.ms-windows.misc&#39;: 985, &#39;soc.religion.christian&#39;: 997}</code></pre>
<p>Pie chart of distribution of the articles</p>
<pre class="python"><code>import matplotlib.pyplot as plt


labels = newsgroups_full.target_names

slices = []

for key in newsgroups_full_dnry:
    slices.append(newsgroups_full_dnry[key])
    
fig , ax = plt.subplots()

ax.pie(slices, labels = labels , autopct = &#39;%1.1f%%&#39;, shadow = True, startangle = 90)

ax.axis(&quot;equal&quot;)
ax.set_title(&quot;News groups messages distribution&quot;)</code></pre>
<p><img src="/img/main/ngpie.png" /></p>
<p>The distribution of messages posted in different newsgroups is almost similar. The sports groups have most number of messages</p>
<p>Viewing the data as tabular form. We can put the data in the dataframe and see the top ten records</p>
<pre class="python"><code>import pandas as pd
data_labels_map = dict(enumerate(newsgroups_full.target_names))
message, target_labels, target_names = (newsgroups_full.data, newsgroups_full.target, [data_labels_map[label] for label in newsgroups_full.target])
newsgroups_full_df = pd.DataFrame({&#39;text&#39;: message, &#39;source&#39;: target_labels, &#39;source_name&#39;: target_names})
print(newsgroups_full_df.shape)</code></pre>
<pre><code>## (18846, 3)</code></pre>
<pre class="python"><code>newsgroups_full_df.head(10)</code></pre>
<pre><code>##                                                 text  ...               source_name
## 0  \n\nI am sure some bashers of Pens fans are pr...  ...          rec.sport.hockey
## 1  My brother is in the market for a high-perform...  ...  comp.sys.ibm.pc.hardware
## 2  \n\n\n\n\tFinally you said what you dream abou...  ...     talk.politics.mideast
## 3  \nThink!\n\nIt&#39;s the SCSI card doing the DMA t...  ...  comp.sys.ibm.pc.hardware
## 4  1)    I have an old Jasmine drive which I cann...  ...     comp.sys.mac.hardware
## 5  \n\nBack in high school I worked as a lab assi...  ...           sci.electronics
## 6  \n\nAE is in Dallas...try 214/241-6060 or 214/...  ...     comp.sys.mac.hardware
## 7  \n[stuff deleted]\n\nOk, here&#39;s the solution t...  ...          rec.sport.hockey
## 8  \n\n\nYeah, it&#39;s the second one.  And I believ...  ...          rec.sport.hockey
## 9  \nIf a Christian means someone who believes in...  ...        talk.religion.misc
## 
## [10 rows x 3 columns]</code></pre>
<p><strong><em>2: Next step is cleaning the textâ€¦</em></strong></p>
<p>To clean the large amounts of text we use <code>nltk</code> tools such as <code>WordNetLemmatizer</code>, <code>PorterStemmer</code>, <code>stopwords</code>, <code>names</code>.
Lets import them first</p>
<pre class="python"><code>import nltk
from nltk.corpus import names
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re

stopWords = set(stopwords.words(&#39;english&#39;))
validwords = set(nltk.corpus.words.words())</code></pre>
<p><code>re</code> is regular expression library in python. We need to first define few functions such as <code>text_tokenizer</code>. The main aim is to clean the posts first by removing the alpha-numeric, numeric and non-alphabatic characters then by applying <code>stemming</code> and <code>lemmmatizing</code> techiniques so that we are left with only the words which are meaningful for the analysis. Lets write the functions for the same</p>
<pre class="python"><code>porter_stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
def text_tokenizer(str_input):
    words = re.sub(r&quot;[^A-Za-z\-]&quot;, &quot; &quot;, str_input).lower().split()
    words = [porter_stemmer.stem(word) for word in words if len(word) &gt; 2 ]
    words = [lemmatizer.lemmatize(word) for word in words if len(word) &gt; 2 and word in validwords and word not in stopWords]
    return &#39; &#39;.join(words)</code></pre>
<p><strong><em>2.1: Next is to apply <code>text_tokenizer</code> function to get a new column having clean textâ€¦</em></strong></p>
<pre class="python"><code>newsgroups_full_df[&#39;clean_text&#39;] = newsgroups_full_df.text.apply(lambda x: text_tokenizer(x))
newsgroups_full_df.sort_values(by=[&#39;source&#39;],inplace=True)
newsgroups_full_df.head(5)</code></pre>
<pre><code>##                                                     text  ...                                         clean_text
## 8501   \nI could give much the same testimonial about...  ...  could give much scout back gay thank well put ...
## 14285  \nFine... THE ILLIAD IS THE WORD OF GOD(tm)  (...  ...              fine word god matter prove wrong west
## 17533  Hello Gang,\n\nThere have been some notes rece...  ...  hello gang note recent ask obtain fish questio...
## 1527   \n  Sorry, gotta disagree with you on this one...  ...  one bill prefer half bake bob vice said queen ...
## 14271  The latest news seems to be that Koresh will g...  ...          latest news seem give finish write sequel
## 
## [5 rows x 4 columns]</code></pre>
<p><strong><em>2.3:Creating a dictionary of newsgroup cleaned text</em></strong></p>
<pre class="python"><code>wordlst = list()
newsgroup_dic = dict()
label = &#39;&#39;</code></pre>
<pre class="python"><code>for i in range(0,20):
    newsgroups_full_df_1 = newsgroups_full_df.loc[newsgroups_full_df[&#39;source&#39;] == i]
    for row in newsgroups_full_df_1[[&#39;source_name&#39;, &#39;clean_text&#39;]].iterrows():
        r = row[1]
        label = r.source_name
        wordlst.append(&#39;&#39;.join(map(str,r.clean_text)))
        wordstr = &#39; &#39;.join(map(str, wordlst))
    newsgroup_dic[label] = wordstr
    label = &#39;&#39;
    wordstr = &#39;&#39;
    wordlst.clear() </code></pre>
<p>Next steps will create the features out of the dictionary of the newsgroups words just created in the previous steps. In natural language processing feature extraction is an important step. In this case the words themselves becomes the features. To extract the features python provides an important library called <code>CountVectorizer</code>. We need to transform our <code>cleaned_text</code> using <code>sklearn.feature_extraction.text</code> and <code>CountVectorizer</code> library. Lets apply it to our newsgroup data.</p>
<p><strong><em>3: Feature extractionâ€¦</em></strong></p>
<p>The feature vector can be created with <code>sklearn</code> <code>CountVectorizer</code>. When creating the feature vectors we can decide the number of features, as well as set limits for the minimum and maximum number of documents a word can appear.</p>
<p>Note that the transformed data is stored in a <code>sparse matrix</code> (which is much more efficient for large data sets).</p>
<pre class="python"><code># First lets import it
from  sklearn.feature_extraction.text import CountVectorizer
count_vectorizer = CountVectorizer(stop_words = &#39;english&#39;)</code></pre>
<p>The function <code>get_word_freq_dict_sorted</code> returns a sorted dictionary of words counts. It taks a dataframe as its argument.</p>
<pre class="python"><code>def get_word_freq_dict_sorted(ng_X_df):
    wordfreq = ng_X_df.sum(axis=0)
    features = ng_X_df.columns.tolist()
    counts = wordfreq.tolist()
    wordfreq_df = pd.DataFrame()
    wordfreq_df[&#39;word&#39;] = features
    wordfreq_df[&#39;count&#39;] = counts
    wordfreq_dict = dict(wordfreq_df.values.tolist())
    wordfreqdict_sorted = dict(sorted(wordfreq_dict.items(), key=lambda x: x[1],reverse=True))
    return wordfreqdict_sorted</code></pre>
<p>Now iterate over the newsgroup dictionary obtained from the newsgroups dataframe and create another dictionary where keys are the newsgroups and values are another dictionary of word counts in that newsgroup.</p>
<pre class="python"><code>ng_dict_of_words = dict()

for key in newsgroup_dic:
    ng_X = count_vectorizer.fit_transform([newsgroup_dic[key]])
    ng_X_df = pd.DataFrame(ng_X.toarray(), columns=count_vectorizer.get_feature_names())
    ng_dict_of_words[key] = get_word_freq_dict_sorted(ng_X_df)
    </code></pre>
<p><strong><em>4: Exploring words in the news groups..</em></strong></p>
<p>QUESTION: What are the top words in newsgroup <code>comp.sys.ibm.pc.hardware</code> by their count ?</p>
<p>ANSWER: Iterating over the dictionary corresponding to <code>comp.sys.ibm.pc.hardware</code> we get the top ten words as {space orbit launch use like time mission year earth moon}. Like wise we get the most common words in each newsgroup by their count.</p>
<pre class="python"><code>word_dic = ng_dict_of_words[&#39;comp.sys.ibm.pc.hardware&#39;] 
word_df = pd.DataFrame.from_dict(word_dic, orient=&#39;index&#39;)
print(word_df.T.iloc[0:1,0:10])</code></pre>
<pre><code>##    drive  use  card  ani  control  disk  work  problem  know  ide
## 0    990  792   537  476      441   384   369      356   333  309</code></pre>
<p>Various other approaches to explore words in news groups include graphical methods, which help us visualize the distribution of words across news groups. We can use <code>matplotlib.pyplot</code> to draw differnt graphs.</p>
<p>Next we will explore various algorithms for text classification.</p>
<p><strong><em>5 Text Classificationâ€¦</em></strong></p>
<p>Text classification is done using various machine learning algorithms. The most popular ones are</p>
<ul>
<li>MultinomialNB</li>
<li>LogisticRegression</li>
<li>SVC</li>
</ul>
<p>The goal of the <code>text classification</code> is to predict which newsgroup a post belongs to based on the post text.</p>
<p><code>BOW</code> and <code>TF-IDF</code> are two different techniques for text classification</p>
<p>Bag of Words (BoW) is an algorithm that counts frequency of a word in newsgroups. Those word counts allow us to compare different newsgroups and gauge their similarities for applications like search, topic modeling etc.</p>
<p>In <code>TF-IDF</code>, words are given weight. TF-IDF measures relevance, not frequency. That is, wordcounts are replaced with TF-IDF scores across the whole dataset.</p>
<p>To use text classification algorithm we need to randomly separates data into training and testing dataset and <code>fit</code> the classifier with selected training data. A <code>classifer</code> defines model for text classification. The <code>score</code> gives us the accuracy for testing data.</p>
<p>Different classifiers can give us different results for accuracy. Accuracy depends on the specific problem, number of categories and differences between them, etc.</p>
<p><strong><em>6 Evaluationâ€¦</em></strong></p>
<p>Evaluation of the model can be done using the confusion matrix which can be ploted using the heatmap plot. A basic heatmap is shown below</p>
<div class="figure">
<img src="/img/main/newgroupsheatmap.png" alt="" />
<p class="caption">newgroupsheatmap.png</p>
</div>
<p>The confusion matrix depicts the wrongly classified records. For example 4 articles from comp.graphics are wrongly classified as comp.windows.x.</p>
<p>***7 Slide show</p>
<pre class="r"><code>knitr::include_url(&#39;/slides/NewsGroupsAnalysis.html&#39;)</code></pre>
<iframe src="/slides/NewsGroupsAnalysis.html" width="672" height="400px">
</iframe>
<p><code>Summary:</code> Text classifcation has usefull applications in detection of spam pages, personal email sorting, tagging products or document filtering, automatic classification of the text based on its contents, sentiment analysis etc. There are different methods and models availble in <code>sklearn</code> and <code>nltp</code> libraries in python which can be utilized for text classification and natural language processing applications.</p>

      <div align = "center">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        
        <ins class="adsbygoogle"
         style="display:block"
         data-ad-client="ca-pub-3804322353139756"
         data-ad-slot="3387213493"
         data-ad-format="auto"
         data-full-width-responsive="true"></ins>
        <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
        </script>
    </div>            
    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/text-analytics/">Text analytics</a></li>
        
          <li><a class="article-terms-link" href="/categories/natural-language-processing/">Natural language processing</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/text-analytics/">Text analytics</a></li>
        
          <li><a class="article-terms-link" href="/tags/nltk/">nltk</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    

  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="29fa154fe43dd91f0f625378c72109a6">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/time-series/" class="button left"><span>Time-Series Forecasting</span></a>
    
    
      <a href="/blog/eda-with-iris-dataset/" class="button right"><span>EDA with Iris dataset</span></a>
    
  </div>
  

      </main>
      
<section id="site-sidebar">

  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/handwritten-digit-recognition/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/2021-04-02-HandwrittenDigits.jpg');">
    <img src="https://laxmikants.github.io/img/main/2021-04-02-HandwrittenDigits.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/handwritten-digit-recognition/">Handwritten Digit Recognition</a></h2>
          <time class="published" datetime="2021-04-02 00:00:00 &#43;0000 UTC">April 2, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-29 00:00:00 &#43;0000 UTC">January 29, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/stock-price-technical-analysis/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/logistic-stock-8.jpg');">
    <img src="https://laxmikants.github.io/img/main/logistic-stock-8.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/stock-price-technical-analysis/">Stock Price Technical Analysis</a></h2>
          <time class="published" datetime="2020-12-25 00:00:00 &#43;0000 UTC">December 25, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      

      
    </section>
  

  <div align="center">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
      
    <ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3804322353139756"
     data-ad-slot="3115024406"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
    <script>
        $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
    </script>
  </div>
  
  
    
      <section id="categories">
        
   
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/convolutional-neural-networks/">convolutional-neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/handwritten-digit-recognition/">handwritten-digit-recognition<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/mobile-application-development/">mobile-application-development<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-technical-analysis/">stock-technical-analysis<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
        <div align="center">
          <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
          
            <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-3804322353139756"
             data-ad-slot="5736252654"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
          <script>
            $(document).ready(function(){(adsbygoogle = window.adsbygoogle || []).push({})})
          </script>             
        </div>             
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>about</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    Â© 2021 Data Science Posts and Resources
      <br>
  </p>
</footer>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/yaml.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.a1ad7ccb559a1034b77cf4c6e6b63e769c07e3433b17bf31cd5d2893c74db6f1.js" integrity="sha256-oa18y1WaEDS3fPTG5rY&#43;dpwH40M7F78xzV0ok8dNtvE="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
  
</html>
