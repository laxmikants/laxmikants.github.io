<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Exploring and preparing data - Data Science Posts and Resources :: Laxmikant Soni</title>

<meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1, minimum-scale = 1, user-scalable = no">

<meta name="google-site-verification" content="MeRcFEBEyWiTb3NfY4THWxbV_fx3rKOJnvr_Jk398wY" />

<meta name=keywords content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics | Laxmikant Soni, Predictive Analytics, Business, Data, Analytics, Machine Learning, Mining, Python, Intelligence, Big, Modeling, Data Science, Integration, Visualization,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow,Javascript,ReactJS,NodeJS,Posts and Resources on Data Science,Data Science,Hadoop,Java,Spring,Hibernate,Struts,MySQL,Oracle,DB2,Websphere,Weblogic">

<meta name=description content="Articles and Posts on Python, R, Data Science, Machine Learning and Analytics :: Laxmikant Soni">

<meta name="robots" content="index">


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>

<link rel="stylesheet"href= "https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" /> 



<meta name="generator" content="Hugo 0.80.0" /><meta itemprop="name" content="Exploring and preparing data">
<meta itemprop="description" content="Exploring and preparing data with titanic dataset">
<meta itemprop="datePublished" content="2020-02-08T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-02-08T00:00:00+00:00" />
<meta itemprop="wordCount" content="2392">



<meta itemprop="keywords" content="Exploring Dataset," />
<meta property="og:title" content="Exploring and preparing data" />
<meta property="og:description" content="Exploring and preparing data with titanic dataset" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/exploring-and-preparing-data/" />
<meta property="article:published_time" content="2020-02-08T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-02-08T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Exploring and preparing data"/>
<meta name="twitter:description" content="Exploring and preparing data with titanic dataset"/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.aa4e8165f5b2a16460fcb21582ad412bed8e48e9c5dc49f3b412d1703be4d75d.css" integrity="sha256-qk6BZfWyoWRg/LIVgq1BK&#43;2OSOnF3EnztBLRcDvk110="><link rel="stylesheet" href="/css/add-on.css">

<title>Exploring and preparing data : Data Science Posts and Resources</title>

<meta property="og:title" content="Exploring and preparing data">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/exploring-and-preparing-data/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="Exploring and preparing data with titanic dataset">
<meta name="description" content="Exploring and preparing data with titanic dataset">
<meta property="og:updated_time" content="2020-02-08T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">
<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2020-02-08T00:00:00Z">
<meta property="article:modified_time" content="2020-02-08T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Exploring and preparing data",
  "alternativeHeadline": "Exploring and preparing data",
  "url": "https://laxmikants.github.io/blog/exploring-and-preparing-data/",
  "image": "https://laxmikants.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/exploring-and-preparing-data/"
  },
  "description": "Exploring and preparing data with titanic dataset",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2020-02-08T00:00:00Z",
  "dateModified": "2020-02-08T00:00:00Z",
  "articleBody": "\r\n\u003cscript src=\"/rmarkdown-libs/header-attrs/header-attrs.js\"\u003e\u003c/script\u003e\r\n\u003clink href=\"/rmarkdown-libs/anchor-sections/anchor-sections.css\" rel=\"stylesheet\" /\u003e\r\n\u003cscript src=\"/rmarkdown-libs/anchor-sections/anchor-sections.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\u003cpre class=\"css\"\u003e\u003ccode\u003e.badCode {\r\nbackground-color: black;\r\n}\u003c/code\u003e\u003c/pre\u003e\r\n\u003cstyle type=\"text/css\"\u003e\r\n.badCode {\r\nbackground-color: black;\r\n}\r\n\u003c/style\u003e\r\n\u003cdiv id=\"introduction\" class=\"section level2\"\u003e\r\n\u003ch2\u003eIntroduction\u003c/h2\u003e\r\n\u003cp\u003eThe first a part of any data analysis or predictive modeling task is an initial exploration of the datasets. Albeit we collected the datasets ourself and we have already got an inventory of questions in mind that we simply want to answer, it’s important to explore the datasets before doing any serious analysis, since oddities within the datasets can cause bugs and muddle your results. Before exploring deeper questions, we got to answer many simpler ones about the shape and quality of datasets . That said, it’s important to travel into initial data exploration with an enormous picture question in mind.\u003c/p\u003e\r\n\u003cp\u003eThis post aims to boost a number of the questions we ought to consider once we check out a replacement data set for the primary time and show the way to perform various Python operations associated with those questions.\u003c/p\u003e\r\n\u003cp\u003eIn this post, we’ll explore the Titanic disaster training set available from Kaggle.co. The dataset consists of 889 passengers who rode aboard the Titanic.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"getting-the-dataset\" class=\"section level2\"\u003e\r\n\u003ch2\u003eGetting the dataset\u003c/h2\u003e\r\n\u003cp\u003eTo get the dataset into \u003ccode\u003epandas dataframe\u003c/code\u003e simply call the function \u003ccode\u003eread_csv\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre class=\"python bg-success\"\u003e\u003ccode\u003eimport pandas as pd\r\nimport numpy as np\r\n\r\ntit_train = pd.read_csv(\u0026quot;../data/titanic/train.csv\u0026quot;)      # Read the data\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eChecking the dimensions of the dataset with \u003ccode\u003edf.shape\u003c/code\u003e and the variable data types of \u003ccode\u003edf.dtypes\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train.shape\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## (891, 12)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train.dtypes\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## PassengerId      int64\r\n## Survived         int64\r\n## Pclass           int64\r\n## Name            object\r\n## Sex             object\r\n## Age            float64\r\n## SibSp            int64\r\n## Parch            int64\r\n## Ticket          object\r\n## Fare           float64\r\n## Cabin           object\r\n## Embarked        object\r\n## dtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe output displays that we re working with a set of 891 records and 12 columns. Most of the column variables are encoded as numeric data types (ints and floats) but a some of them are encoded as “object”.\u003c/p\u003e\r\n\u003cp\u003eCheck the head of the data to get a better sense of what the variables look like:\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train.head(5)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##    PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\r\n## 0            1         0       3  ...   7.2500   NaN         S\r\n## 1            2         1       1  ...  71.2833   C85         C\r\n## 2            3         1       3  ...   7.9250   NaN         S\r\n## 3            4         1       1  ...  53.1000  C123         S\r\n## 4            5         0       3  ...   8.0500   NaN         S\r\n## \r\n## [5 rows x 12 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe have a combination of numeric columns and columns with text data.\u003c/p\u003e\r\n\u003cp\u003eIn dataset analysis, variables or features that split records into a fixed number of unique categories, such as Sex, are called as categorical variables.\u003c/p\u003e\r\n\u003cp\u003ePandas can be used to interpret categorical variables as such when we load dataset, but we can convert a variable to categorical if necessary\u003c/p\u003e\r\n\u003cp\u003eAfter getting a sense of the datasets structure, it is a good practice to look at a statistical summary of the features with df.describe():\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train.describe().transpose()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##              count        mean         std  ...       50%    75%       max\r\n## PassengerId  891.0  446.000000  257.353842  ...  446.0000  668.5  891.0000\r\n## Survived     891.0    0.383838    0.486592  ...    0.0000    1.0    1.0000\r\n## Pclass       891.0    2.308642    0.836071  ...    3.0000    3.0    3.0000\r\n## Age          714.0   29.699118   14.526497  ...   28.0000   38.0   80.0000\r\n## SibSp        891.0    0.523008    1.102743  ...    0.0000    1.0    8.0000\r\n## Parch        891.0    0.381594    0.806057  ...    0.0000    0.0    6.0000\r\n## Fare         891.0   32.204208   49.693429  ...   14.4542   31.0  512.3292\r\n## \r\n## [7 rows x 8 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003ewe notice that the non-numeric columns are omitted from the statistical summary provided by \u003ccode\u003edf.describe()\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eWe can find the summary of the categorical variables by passing only those columns to describe():\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e\r\ncat_vars = tit_train.dtypes[tit_train.dtypes == \u0026quot;object\u0026quot;].index\r\n\r\nprint(cat_vars)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## Index([\u0026#39;Name\u0026#39;, \u0026#39;Sex\u0026#39;, \u0026#39;Ticket\u0026#39;, \u0026#39;Cabin\u0026#39;, \u0026#39;Embarked\u0026#39;], dtype=\u0026#39;object\u0026#39;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[cat_vars].describe().transpose()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##          count unique                  top freq\r\n## Name       891    891  Doharr, Mr. Tannous    1\r\n## Sex        891      2                 male  577\r\n## Ticket     891    681               347082    7\r\n## Cabin      204    147                   G6    4\r\n## Embarked   889      3                    S  644\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe summary of the categorical features shows the count of non-NaN records, the number of unique categories, the most frequent occurring value and the number of occurrences of the most frequent value.\u003c/p\u003e\r\n\u003cp\u003eAlthough describe() gives a concise overview of each variable, it does not necessarily give us enough information to determine what each variable means.\u003c/p\u003e\r\n\u003cp\u003eCertain features like “Age” and “Fare” are easy to understand, while others like “SibSp” and “Parch” are not. The details of these are provided by kaggle on the data download page.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e# VARIABLE DESCRIPTIONS:\r\n# survival        Survival\r\n#                 (0 = No; 1 = Yes)\r\n# pclass          Passenger Class\r\n#                 (1 = 1st; 2 = 2nd; 3 = 3rd)\r\n# name            Name\r\n# sex             Sex\r\n# age             Age\r\n# sibsp           Number of Siblings/Spouses Aboard\r\n# parch           Number of Parents/Children Aboard\r\n# ticket          Ticket Number\r\n# fare            Passenger Fare\r\n# cabin           Cabin\r\n# embarked        Port of Embarkation\r\n#                 (C = Cherbourg; Q = Queenstown; S = Southampton)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eAfter looking at the data we ask yourself a few questions:\u003c/p\u003e\r\n\u003ctable\u003e\r\n\u003cthead\u003e\r\n\u003ctr class=\"header\"\u003e\r\n\u003cth\u003eQUESTIONS\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr class=\"odd\"\u003e\r\n\u003ctd\u003eDo we require all of the variables ?\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr class=\"even\"\u003e\r\n\u003ctd\u003eShould we transform any variables ?\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr class=\"odd\"\u003e\r\n\u003ctd\u003eCheck if there are any NA values, outliers etc ?\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr class=\"even\"\u003e\r\n\u003ctd\u003eShould we create new variables?\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cdiv id=\"do-we-require-all-of-the-variables\" class=\"section level4\"\u003e\r\n\u003ch4\u003eDo we require all of the Variables?\u003c/h4\u003e\r\n\u003cp\u003eRemoval of unnecessary variables is a first step when dealing with any data set, since removing variables reduces complexity and can make computation on the data faster.\u003c/p\u003e\r\n\u003cp\u003eWhether we should get rid of a variable or not will depend on size of the data set and the goal of the analysis. With a dataset like the titanic data, there’s no requirement to remove variables from a computing perspective.\r\nBut it can be helpful to drop variables that will only distract from your goal.\u003c/p\u003e\r\n\u003cp\u003eLet’s go through each variable and consider whether we should keep it or not in the context of survival prediction.\u003c/p\u003e\r\n\u003cp\u003e“PassengerId” is just a number assigned to each passenger. We can remove it\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003edel tit_train[\u0026#39;PassengerId\u0026#39;]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eVariable “Survived” shows whether each passenger lived or died. Since survival prediction is our goal, we definitely need to keep it.\u003c/p\u003e\r\n\u003cp\u003eFeatures describing passengers numerically or grouping them into a few broad categories could be useful for survival prediction. Therefore variables Pclass, Sex, Age, SibSp, Parch, Fare and Embarked can be kept.\u003c/p\u003e\r\n\u003cp\u003efurther, “Name” appears to be a character string of the name of each passenger and it will also help in identifying passenger so we can keep it\u003c/p\u003e\r\n\u003cp\u003eNext, let’s see at “Ticket”\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Ticket\u0026#39;][0:10]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## 0           A/5 21171\r\n## 1            PC 17599\r\n## 2    STON/O2. 3101282\r\n## 3              113803\r\n## 4              373450\r\n## 5              330877\r\n## 6               17463\r\n## 7              349909\r\n## 8              347742\r\n## 9              237736\r\n## Name: Ticket, dtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Ticket\u0026#39;].describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## count        891\r\n## unique       681\r\n## top       347082\r\n## freq           7\r\n## Name: Ticket, dtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eTicket has 681 unique values: almost as many as there are passengers. Categorical variables with this many levels are generally not very useful for prediction. Let’s remove it\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003edel tit_train[\u0026#39;Ticket\u0026#39;]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eLastly let’s see the “Cabin” variable\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Cabin\u0026#39;][0:10]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## 0     NaN\r\n## 1     C85\r\n## 2     NaN\r\n## 3    C123\r\n## 4     NaN\r\n## 5     NaN\r\n## 6     E46\r\n## 7     NaN\r\n## 8     NaN\r\n## 9     NaN\r\n## Name: Cabin, dtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Cabin\u0026#39;].describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## count     204\r\n## unique    147\r\n## top        G6\r\n## freq        4\r\n## Name: Cabin, dtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eCabin also has 147 unique values, which shows it may not be useful for prediction. On the other hand, the names of the different levels for the cabin variable seem to have a some structure, each starts with a capital letter followed by a number. We can use that structure to reduce the number of levels to make categories large enough that they might be useful for prediction later on. So Lets Keep Cabin for now.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"should-we-transform-any-variables\" class=\"section level4\"\u003e\r\n\u003ch4\u003eShould we transform Any Variables?\u003c/h4\u003e\r\n\u003cp\u003e\u003ccode\u003ePclass\u003c/code\u003e is an integer variable that indicates a passenger’s class, with 1 being first class, 2 as second class and 3 as third class. We can transform this by transforming Pclass into an ordered categorical variable\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e\r\npclass_new = pd.Categorical(tit_train[\u0026#39;Pclass\u0026#39;], ordered=True)\r\n\r\npclass_new = pclass_new.rename_categories([\u0026quot;class1\u0026quot;,\u0026quot;class2\u0026quot;,\u0026quot;class3\u0026quot;])\r\n\r\npclass_new.describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##             counts     freqs\r\n## categories                  \r\n## class1         216  0.242424\r\n## class2         184  0.206510\r\n## class3         491  0.551066\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Pclass\u0026#39;] = pclass_new\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNow see the Cabin variable. It appears that each Cabin is in a general section of the ship indicated by the capital letter at the start of each factor level\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026#39;Cabin\u0026#39;].unique()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## array([nan, \u0026#39;C85\u0026#39;, \u0026#39;C123\u0026#39;, \u0026#39;E46\u0026#39;, \u0026#39;G6\u0026#39;, \u0026#39;C103\u0026#39;, \u0026#39;D56\u0026#39;, \u0026#39;A6\u0026#39;,\r\n##        \u0026#39;C23 C25 C27\u0026#39;, \u0026#39;B78\u0026#39;, \u0026#39;D33\u0026#39;, \u0026#39;B30\u0026#39;, \u0026#39;C52\u0026#39;, \u0026#39;B28\u0026#39;, \u0026#39;C83\u0026#39;, \u0026#39;F33\u0026#39;,\r\n##        \u0026#39;F G73\u0026#39;, \u0026#39;E31\u0026#39;, \u0026#39;A5\u0026#39;, \u0026#39;D10 D12\u0026#39;, \u0026#39;D26\u0026#39;, \u0026#39;C110\u0026#39;, \u0026#39;B58 B60\u0026#39;, \u0026#39;E101\u0026#39;,\r\n##        \u0026#39;F E69\u0026#39;, \u0026#39;D47\u0026#39;, \u0026#39;B86\u0026#39;, \u0026#39;F2\u0026#39;, \u0026#39;C2\u0026#39;, \u0026#39;E33\u0026#39;, \u0026#39;B19\u0026#39;, \u0026#39;A7\u0026#39;, \u0026#39;C49\u0026#39;, \u0026#39;F4\u0026#39;,\r\n##        \u0026#39;A32\u0026#39;, \u0026#39;B4\u0026#39;, \u0026#39;B80\u0026#39;, \u0026#39;A31\u0026#39;, \u0026#39;D36\u0026#39;, \u0026#39;D15\u0026#39;, \u0026#39;C93\u0026#39;, \u0026#39;C78\u0026#39;, \u0026#39;D35\u0026#39;,\r\n##        \u0026#39;C87\u0026#39;, \u0026#39;B77\u0026#39;, \u0026#39;E67\u0026#39;, \u0026#39;B94\u0026#39;, \u0026#39;C125\u0026#39;, \u0026#39;C99\u0026#39;, \u0026#39;C118\u0026#39;, \u0026#39;D7\u0026#39;, \u0026#39;A19\u0026#39;,\r\n##        \u0026#39;B49\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;C22 C26\u0026#39;, \u0026#39;C106\u0026#39;, \u0026#39;C65\u0026#39;, \u0026#39;E36\u0026#39;, \u0026#39;C54\u0026#39;,\r\n##        \u0026#39;B57 B59 B63 B66\u0026#39;, \u0026#39;C7\u0026#39;, \u0026#39;E34\u0026#39;, \u0026#39;C32\u0026#39;, \u0026#39;B18\u0026#39;, \u0026#39;C124\u0026#39;, \u0026#39;C91\u0026#39;, \u0026#39;E40\u0026#39;,\r\n##        \u0026#39;T\u0026#39;, \u0026#39;C128\u0026#39;, \u0026#39;D37\u0026#39;, \u0026#39;B35\u0026#39;, \u0026#39;E50\u0026#39;, \u0026#39;C82\u0026#39;, \u0026#39;B96 B98\u0026#39;, \u0026#39;E10\u0026#39;, \u0026#39;E44\u0026#39;,\r\n##        \u0026#39;A34\u0026#39;, \u0026#39;C104\u0026#39;, \u0026#39;C111\u0026#39;, \u0026#39;C92\u0026#39;, \u0026#39;E38\u0026#39;, \u0026#39;D21\u0026#39;, \u0026#39;E12\u0026#39;, \u0026#39;E63\u0026#39;, \u0026#39;A14\u0026#39;,\r\n##        \u0026#39;B37\u0026#39;, \u0026#39;C30\u0026#39;, \u0026#39;D20\u0026#39;, \u0026#39;B79\u0026#39;, \u0026#39;E25\u0026#39;, \u0026#39;D46\u0026#39;, \u0026#39;B73\u0026#39;, \u0026#39;C95\u0026#39;, \u0026#39;B38\u0026#39;,\r\n##        \u0026#39;B39\u0026#39;, \u0026#39;B22\u0026#39;, \u0026#39;C86\u0026#39;, \u0026#39;C70\u0026#39;, \u0026#39;A16\u0026#39;, \u0026#39;C101\u0026#39;, \u0026#39;C68\u0026#39;, \u0026#39;A10\u0026#39;, \u0026#39;E68\u0026#39;,\r\n##        \u0026#39;B41\u0026#39;, \u0026#39;A20\u0026#39;, \u0026#39;D19\u0026#39;, \u0026#39;D50\u0026#39;, \u0026#39;D9\u0026#39;, \u0026#39;A23\u0026#39;, \u0026#39;B50\u0026#39;, \u0026#39;A26\u0026#39;, \u0026#39;D48\u0026#39;,\r\n##        \u0026#39;E58\u0026#39;, \u0026#39;C126\u0026#39;, \u0026#39;B71\u0026#39;, \u0026#39;B51 B53 B55\u0026#39;, \u0026#39;D49\u0026#39;, \u0026#39;B5\u0026#39;, \u0026#39;B20\u0026#39;, \u0026#39;F G63\u0026#39;,\r\n##        \u0026#39;C62 C64\u0026#39;, \u0026#39;E24\u0026#39;, \u0026#39;C90\u0026#39;, \u0026#39;C45\u0026#39;, \u0026#39;E8\u0026#39;, \u0026#39;B101\u0026#39;, \u0026#39;D45\u0026#39;, \u0026#39;C46\u0026#39;, \u0026#39;D30\u0026#39;,\r\n##        \u0026#39;E121\u0026#39;, \u0026#39;D11\u0026#39;, \u0026#39;E77\u0026#39;, \u0026#39;F38\u0026#39;, \u0026#39;B3\u0026#39;, \u0026#39;D6\u0026#39;, \u0026#39;B82 B84\u0026#39;, \u0026#39;D17\u0026#39;, \u0026#39;A36\u0026#39;,\r\n##        \u0026#39;B102\u0026#39;, \u0026#39;B69\u0026#39;, \u0026#39;E49\u0026#39;, \u0026#39;C47\u0026#39;, \u0026#39;D28\u0026#39;, \u0026#39;E17\u0026#39;, \u0026#39;A24\u0026#39;, \u0026#39;C50\u0026#39;, \u0026#39;B42\u0026#39;,\r\n##        \u0026#39;C148\u0026#39;], dtype=object)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eIf we grouped the cabin just by this letter, we could lesser the number of levels while getting some useful information.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e\r\nchr_cabin = tit_train[\u0026quot;Cabin\u0026quot;].astype(str)\r\n\r\nn_Cabin = np.array([cabin[0] for cabin in chr_cabin]) \r\n\r\nn_Cabin = pd.Categorical(n_Cabin)\r\n\r\nn_Cabin.describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##             counts     freqs\r\n## categories                  \r\n## A               15  0.016835\r\n## B               47  0.052750\r\n## C               59  0.066218\r\n## D               33  0.037037\r\n## E               32  0.035915\r\n## F               13  0.014590\r\n## G                4  0.004489\r\n## T                1  0.001122\r\n## n              687  0.771044\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThe output of describe() shows we can group Cabin into broader categories, but we also discovered something interesting: 688 of the records have Cabin are “n” which is shortened from “nan”. In other words, more than 2/3 of the passengers do not have a cabin.\u003c/p\u003e\r\n\u003cp\u003eA missing cabin variable could be an indication that a passenger died.\u003c/p\u003e\r\n\u003cp\u003eWe can keep the new variable cabin\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026quot;Cabin\u0026quot;] = n_Cabin\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"checking-to-if-there-are-null-values-outliers-or-other-garbage-values\" class=\"section level3\"\u003e\r\n\u003ch3\u003eChecking to if there are null Values, Outliers or Other garbage Values?\u003c/h3\u003e\r\n\u003cp\u003eTo check the missing values we us \u003ccode\u003epd.isnull()\u003c/code\u003e function for example\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003e\r\nmock_vector = pd.Series([1,None,3,None,7,8])\r\n\r\nmock_vector.isnull()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## 0    False\r\n## 1     True\r\n## 2    False\r\n## 3     True\r\n## 4    False\r\n## 5    False\r\n## dtype: bool\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eIf the missing values are numeric then they can be simple deleted. If missing values are categorical then they can be treated as additional category with value as NA.\u003c/p\u003e\r\n\u003cp\u003eTo check if there is missing age values in titanic dataset\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026quot;Age\u0026quot;].describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## count    714.000000\r\n## mean      29.699118\r\n## std       14.526497\r\n## min        0.420000\r\n## 25%       20.125000\r\n## 50%       28.000000\r\n## 75%       38.000000\r\n## max       80.000000\r\n## Name: Age, dtype: float64\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe see that the count of age (712) is less than the total row count of dataset(889).\r\nTo check indexes of the missing ages we use \u003ccode\u003enp.where()\u003c/code\u003e\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emissvalues = np.where(tit_train[\u0026quot;Age\u0026quot;].isnull() == True)\r\nmissvalues\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## (array([  5,  17,  19,  26,  28,  29,  31,  32,  36,  42,  45,  46,  47,\r\n##         48,  55,  64,  65,  76,  77,  82,  87,  95, 101, 107, 109, 121,\r\n##        126, 128, 140, 154, 158, 159, 166, 168, 176, 180, 181, 185, 186,\r\n##        196, 198, 201, 214, 223, 229, 235, 240, 241, 250, 256, 260, 264,\r\n##        270, 274, 277, 284, 295, 298, 300, 301, 303, 304, 306, 324, 330,\r\n##        334, 335, 347, 351, 354, 358, 359, 364, 367, 368, 375, 384, 388,\r\n##        409, 410, 411, 413, 415, 420, 425, 428, 431, 444, 451, 454, 457,\r\n##        459, 464, 466, 468, 470, 475, 481, 485, 490, 495, 497, 502, 507,\r\n##        511, 517, 522, 524, 527, 531, 533, 538, 547, 552, 557, 560, 563,\r\n##        564, 568, 573, 578, 584, 589, 593, 596, 598, 601, 602, 611, 612,\r\n##        613, 629, 633, 639, 643, 648, 650, 653, 656, 667, 669, 674, 680,\r\n##        692, 697, 709, 711, 718, 727, 732, 738, 739, 740, 760, 766, 768,\r\n##        773, 776, 778, 783, 790, 792, 793, 815, 825, 826, 828, 832, 837,\r\n##        839, 846, 849, 859, 863, 868, 878, 888], dtype=int64),)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003elen(missvalues)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## 1\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eBefore we do anything with missing values its good to check the distribution of the missing values to know the central tendency of age.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train.hist(column=\u0026#39;Age\u0026#39;,    \r\n                   figsize=(9,6),   \r\n                   bins=20)         \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/titdsage.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThe histogram shows that couple of passengers are near age 80.\u003c/p\u003e\r\n\u003cp\u003eTo check the \u003ccode\u003efare\u003c/code\u003e variable we create the box plot\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026quot;Fare\u0026quot;].plot(kind=\u0026quot;box\u0026quot;,\r\n                           figsize=(9,9))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/titdsfare.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003e50% of the data in the box plot represents the median. There are outliers in the data. There are passengers who paid double the amount than any other passenger. We can check this using \u003ccode\u003enp.where()\u003c/code\u003e function\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eind = np.where(tit_train[\u0026quot;Fare\u0026quot;] == max(tit_train[\u0026quot;Fare\u0026quot;]) )\r\n\r\ntit_train.loc[ind]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##      Survived  Pclass  ... Cabin Embarked\r\n## 258         1  class1  ...     n        C\r\n## 679         1  class1  ...     B        C\r\n## 737         1  class1  ...     B        C\r\n## \r\n## [3 rows x 10 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eBefore modeling datasets using ML models it is better to address missing values, outliers, mislabeled data, bad data because they can corrupt the analysis and lead to wrong results.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"should-we-create-new-variables\" class=\"section level3\"\u003e\r\n\u003ch3\u003eShould we Create New Variables?\u003c/h3\u003e\r\n\u003cp\u003eThe decision to create new variables should be taken while preparing the data. The new variable could represent aggregate of existing variables, for example in titanic dataset we can create a new variable called \u003ccode\u003efamily\u003c/code\u003e which stores the number of members in that family.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003etit_train[\u0026quot;Family\u0026quot;] = tit_train[\u0026quot;SibSp\u0026quot;] + tit_train[\u0026quot;Parch\u0026quot;]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003ewe can check who has most family members on the board\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emostfamily = np.where(tit_train[\u0026quot;Family\u0026quot;] == max(tit_train[\u0026quot;Family\u0026quot;]))\r\n\r\ntit_train.loc[mostfamily]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e##      Survived  Pclass                               Name  ... Cabin  Embarked  Family\r\n## 159         0  class3         Sage, Master. Thomas Henry  ...     n         S      10\r\n## 180         0  class3       Sage, Miss. Constance Gladys  ...     n         S      10\r\n## 201         0  class3                Sage, Mr. Frederick  ...     n         S      10\r\n## 324         0  class3           Sage, Mr. George John Jr  ...     n         S      10\r\n## 792         0  class3            Sage, Miss. Stella Anna  ...     n         S      10\r\n## 846         0  class3           Sage, Mr. Douglas Bullen  ...     n         S      10\r\n## 863         0  class3  Sage, Miss. Dorothy Edith \u0026quot;Dolly\u0026quot;  ...     n         S      10\r\n## \r\n## [7 rows x 11 columns]\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"summary\" class=\"section level2\"\u003e\r\n\u003ch2\u003eSummary\u003c/h2\u003e\r\n\u003cp\u003eThere are question that should be answered while investing any dataset. Once the basic questions are answered one can move further to find relationship between variables/features and build the machine learning models.\u003c/p\u003e\r\n\u003c/div\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  


<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T5KFS4C');</script>

</head>

  <body>
    
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T5KFS4C"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
      
    

<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
        
          
          <a href="/contact/" class="nav link"><i class='far fa-envelope'></i> Contact</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu"></div></menu>
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Exploring%20and%20preparing%20data&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f&amp;title=Exploring%20and%20preparing%20data" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    <p>Articles on Data Science</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>

      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/exploring-and-preparing-data/">Exploring and preparing data</a></h2>
    
    
      <p>Exploring and preparing data with titanic dataset</p>
    
  </div>
  <div class="meta">
    <time datetime="2020-02-08 00:00:00 &#43;0000 UTC">February 8, 2020</time>
    <p>Laxmi K Soni</p>
    <p>12-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Exploring%20and%20preparing%20data&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fblog%2fexploring-and-preparing-data%2f&amp;title=Exploring%20and%20preparing%20data" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  


    </div>
    <div class="content">
      <a href="/blog/exploring-and-preparing-data/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/eda_iris05.jpg');">
    <img src="https://laxmikants.github.io/img/main/eda_iris05.jpg" alt="">
  </a>
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<pre class="css"><code>.badCode {
background-color: black;
}</code></pre>
<style type="text/css">
.badCode {
background-color: black;
}
</style>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The first a part of any data analysis or predictive modeling task is an initial exploration of the datasets. Albeit we collected the datasets ourself and we have already got an inventory of questions in mind that we simply want to answer, it’s important to explore the datasets before doing any serious analysis, since oddities within the datasets can cause bugs and muddle your results. Before exploring deeper questions, we got to answer many simpler ones about the shape and quality of datasets . That said, it’s important to travel into initial data exploration with an enormous picture question in mind.</p>
<p>This post aims to boost a number of the questions we ought to consider once we check out a replacement data set for the primary time and show the way to perform various Python operations associated with those questions.</p>
<p>In this post, we’ll explore the Titanic disaster training set available from Kaggle.co. The dataset consists of 889 passengers who rode aboard the Titanic.</p>
</div>
<div id="getting-the-dataset" class="section level2">
<h2>Getting the dataset</h2>
<p>To get the dataset into <code>pandas dataframe</code> simply call the function <code>read_csv</code>.</p>
<pre class="python bg-success"><code>import pandas as pd
import numpy as np

tit_train = pd.read_csv(&quot;../data/titanic/train.csv&quot;)      # Read the data
</code></pre>
<p>Checking the dimensions of the dataset with <code>df.shape</code> and the variable data types of <code>df.dtypes</code>.</p>
<pre class="python"><code>tit_train.shape</code></pre>
<pre><code>## (891, 12)</code></pre>
<pre class="python"><code>tit_train.dtypes</code></pre>
<pre><code>## PassengerId      int64
## Survived         int64
## Pclass           int64
## Name            object
## Sex             object
## Age            float64
## SibSp            int64
## Parch            int64
## Ticket          object
## Fare           float64
## Cabin           object
## Embarked        object
## dtype: object</code></pre>
<p>The output displays that we re working with a set of 891 records and 12 columns. Most of the column variables are encoded as numeric data types (ints and floats) but a some of them are encoded as “object”.</p>
<p>Check the head of the data to get a better sense of what the variables look like:</p>
<pre class="python"><code>tit_train.head(5)</code></pre>
<pre><code>##    PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked
## 0            1         0       3  ...   7.2500   NaN         S
## 1            2         1       1  ...  71.2833   C85         C
## 2            3         1       3  ...   7.9250   NaN         S
## 3            4         1       1  ...  53.1000  C123         S
## 4            5         0       3  ...   8.0500   NaN         S
## 
## [5 rows x 12 columns]</code></pre>
<p>We have a combination of numeric columns and columns with text data.</p>
<p>In dataset analysis, variables or features that split records into a fixed number of unique categories, such as Sex, are called as categorical variables.</p>
<p>Pandas can be used to interpret categorical variables as such when we load dataset, but we can convert a variable to categorical if necessary</p>
<p>After getting a sense of the datasets structure, it is a good practice to look at a statistical summary of the features with df.describe():</p>
<pre class="python"><code>tit_train.describe().transpose()</code></pre>
<pre><code>##              count        mean         std  ...       50%    75%       max
## PassengerId  891.0  446.000000  257.353842  ...  446.0000  668.5  891.0000
## Survived     891.0    0.383838    0.486592  ...    0.0000    1.0    1.0000
## Pclass       891.0    2.308642    0.836071  ...    3.0000    3.0    3.0000
## Age          714.0   29.699118   14.526497  ...   28.0000   38.0   80.0000
## SibSp        891.0    0.523008    1.102743  ...    0.0000    1.0    8.0000
## Parch        891.0    0.381594    0.806057  ...    0.0000    0.0    6.0000
## Fare         891.0   32.204208   49.693429  ...   14.4542   31.0  512.3292
## 
## [7 rows x 8 columns]</code></pre>
<p>we notice that the non-numeric columns are omitted from the statistical summary provided by <code>df.describe()</code>.</p>
<p>We can find the summary of the categorical variables by passing only those columns to describe():</p>
<pre class="python"><code>
cat_vars = tit_train.dtypes[tit_train.dtypes == &quot;object&quot;].index

print(cat_vars)
</code></pre>
<pre><code>## Index([&#39;Name&#39;, &#39;Sex&#39;, &#39;Ticket&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;], dtype=&#39;object&#39;)</code></pre>
<pre class="python"><code>tit_train[cat_vars].describe().transpose()</code></pre>
<pre><code>##          count unique                  top freq
## Name       891    891  Doharr, Mr. Tannous    1
## Sex        891      2                 male  577
## Ticket     891    681               347082    7
## Cabin      204    147                   G6    4
## Embarked   889      3                    S  644</code></pre>
<p>The summary of the categorical features shows the count of non-NaN records, the number of unique categories, the most frequent occurring value and the number of occurrences of the most frequent value.</p>
<p>Although describe() gives a concise overview of each variable, it does not necessarily give us enough information to determine what each variable means.</p>
<p>Certain features like “Age” and “Fare” are easy to understand, while others like “SibSp” and “Parch” are not. The details of these are provided by kaggle on the data download page.</p>
<pre class="python"><code># VARIABLE DESCRIPTIONS:
# survival        Survival
#                 (0 = No; 1 = Yes)
# pclass          Passenger Class
#                 (1 = 1st; 2 = 2nd; 3 = 3rd)
# name            Name
# sex             Sex
# age             Age
# sibsp           Number of Siblings/Spouses Aboard
# parch           Number of Parents/Children Aboard
# ticket          Ticket Number
# fare            Passenger Fare
# cabin           Cabin
# embarked        Port of Embarkation
#                 (C = Cherbourg; Q = Queenstown; S = Southampton)</code></pre>
<p>After looking at the data we ask yourself a few questions:</p>
<table>
<thead>
<tr class="header">
<th>QUESTIONS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Do we require all of the variables ?</td>
</tr>
<tr class="even">
<td>Should we transform any variables ?</td>
</tr>
<tr class="odd">
<td>Check if there are any NA values, outliers etc ?</td>
</tr>
<tr class="even">
<td>Should we create new variables?</td>
</tr>
</tbody>
</table>
<div id="do-we-require-all-of-the-variables" class="section level4">
<h4>Do we require all of the Variables?</h4>
<p>Removal of unnecessary variables is a first step when dealing with any data set, since removing variables reduces complexity and can make computation on the data faster.</p>
<p>Whether we should get rid of a variable or not will depend on size of the data set and the goal of the analysis. With a dataset like the titanic data, there’s no requirement to remove variables from a computing perspective.
But it can be helpful to drop variables that will only distract from your goal.</p>
<p>Let’s go through each variable and consider whether we should keep it or not in the context of survival prediction.</p>
<p>“PassengerId” is just a number assigned to each passenger. We can remove it</p>
<pre class="python"><code>del tit_train[&#39;PassengerId&#39;]</code></pre>
<p>Variable “Survived” shows whether each passenger lived or died. Since survival prediction is our goal, we definitely need to keep it.</p>
<p>Features describing passengers numerically or grouping them into a few broad categories could be useful for survival prediction. Therefore variables Pclass, Sex, Age, SibSp, Parch, Fare and Embarked can be kept.</p>
<p>further, “Name” appears to be a character string of the name of each passenger and it will also help in identifying passenger so we can keep it</p>
<p>Next, let’s see at “Ticket”</p>
<pre class="python"><code>tit_train[&#39;Ticket&#39;][0:10]</code></pre>
<pre><code>## 0           A/5 21171
## 1            PC 17599
## 2    STON/O2. 3101282
## 3              113803
## 4              373450
## 5              330877
## 6               17463
## 7              349909
## 8              347742
## 9              237736
## Name: Ticket, dtype: object</code></pre>
<pre class="python"><code>tit_train[&#39;Ticket&#39;].describe()</code></pre>
<pre><code>## count        891
## unique       681
## top       347082
## freq           7
## Name: Ticket, dtype: object</code></pre>
<p>Ticket has 681 unique values: almost as many as there are passengers. Categorical variables with this many levels are generally not very useful for prediction. Let’s remove it</p>
<pre class="python"><code>del tit_train[&#39;Ticket&#39;]</code></pre>
<p>Lastly let’s see the “Cabin” variable</p>
<pre class="python"><code>tit_train[&#39;Cabin&#39;][0:10]</code></pre>
<pre><code>## 0     NaN
## 1     C85
## 2     NaN
## 3    C123
## 4     NaN
## 5     NaN
## 6     E46
## 7     NaN
## 8     NaN
## 9     NaN
## Name: Cabin, dtype: object</code></pre>
<pre class="python"><code>tit_train[&#39;Cabin&#39;].describe()</code></pre>
<pre><code>## count     204
## unique    147
## top        G6
## freq        4
## Name: Cabin, dtype: object</code></pre>
<p>Cabin also has 147 unique values, which shows it may not be useful for prediction. On the other hand, the names of the different levels for the cabin variable seem to have a some structure, each starts with a capital letter followed by a number. We can use that structure to reduce the number of levels to make categories large enough that they might be useful for prediction later on. So Lets Keep Cabin for now.</p>
</div>
<div id="should-we-transform-any-variables" class="section level4">
<h4>Should we transform Any Variables?</h4>
<p><code>Pclass</code> is an integer variable that indicates a passenger’s class, with 1 being first class, 2 as second class and 3 as third class. We can transform this by transforming Pclass into an ordered categorical variable</p>
<pre class="python"><code>
pclass_new = pd.Categorical(tit_train[&#39;Pclass&#39;], ordered=True)

pclass_new = pclass_new.rename_categories([&quot;class1&quot;,&quot;class2&quot;,&quot;class3&quot;])

pclass_new.describe()</code></pre>
<pre><code>##             counts     freqs
## categories                  
## class1         216  0.242424
## class2         184  0.206510
## class3         491  0.551066</code></pre>
<pre class="python"><code>tit_train[&#39;Pclass&#39;] = pclass_new</code></pre>
<p>Now see the Cabin variable. It appears that each Cabin is in a general section of the ship indicated by the capital letter at the start of each factor level</p>
<pre class="python"><code>tit_train[&#39;Cabin&#39;].unique()</code></pre>
<pre><code>## array([nan, &#39;C85&#39;, &#39;C123&#39;, &#39;E46&#39;, &#39;G6&#39;, &#39;C103&#39;, &#39;D56&#39;, &#39;A6&#39;,
##        &#39;C23 C25 C27&#39;, &#39;B78&#39;, &#39;D33&#39;, &#39;B30&#39;, &#39;C52&#39;, &#39;B28&#39;, &#39;C83&#39;, &#39;F33&#39;,
##        &#39;F G73&#39;, &#39;E31&#39;, &#39;A5&#39;, &#39;D10 D12&#39;, &#39;D26&#39;, &#39;C110&#39;, &#39;B58 B60&#39;, &#39;E101&#39;,
##        &#39;F E69&#39;, &#39;D47&#39;, &#39;B86&#39;, &#39;F2&#39;, &#39;C2&#39;, &#39;E33&#39;, &#39;B19&#39;, &#39;A7&#39;, &#39;C49&#39;, &#39;F4&#39;,
##        &#39;A32&#39;, &#39;B4&#39;, &#39;B80&#39;, &#39;A31&#39;, &#39;D36&#39;, &#39;D15&#39;, &#39;C93&#39;, &#39;C78&#39;, &#39;D35&#39;,
##        &#39;C87&#39;, &#39;B77&#39;, &#39;E67&#39;, &#39;B94&#39;, &#39;C125&#39;, &#39;C99&#39;, &#39;C118&#39;, &#39;D7&#39;, &#39;A19&#39;,
##        &#39;B49&#39;, &#39;D&#39;, &#39;C22 C26&#39;, &#39;C106&#39;, &#39;C65&#39;, &#39;E36&#39;, &#39;C54&#39;,
##        &#39;B57 B59 B63 B66&#39;, &#39;C7&#39;, &#39;E34&#39;, &#39;C32&#39;, &#39;B18&#39;, &#39;C124&#39;, &#39;C91&#39;, &#39;E40&#39;,
##        &#39;T&#39;, &#39;C128&#39;, &#39;D37&#39;, &#39;B35&#39;, &#39;E50&#39;, &#39;C82&#39;, &#39;B96 B98&#39;, &#39;E10&#39;, &#39;E44&#39;,
##        &#39;A34&#39;, &#39;C104&#39;, &#39;C111&#39;, &#39;C92&#39;, &#39;E38&#39;, &#39;D21&#39;, &#39;E12&#39;, &#39;E63&#39;, &#39;A14&#39;,
##        &#39;B37&#39;, &#39;C30&#39;, &#39;D20&#39;, &#39;B79&#39;, &#39;E25&#39;, &#39;D46&#39;, &#39;B73&#39;, &#39;C95&#39;, &#39;B38&#39;,
##        &#39;B39&#39;, &#39;B22&#39;, &#39;C86&#39;, &#39;C70&#39;, &#39;A16&#39;, &#39;C101&#39;, &#39;C68&#39;, &#39;A10&#39;, &#39;E68&#39;,
##        &#39;B41&#39;, &#39;A20&#39;, &#39;D19&#39;, &#39;D50&#39;, &#39;D9&#39;, &#39;A23&#39;, &#39;B50&#39;, &#39;A26&#39;, &#39;D48&#39;,
##        &#39;E58&#39;, &#39;C126&#39;, &#39;B71&#39;, &#39;B51 B53 B55&#39;, &#39;D49&#39;, &#39;B5&#39;, &#39;B20&#39;, &#39;F G63&#39;,
##        &#39;C62 C64&#39;, &#39;E24&#39;, &#39;C90&#39;, &#39;C45&#39;, &#39;E8&#39;, &#39;B101&#39;, &#39;D45&#39;, &#39;C46&#39;, &#39;D30&#39;,
##        &#39;E121&#39;, &#39;D11&#39;, &#39;E77&#39;, &#39;F38&#39;, &#39;B3&#39;, &#39;D6&#39;, &#39;B82 B84&#39;, &#39;D17&#39;, &#39;A36&#39;,
##        &#39;B102&#39;, &#39;B69&#39;, &#39;E49&#39;, &#39;C47&#39;, &#39;D28&#39;, &#39;E17&#39;, &#39;A24&#39;, &#39;C50&#39;, &#39;B42&#39;,
##        &#39;C148&#39;], dtype=object)</code></pre>
<p>If we grouped the cabin just by this letter, we could lesser the number of levels while getting some useful information.</p>
<pre class="python"><code>
chr_cabin = tit_train[&quot;Cabin&quot;].astype(str)

n_Cabin = np.array([cabin[0] for cabin in chr_cabin]) 

n_Cabin = pd.Categorical(n_Cabin)

n_Cabin.describe()</code></pre>
<pre><code>##             counts     freqs
## categories                  
## A               15  0.016835
## B               47  0.052750
## C               59  0.066218
## D               33  0.037037
## E               32  0.035915
## F               13  0.014590
## G                4  0.004489
## T                1  0.001122
## n              687  0.771044</code></pre>
<p>The output of describe() shows we can group Cabin into broader categories, but we also discovered something interesting: 688 of the records have Cabin are “n” which is shortened from “nan”. In other words, more than 2/3 of the passengers do not have a cabin.</p>
<p>A missing cabin variable could be an indication that a passenger died.</p>
<p>We can keep the new variable cabin</p>
<pre class="python"><code>tit_train[&quot;Cabin&quot;] = n_Cabin</code></pre>
</div>
<div id="checking-to-if-there-are-null-values-outliers-or-other-garbage-values" class="section level3">
<h3>Checking to if there are null Values, Outliers or Other garbage Values?</h3>
<p>To check the missing values we us <code>pd.isnull()</code> function for example</p>
<pre class="python"><code>
mock_vector = pd.Series([1,None,3,None,7,8])

mock_vector.isnull()</code></pre>
<pre><code>## 0    False
## 1     True
## 2    False
## 3     True
## 4    False
## 5    False
## dtype: bool</code></pre>
<p>If the missing values are numeric then they can be simple deleted. If missing values are categorical then they can be treated as additional category with value as NA.</p>
<p>To check if there is missing age values in titanic dataset</p>
<pre class="python"><code>tit_train[&quot;Age&quot;].describe()</code></pre>
<pre><code>## count    714.000000
## mean      29.699118
## std       14.526497
## min        0.420000
## 25%       20.125000
## 50%       28.000000
## 75%       38.000000
## max       80.000000
## Name: Age, dtype: float64</code></pre>
<p>We see that the count of age (712) is less than the total row count of dataset(889).
To check indexes of the missing ages we use <code>np.where()</code></p>
<pre class="python"><code>missvalues = np.where(tit_train[&quot;Age&quot;].isnull() == True)
missvalues</code></pre>
<pre><code>## (array([  5,  17,  19,  26,  28,  29,  31,  32,  36,  42,  45,  46,  47,
##         48,  55,  64,  65,  76,  77,  82,  87,  95, 101, 107, 109, 121,
##        126, 128, 140, 154, 158, 159, 166, 168, 176, 180, 181, 185, 186,
##        196, 198, 201, 214, 223, 229, 235, 240, 241, 250, 256, 260, 264,
##        270, 274, 277, 284, 295, 298, 300, 301, 303, 304, 306, 324, 330,
##        334, 335, 347, 351, 354, 358, 359, 364, 367, 368, 375, 384, 388,
##        409, 410, 411, 413, 415, 420, 425, 428, 431, 444, 451, 454, 457,
##        459, 464, 466, 468, 470, 475, 481, 485, 490, 495, 497, 502, 507,
##        511, 517, 522, 524, 527, 531, 533, 538, 547, 552, 557, 560, 563,
##        564, 568, 573, 578, 584, 589, 593, 596, 598, 601, 602, 611, 612,
##        613, 629, 633, 639, 643, 648, 650, 653, 656, 667, 669, 674, 680,
##        692, 697, 709, 711, 718, 727, 732, 738, 739, 740, 760, 766, 768,
##        773, 776, 778, 783, 790, 792, 793, 815, 825, 826, 828, 832, 837,
##        839, 846, 849, 859, 863, 868, 878, 888], dtype=int64),)</code></pre>
<pre class="python"><code>len(missvalues)</code></pre>
<pre><code>## 1</code></pre>
<p>Before we do anything with missing values its good to check the distribution of the missing values to know the central tendency of age.</p>
<pre class="python"><code>tit_train.hist(column=&#39;Age&#39;,    
                   figsize=(9,6),   
                   bins=20)         </code></pre>
<p><img src="/img/main/titdsage.png" /></p>
<p>The histogram shows that couple of passengers are near age 80.</p>
<p>To check the <code>fare</code> variable we create the box plot</p>
<pre class="python"><code>tit_train[&quot;Fare&quot;].plot(kind=&quot;box&quot;,
                           figsize=(9,9))</code></pre>
<p><img src="/img/main/titdsfare.png" /></p>
<p>50% of the data in the box plot represents the median. There are outliers in the data. There are passengers who paid double the amount than any other passenger. We can check this using <code>np.where()</code> function</p>
<pre class="python"><code>ind = np.where(tit_train[&quot;Fare&quot;] == max(tit_train[&quot;Fare&quot;]) )

tit_train.loc[ind]</code></pre>
<pre><code>##      Survived  Pclass  ... Cabin Embarked
## 258         1  class1  ...     n        C
## 679         1  class1  ...     B        C
## 737         1  class1  ...     B        C
## 
## [3 rows x 10 columns]</code></pre>
<p>Before modeling datasets using ML models it is better to address missing values, outliers, mislabeled data, bad data because they can corrupt the analysis and lead to wrong results.</p>
</div>
<div id="should-we-create-new-variables" class="section level3">
<h3>Should we Create New Variables?</h3>
<p>The decision to create new variables should be taken while preparing the data. The new variable could represent aggregate of existing variables, for example in titanic dataset we can create a new variable called <code>family</code> which stores the number of members in that family.</p>
<pre class="python"><code>tit_train[&quot;Family&quot;] = tit_train[&quot;SibSp&quot;] + tit_train[&quot;Parch&quot;]</code></pre>
<p>we can check who has most family members on the board</p>
<pre class="python"><code>mostfamily = np.where(tit_train[&quot;Family&quot;] == max(tit_train[&quot;Family&quot;]))

tit_train.loc[mostfamily]</code></pre>
<pre><code>##      Survived  Pclass                               Name  ... Cabin  Embarked  Family
## 159         0  class3         Sage, Master. Thomas Henry  ...     n         S      10
## 180         0  class3       Sage, Miss. Constance Gladys  ...     n         S      10
## 201         0  class3                Sage, Mr. Frederick  ...     n         S      10
## 324         0  class3           Sage, Mr. George John Jr  ...     n         S      10
## 792         0  class3            Sage, Miss. Stella Anna  ...     n         S      10
## 846         0  class3           Sage, Mr. Douglas Bullen  ...     n         S      10
## 863         0  class3  Sage, Miss. Dorothy Edith &quot;Dolly&quot;  ...     n         S      10
## 
## [7 rows x 11 columns]</code></pre>
</div>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>There are question that should be answered while investing any dataset. Once the basic questions are answered one can move further to find relationship between variables/features and build the machine learning models.</p>
</div>

    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/exploring-dataset/">Exploring Dataset</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/exploring-dataset/">Exploring Dataset</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    

  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="d5418e809e56039bb3c5626dc4ffde39">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/exploring-frequency-tables/" class="button left"><span>Understanding frequency tables</span></a>
    
    
      <a href="/blog/handling-numeric-data/" class="button right"><span>Handling numeric data</span></a>
    
  </div>
  

      </main>
      

<section id="site-sidebar">
 

  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/convolutional-neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/cnn-neural-network.jpg');">
    <img src="https://laxmikants.github.io/img/main/cnn-neural-network.jpg" alt="CNN Neural Networks">
  </a>
        <header>
          <h2><a href="/blog/convolutional-neural-networks/">Convolutional Neural Networks</a></h2>
          <time class="published" datetime="2021-01-03 00:00:00 &#43;0000 UTC">January 3, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/neural-network-using-make-moons-dataset/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg');">
    <img src="https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/neural-network-using-make-moons-dataset/">Neural Network using Make Moons dataset</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/single-layer-perceptron/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg');">
    <img src="https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/single-layer-perceptron/">Single Layer Perceptron</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      

      
    </section>
  

   

  
    
      <section id="categories">
        
   
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/convolutional-neural-networks/">convolutional-neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
      </section>
    
  



  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>about</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    © 2021 Data Science Posts and Resources
      <br>
  </p>
</footer>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.daca826145adfcf5004b4b16d74010eff217a0382fad56b874f5630927a20c4e.js" integrity="sha256-2sqCYUWt/PUAS0sW10AQ7/IXoDgvrVa4dPVjCSeiDE4="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
  
</html>
