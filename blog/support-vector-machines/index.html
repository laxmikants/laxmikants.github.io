<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
  <style>

    .nocopy {
      -webkit-user-select: none;   
      -moz-user-select: none;      
      -ms-user-select: none;       
      user-select: none;           
    }  

</style>

<script data-ad-client="ca-pub-3804322353139756" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script async src = "https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js',new Date());
 
 gtag('config','UA-155379268-1');

</script>  
  <meta charset="utf-8">
<title>Support Vector Machines - Data Science Posts and Resources | Laxmikant Soni</title>
<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name= "keywords" content="Predictive, Business, Data, Analytics, Machine Learning, Mining, Python, Intelligence, Big, Modeling, Data Science, Integration, Visualization">

<meta name="robots" content="index">

<meta name="description" content="Articles and Posts on Data Science, Machine Learning and Analytics">



<meta name="generator" content="Hugo 0.74.3" /><meta itemprop="name" content="Support Vector Machines">
<meta itemprop="description" content="In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.">
<meta itemprop="datePublished" content="2020-04-12T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-04-12T00:00:00+00:00" />
<meta itemprop="wordCount" content="932">



<meta itemprop="keywords" content="Support Vector Machines," />
<meta property="og:title" content="Support Vector Machines" />
<meta property="og:description" content="In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://laxmikants.github.io/blog/support-vector-machines/" />
<meta property="article:published_time" content="2020-04-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-04-12T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Support Vector Machines"/>
<meta name="twitter:description" content="In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis."/>
<meta name="twitter:site" content="@laxmikantsoni09"/>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
        <script src="https://kit.fontawesome.com/be54eb011a.js" crossorigin="anonymous"></script>
      <script async   src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="/css/main.min.1f17d6560afe48677306aa7452f1c061799e35dbd1cc697cb7d6d22eed0b6b9b.css" integrity="sha256-HxfWVgr&#43;SGdzBqp0UvHAYXmeNdvRzGl8t9bSLu0La5s="><link rel="stylesheet" href="/css/add-on.css">

<title>Support Vector Machines : Data Science Posts and Resources</title>

<meta property="og:title" content="Support Vector Machines">
<meta property="og:site_name" content="Data Science Posts and Resources">
<meta property="og:url" content="https://laxmikants.github.io/blog/support-vector-machines/">
<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:description" content="In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.">
<meta name="description" content="In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.">
<meta property="og:updated_time" content="2020-04-12T00:00:00Z">
<meta property="fb:app_id" content="428818034507005">
<meta name="author" content="Laxmikant Soni">
<meta property="article:author" content="https://laxmikants.github.io">
<meta property="article:published_time" content="2020-04-12T00:00:00Z">
<meta property="article:modified_time" content="2020-04-12T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Support Vector Machines",
  "alternativeHeadline": "Support Vector Machines",
  "url": "https://laxmikants.github.io/blog/support-vector-machines/",
  "image": "https://laxmikants.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://laxmikants.github.io/blog/support-vector-machines/"
  },
  "description": "In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.",
  "author": {
    "@type": "Person",
    "name": "Laxmikant Soni"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Science Posts and Resources",
    "logo": {
      "@type": "ImageObject",
      "url": "https://laxmikants.github.io/"
    }
  },
  "datePublished": "2020-04-12T00:00:00Z",
  "dateModified": "2020-04-12T00:00:00Z",
  "articleBody": "\r\n\u003cscript src=\"/rmarkdown-libs/header-attrs/header-attrs.js\"\u003e\u003c/script\u003e\r\n\u003clink href=\"/rmarkdown-libs/anchor-sections/anchor-sections.css\" rel=\"stylesheet\" /\u003e\r\n\u003cscript src=\"/rmarkdown-libs/anchor-sections/anchor-sections.js\"\u003e\u003c/script\u003e\r\n\r\n\r\n\u003cdiv id=\"support-vector-machines\" class=\"section level2\"\u003e\r\n\u003ch2\u003eSupport Vector Machines\u003c/h2\u003e\r\n\u003cp\u003eSupport Vector Machines are very powerful, very efficient machine learning algorithms and they even achieve much better results than neural networks in some areas. We are again dealing with classification here but the methodology is quite different.\u003c/p\u003e\r\n\u003cp\u003eWhat we are looking for is a hyperplane that distinctly classifies our data points and has the maximum margin to all of our points. We want our model to be as generalized as possible.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm1.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eIn the graph above the model is very general and the line is the optimal function to separate our data. We can use an endless amount of lines to separate the two classes but we don’t want to overfit our model so that it only works for the data we already have. We also want it to work for unknown data.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm2.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eHere our model also separates the data we already have perfectly. But we’ve got a new red data point here. When we just look at this with our intuition it is obvious that this point belongs to the orange triangles. However, our model classifies it as a blue circle because it is overfitting our current data.\r\nTo find our perfect line we are using so-called support vectors , which are parallel lines.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm3.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eWe are looking for the two points that are the farthest away from the other class. In between of those, we draw our hyperplane so that the distance to both points is the same and as large as possible. The two parallel lines are the support vectors. In between the orange and the blue line there are no data points. This is our margin. We want this margin to be as big as possible because it makes our predictions more reliable.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"kernels\" class=\"section level2\"\u003e\r\n\u003ch2\u003eKERNELS\u003c/h2\u003e\r\n\u003cp\u003eThe data we have looked at so far is relatively easy to classify because it is clearly separated. Such data can almost never be found in the real world. Also, we are oftentimes working in higher dimensions with many features. This makes things more complicated.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm4.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eData taken from the real world often looks like this in figure. Here it is impossible to draw a straight line, and even a quadratic or cubic function does not help us here. In such cases we can use so-called kernels . These add a new dimension to our data. By doing that, we hope to increase the complexity of the data and possibly use a hyperplane as a separator.\u003c/p\u003e\r\n\u003cp\u003eNotice that the kernel (a.k.a. the additional dimension) should be derived from the data that we already have. We are just making it more abstract. A kernel is not some random feature but a combination of the features we already have. But that wouldn’t be reasonable or helpful. Therefore, there are pre-defined and effective kernels that we can choose from.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"soft-margin\" class=\"section level2\"\u003e\r\n\u003ch2\u003eSOFT MARGIN\u003c/h2\u003e\r\n\u003cp\u003eSometimes, we will encounter statistical outliers in our data. It would be very easy to draw a hyperplane that separates the data into the classes, if it wasn’t for these outliers.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm5.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003en the figure above, you can see such a data set. We can see that almost all of the orange triangles are in the top first third, whereas almost all the blue dots are in the bottom two thirds. The problem here is with the outliers.\r\nNow instead of using a kernel or a polynomial function to solve this problem, we can define a so-called soft margin. With this, we allow for conscious misclassification of outliers in order to create a more accurate model. Caring too much about these outliers would again mean overfitting the model.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"/img/main/svm6.png\" /\u003e\r\nAs you can see, even though we are misclassifying two data points our model is very accurate.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"loading-data\" class=\"section level2\"\u003e\r\n\u003ch2\u003eLOADING DATA\u003c/h2\u003e\r\n\u003cp\u003eNow that we understand how SVMs work, let’s get into the coding. For this machine learning algorithm, we are going to once again use the breast cancer data set. We will need the following imports:\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003efrom sklearn.svm import SVC\r\nfrom sklearn.datasets import load_breast_cancer\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\nfrom sklearn.model_selection import train_test_split \u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eBesides the libraries we already know, we are importing the SVC module. This is the support vector classifier that we are going to use as our model. Notice that we are also importing the KNeighborsClassifier again, since we are going to compare the accuracies at the end.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003edata = load_breast_cancer()\r\nX = data.data\r\nY = data.target\r\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1 , random_state = 30 )\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eThis time we use a new parameter named random_state . It is a seed that always produces the exact same split of our data. Usually, the data gets split randomly every time we run the script. You can use whatever number you want here. Each number creates a certain split which doesn’t change no matter how many times we run the script. We do this in order to be able to objectively compare the different classifiers.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cdiv id=\"training-and-testing\" class=\"section level2\"\u003e\r\n\u003ch2\u003eTRAINING AND TESTING\u003c/h2\u003e\r\n\u003cp\u003eSo first we define our support vector classifier and start training it.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003emodel = SVC( kernel = \u0026#39;linear\u0026#39; , C = 3 )\r\nmodel.fit(X_train, Y_train)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## SVC(C=3, kernel=\u0026#39;linear\u0026#39;)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWe are using two parameters when creating an instance of the SVC class. The first one is our kernel and the second one is C which is our soft margin. Here we choose a linear kernel and allow for three misclassifications. Alternatively we could choose poly, rbf, sigmoid, precomputed or a self-defined kernel. Some are more effective in certain situations but also a lot more time-intensive than linear kernels.\u003c/p\u003e\r\n\u003cpre class=\"python\"\u003e\u003ccode\u003eaccuracy = model.score(X_test, Y_test)\r\nprint (accuracy)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e## 0.9649122807017544\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWhen we now score our model, we will see a very good result.\r\n0.9649122807017544\u003c/p\u003e\r\n\u003c/div\u003e"
}
</script>

  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>  
</head>

  <body>
    
      
    

<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
        
          
          <a href="/categories/" class="nav link"><i class='fas fa-sitemap'></i> Categories</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="nav lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu"></div></menu>
  <menu id="lang-menu" class="flyout-menu menu">
  <a href="#" lang="en" class="nav link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Support%20Vector%20Machines&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsupport-vector-machines%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fsupport-vector-machines%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  
  <header>
    <h1>Data Science Posts and Resources</h1>
  </header>
  <main>
    
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
    </footer>
  
</section>

      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/support-vector-machines/">Support Vector Machines</a></h2>
    
    
      <p>In machine learning, support-vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.</p>
    
  </div>
  <div class="meta">
    <time datetime="2020-04-12 00:00:00 &#43;0000 UTC">April 12, 2020</time>
    <p>Laxmi K Soni</p>
    <p>5-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Support%20Vector%20Machines&amp;url=https%3a%2f%2flaxmikants.github.io%2fblog%2fsupport-vector-machines%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fblog%2fsupport-vector-machines%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  


    </div>
    <div class="content">
      <a href="/blog/support-vector-machines/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/support_vector_machines-18.jpg');">
    <img src="https://laxmikants.github.io/img/main/support_vector_machines-18.jpg" alt="">
  </a>
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="support-vector-machines" class="section level2">
<h2>Support Vector Machines</h2>
<p>Support Vector Machines are very powerful, very efficient machine learning algorithms and they even achieve much better results than neural networks in some areas. We are again dealing with classification here but the methodology is quite different.</p>
<p>What we are looking for is a hyperplane that distinctly classifies our data points and has the maximum margin to all of our points. We want our model to be as generalized as possible.</p>
<p><img src="/img/main/svm1.png" /></p>
<p>In the graph above the model is very general and the line is the optimal function to separate our data. We can use an endless amount of lines to separate the two classes but we don’t want to overfit our model so that it only works for the data we already have. We also want it to work for unknown data.</p>
<p><img src="/img/main/svm2.png" /></p>
<p>Here our model also separates the data we already have perfectly. But we’ve got a new red data point here. When we just look at this with our intuition it is obvious that this point belongs to the orange triangles. However, our model classifies it as a blue circle because it is overfitting our current data.
To find our perfect line we are using so-called support vectors , which are parallel lines.</p>
<p><img src="/img/main/svm3.png" /></p>
<p>We are looking for the two points that are the farthest away from the other class. In between of those, we draw our hyperplane so that the distance to both points is the same and as large as possible. The two parallel lines are the support vectors. In between the orange and the blue line there are no data points. This is our margin. We want this margin to be as big as possible because it makes our predictions more reliable.</p>
</div>
<div id="kernels" class="section level2">
<h2>KERNELS</h2>
<p>The data we have looked at so far is relatively easy to classify because it is clearly separated. Such data can almost never be found in the real world. Also, we are oftentimes working in higher dimensions with many features. This makes things more complicated.</p>
<p><img src="/img/main/svm4.png" /></p>
<p>Data taken from the real world often looks like this in figure. Here it is impossible to draw a straight line, and even a quadratic or cubic function does not help us here. In such cases we can use so-called kernels . These add a new dimension to our data. By doing that, we hope to increase the complexity of the data and possibly use a hyperplane as a separator.</p>
<p>Notice that the kernel (a.k.a. the additional dimension) should be derived from the data that we already have. We are just making it more abstract. A kernel is not some random feature but a combination of the features we already have. But that wouldn’t be reasonable or helpful. Therefore, there are pre-defined and effective kernels that we can choose from.</p>
</div>
<div id="soft-margin" class="section level2">
<h2>SOFT MARGIN</h2>
<p>Sometimes, we will encounter statistical outliers in our data. It would be very easy to draw a hyperplane that separates the data into the classes, if it wasn’t for these outliers.</p>
<p><img src="/img/main/svm5.png" /></p>
<p>n the figure above, you can see such a data set. We can see that almost all of the orange triangles are in the top first third, whereas almost all the blue dots are in the bottom two thirds. The problem here is with the outliers.
Now instead of using a kernel or a polynomial function to solve this problem, we can define a so-called soft margin. With this, we allow for conscious misclassification of outliers in order to create a more accurate model. Caring too much about these outliers would again mean overfitting the model.</p>
<p><img src="/img/main/svm6.png" />
As you can see, even though we are misclassifying two data points our model is very accurate.</p>
</div>
<div id="loading-data" class="section level2">
<h2>LOADING DATA</h2>
<p>Now that we understand how SVMs work, let’s get into the coding. For this machine learning algorithm, we are going to once again use the breast cancer data set. We will need the following imports:</p>
<pre class="python"><code>from sklearn.svm import SVC
from sklearn.datasets import load_breast_cancer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split </code></pre>
<p>Besides the libraries we already know, we are importing the SVC module. This is the support vector classifier that we are going to use as our model. Notice that we are also importing the KNeighborsClassifier again, since we are going to compare the accuracies at the end.</p>
<pre class="python"><code>data = load_breast_cancer()
X = data.data
Y = data.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1 , random_state = 30 )</code></pre>
<p>This time we use a new parameter named random_state . It is a seed that always produces the exact same split of our data. Usually, the data gets split randomly every time we run the script. You can use whatever number you want here. Each number creates a certain split which doesn’t change no matter how many times we run the script. We do this in order to be able to objectively compare the different classifiers.</p>
</div>
<div id="training-and-testing" class="section level2">
<h2>TRAINING AND TESTING</h2>
<p>So first we define our support vector classifier and start training it.</p>
<pre class="python"><code>model = SVC( kernel = &#39;linear&#39; , C = 3 )
model.fit(X_train, Y_train)</code></pre>
<pre><code>## SVC(C=3, kernel=&#39;linear&#39;)</code></pre>
<p>We are using two parameters when creating an instance of the SVC class. The first one is our kernel and the second one is C which is our soft margin. Here we choose a linear kernel and allow for three misclassifications. Alternatively we could choose poly, rbf, sigmoid, precomputed or a self-defined kernel. Some are more effective in certain situations but also a lot more time-intensive than linear kernels.</p>
<pre class="python"><code>accuracy = model.score(X_test, Y_test)
print (accuracy)</code></pre>
<pre><code>## 0.9649122807017544</code></pre>
<p>When we now score our model, we will see a very good result.
0.9649122807017544</p>
</div>

    </div>
    <footer>
      <div class="stats">
  <ul class="categories">
    
      
        
          <li><a class="article-terms-link" href="/categories/support-vector-machines/">Support Vector Machines</a></li>
        
      
    
  </ul>
  <ul class="tags">
    
      
        
          <li><a class="article-terms-link" href="/tags/support-vector-machines/">Support Vector Machines</a></li>
        
      
    
  </ul>
</div>

    </footer>
  </article>
  
    


  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="018e98c5ee3b3b3f8f39680047bae15f">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2><p>Nothing yet.</p>
      
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/k-nearest-neighbours/" class="button left"><span>K nearest Neighbours</span></a>
    
    
      <a href="/blog/linear-regression/" class="button right"><span>Decision Trees</span></a>
    
  </div>

      </main>
      <section id="site-sidebar">
  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/neural-network-using-make-moons-dataset/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg');">
    <img src="https://laxmikants.github.io/img/main/nn_makemoons_dataset.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/neural-network-using-make-moons-dataset/">Neural Network using Make Moons dataset</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/single-layer-perceptron/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg');">
    <img src="https://laxmikants.github.io/img/main/Single_Layer_Perceptron.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/single-layer-perceptron/">Single Layer Perceptron</a></h2>
          <time class="published" datetime="2020-12-10 00:00:00 &#43;0000 UTC">December 10, 2020</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/neural-networks/" class="image" style="--bg-image: url('https://laxmikants.github.io/img/main/Neural-Networks-32.jpg');">
    <img src="https://laxmikants.github.io/img/main/Neural-Networks-32.jpg" alt="">
  </a>
        <header>
          <h2><a href="/blog/neural-networks/">Neural Networks</a></h2>
          <time class="published" datetime="2020-12-05 00:00:00 &#43;0000 UTC">December 5, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      
    </section>
  

  
    
      <section id="categories">
        <header>
          <h1><a href="/categories">categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/python/">python<span class="count">14</span></a>
          
          <li>
              <a href="/categories/linear-regression/">linear-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/logistic-regression/">logistic-regression<span class="count">2</span></a>
          
          <li>
              <a href="/categories/big-data/">big-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/bigdata/">bigdata<span class="count">1</span></a>
          
          <li>
              <a href="/categories/classification/">classification<span class="count">1</span></a>
          
          <li>
              <a href="/categories/clustering/">clustering<span class="count">1</span></a>
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">1</span></a>
          
          <li>
              <a href="/categories/decision-trees/">decision-trees<span class="count">1</span></a>
          
          <li>
              <a href="/categories/eda/">eda<span class="count">1</span></a>
          
          <li>
              <a href="/categories/exploring-dataset/">exploring-dataset<span class="count">1</span></a>
          
          <li>
              <a href="/categories/frequency-tables/">frequency-tables<span class="count">1</span></a>
          
          <li>
              <a href="/categories/hadoop/">hadoop<span class="count">1</span></a>
          
          <li>
              <a href="/categories/k-nearest-neighbours/">k-nearest-neighbours<span class="count">1</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">1</span></a>
          
          <li>
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-network/">neural-network<span class="count">1</span></a>
          
          <li>
              <a href="/categories/neural-networks/">neural-networks<span class="count">1</span></a>
          
          <li>
              <a href="/categories/numeric-data/">numeric-data<span class="count">1</span></a>
          
          <li>
              <a href="/categories/pandas/">pandas<span class="count">1</span></a>
          
          <li>
              <a href="/categories/react-native/">react-native<span class="count">1</span></a>
          
          <li>
              <a href="/categories/reactjs/">reactjs<span class="count">1</span></a>
          
          <li>
              <a href="/categories/single-layer-perceptron/">single-layer-perceptron<span class="count">1</span></a>
          
          <li>
              <a href="/categories/stock-market/">stock-market<span class="count">1</span></a>
          
          <li>
              <a href="/categories/support-vector-machines/">support-vector-machines<span class="count">1</span></a>
          
          <li>
              <a href="/categories/text-analytics/">text-analytics<span class="count">1</span></a>
          
          <li>
              <a href="/categories/time-series/">time-series<span class="count">1</span></a>
          
          <li>
              <a href="/categories/web-scrapping/">web-scrapping<span class="count">1</span></a>
          
          </li>
        </ul>
      </section>
    
  

  
</section>

      <footer id="site-footer">
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/laxmikants" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/laxmikantsoni09" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>




<li><a href="//facebook.com/laxmikantsoni09" target="_blank" rel="noopener" title="Facebook" class="fab fa-facebook"></a></li>










<li><a href="//twitter.com/laxmikantsoni09" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>













      </ul>
  
  <p class="copyright">
    © 2020 Data Science Posts and Resources
      <br>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="//code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.js"></script>
    <script src="//unpkg.com/lunr/lunr.js"></script><script src="/js/bundlecdn.min.f2add8c14b1f0b4ba32b812ada31b9a7ae32730960754ccf519f6d49f5da77a1.js" integrity="sha256-8q3YwUsfC0ujK4Eq2jG5p64ycwlgdUzPUZ9tSfXad6E="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-155379268-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
</html>
