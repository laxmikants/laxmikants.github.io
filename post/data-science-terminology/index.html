<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><script data-ad-client=ca-pub-3804322353139756 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-155379268-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-155379268-1');</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Data Science Terminology","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/laxmikants.github.io\/post\/data-science-terminology\/"},"image":{"@type":"ImageObject","url":"https:\/\/laxmikants.github.io\/img\/cover.png","width":800,"height":600},"genre":"post","keywords":"Data Science, Statistical Population, Probability, False Positives, Statistical Inference","wordcount":2437,"url":"https:\/\/laxmikants.github.io\/post\/data-science-terminology\/","datePublished":"2018-02-05","dateModified":"2018-02-05","license":"This work is licensed.","publisher":{"@type":"Organization","name":"Laxmi K Soni","logo":{"@type":"ImageObject","url":"https:\/\/laxmikants.github.io\/img\/laxmikant-soni-1.jpg","width":60,"height":60}},"author":{"@type":"Person","name":"Laxmi K Soni"},"description":"Data Science Terminology"}</script><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=keywords content="Posts and Resources on Data Science | Laxmikant Soni,Statistical population,Probability,False positives,Statistical inference,Regression,Fitting,Categorical data,Classification,Clustering,Statistical comparison,CodingDistributions,Data mining,Decision trees,Machine learning,Munging and wrangling,Visualization,D3,Regularization,Assessment,Cross-validation,Neural networks,Boosting,Lift,Mode,Outlier,Predictive modeling,Big data,Confidence interval,Python,R,Jupyter Notebook,Tensorflow,Javascript,ReactJS,NodeJS,Posts and Resources on Data Science,Data Science,Hadoop,Java,Spring,Hibernate,Struts,MySQL,Oracle,DB2,Websphere,Weblogic"><meta name=robots content=index><meta name=description content="Posts and Resources on Data Science | Laxmikant Soni"><title>Laxmikant Soni</title><meta property=og:title content="Posts and Resources on Data Science | Data Science Terminology"><meta property=fb:app_id content=428818034507005><meta name=description content="Data Science Terminology"><meta property=og:description content="Data Science Terminology"><meta name=author content="Laxmikant Soni"><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"@type":"Person","name":"Laxmi K Soni"},"headline":"Data Science Terminology","description":"Data Science Terminology","inLanguage":"en","wordCount":2437,"datePublished":"2018-02-05","dateModified":"2018-02-05","image":"https:\/\/laxmikants.github.io\/img\/cover.png","keywords":["Data Science, Statistical Population, Probability, False Positives, Statistical Inference"],"mainEntityOfPage":"https:\/\/laxmikants.github.io\/post\/data-science-terminology\/","publisher":{"@type":"Organization","name":"Laxmi K Soni","logo":{"@type":"ImageObject","url":"https:\/\/laxmikants.github.io\/img\/laxmikant-soni-1.jpg","height":60,"width":60}}}</script><link href=https://laxmikants.github.io/img/favicon.ico rel=icon type=image/x-icon><meta property=og:image content=https://laxmikants.github.io/img/laxmikant-soni-1.jpg><meta property=fb:app_id content=428818034507005><meta property=og:url content=https://laxmikants.github.io/post/data-science-terminology/><meta property=og:type content=article><meta property=og:site_name content="Laxmikant Soni"><meta property=og:description content="Data Science blog: Posts, Tutorials and resources for Data Science programming languages, frameworks, tools, etc."><meta property=og:locale content=en_IN><meta property=og:type content=article><meta content="Data Science Terminology" property=og:description><meta property=og:url content=https://laxmikants.github.io/post/data-science-terminology/><meta property=og:site_name content="Laxmikant Soni"><meta property=article:section content="Posts and Resources on Data Science | Laxmikant Soni"><meta property=article:section content="Statistical population"><meta property=article:section content=Probability><meta property=article:section content="False positives"><meta property=article:section content="Statistical inference"><meta property=article:section content=Regression><meta property=article:section content=Fitting><meta property=article:section content="Categorical data"><meta property=article:section content=Classification><meta property=article:section content=Clustering><meta property=article:section content="Statistical comparison"><meta property=article:section content=CodingDistributions><meta property=article:section content="Data mining"><meta property=article:section content="Decision trees"><meta property=article:section content="Machine learning"><meta property=article:section content="Munging and wrangling"><meta property=article:section content=Visualization><meta property=article:section content=D3><meta property=article:section content=Regularization><meta property=article:section content=Assessment><meta property=article:section content=Cross-validation><meta property=article:section content="Neural networks"><meta property=article:section content=Boosting><meta property=article:section content=Lift><meta property=article:section content=Mode><meta property=article:section content=Outlier><meta property=article:section content="Predictive modeling"><meta property=article:section content="Big data"><meta property=article:section content="Confidence interval"><meta property=article:section content=Python><meta property=article:section content=R><meta property=article:section content="Jupyter Notebook"><meta property=article:section content=Tensorflow><meta property=article:section content=Javascript><meta property=article:section content=ReactJS><meta property=article:section content=NodeJS><meta property=article:section content="Posts and Resources on Data Science"><meta property=article:section content="Data Science"><meta property=article:section content=Hadoop><meta property=article:section content=Java><meta property=article:section content=Spring><meta property=article:section content=Hibernate><meta property=article:section content=Struts><meta property=article:section content=MySQL><meta property=article:section content=Oracle><meta property=article:section content=DB2><meta property=article:section content=Websphere><meta property=article:section content=Weblogic><meta property=article:section content=AWS><meta property=article:published_time content="2018-02-05 00:00:00 &#43;0000 UTC"><meta name=twitter:site content=@laxmikantsoni09><meta name=twitter:creator content=@laxmikantsoni09><meta name=twitter:description content><meta name=twitter:title content="Data Science Terminology"><meta name=twitter:card content=summary_large_image><meta name=twitter:image content><meta name=generator content="Hugo 0.55.6"><link rel=alternate href=https://laxmikants.github.io/index.xml type=application/rss+xml title="Laxmikant Soni"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://laxmikants.github.io/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://laxmikants.github.io/css/highlight.min.css><link rel=stylesheet href=https://laxmikants.github.io/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous><script src=https://yihui.org/js/math-code.js></script><script async src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-155379268-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><span itemscope itemtype=https://schema.org/Organization><link itemprop=url href=http://laxmikants.github.io><a itemprop=sameAs href=http://www.facebook.com/laxmikantsoni09>FB</a>
<a itemprop=sameAs href=http://www.twitter.com/laxmikantsoni09>Twitter</a></span><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=https://laxmikants.github.io>Laxmikant Soni</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li class=navlinks-container><a class=navlinks-parent>About</a><div class=navlinks-children><a href=https://laxmikants.github.io/page/aboutme>About Me</a>
<a href=https://laxmikants.github.io/page/consulting>Consulting</a></div></li><li class=navlinks-container><a class=navlinks-parent>Data Science Resources</a><div class=navlinks-children><a href=https://laxmikants.github.io/page/ds-resources>Data Science Links</a></div></li><li class=navlinks-container><a class=navlinks-parent>Posts</a><div class=navlinks-children><a href=https://laxmikants.github.io/post/regression-in-ml/>Regression</a>
<a href=https://laxmikants.github.io/post/up-and-running-with-blogdown/>Blogdown</a>
<a href=https://laxmikants.github.io/post/authoring-scientific-paper/>Scientific paper</a></div></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title="Laxmikant Soni" href=https://laxmikants.github.io><img class=avatar-img src=https://laxmikants.github.io/img/laxmikant-soni-1.jpg alt="Laxmikant Soni"></a></div></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Data Science Terminology</h1><h2 class=post-subheading>Data Science Terminology</h2><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on February 5, 2018
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;12&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;2437&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Laxmi K Soni</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><div id=data-science-terminology class="section level2"><h2>Data Science Terminology</h2><p>Based upon personal experience, research, and various industry experts’ advice, someone delving
into the art of data science should take every opportunity to understand and gain experience as well as proficiency with the following list of common data science terms:</p><div id=statistical-population class="section level3"><h3>Statistical population</h3><p>Statistical population as a recordset (or a set of records). This set or group of records will be of similar items or events that are of interest to the data scientist for some experiment.</p><p>If a sample of a population is chosen accurately, characteristics of the entire population (that the sample is drawn from) can be estimated from the corresponding characteristics of the sample.</p></div><div id=probability class="section level3"><h3>Probability</h3><p>This is possible upcoming events and the likelihood of them actually occurring.
This compares to a statistical thought process that involves analyzing the
frequency of past events in an attempt to explain or make sense of the observations.</p><p>In addition, the data scientist will associate various individual events, studying the relationship of these events. How these different events relate to each other governs the methods and rules that will need to be followed when we’re studying their probabilities.</p></div><div id=false-positives class="section level3"><h3>False Positives</h3><p>The idea of false positives is a very important statistical (data science) concept. A false positive is a mistake or an errored result. That is, it is a scenario where the results of a process or experiment indicate a fulfilled or true condition when, in fact, the condition is not true (not fulfilled). This situation is also referred to by some data scientists as a false alarm and is most easily understood by considering the idea of a recordset or statistical population that is determined not only by the accuracy of the processing but by the characteristics of the sampled population. In other words, the data scientist has made errors during the statistical process, or the recordset is a population that does not have an appropriate sample (or characteristics) for what is being investigated. The idea of false positives closely relates to confusion matrix.</p><blockquote><p>sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)</p></blockquote></div><div id=statistical-inference class="section level3"><h3>Statistical Inference</h3><p>Given a sample from a population, Statistical inference makes estimates about population characteristics. This can be either point estimate or interval estimate.
It includes testing various hypotheses and deriving estimates.</p><blockquote><p>statsmodels in a python library for difference statistical models</p></blockquote></div><div id=regression class="section level3"><h3>Regression</h3><p>Regression is a process or method (selected by the data scientist as the best fit technique for the experiment at hand) used for determining the relationships among variables.</p><p>More precisely, regression is the process that helps the data scientist comprehend how the typical value of the dependent variable (or criterion variable) changes when any one or more of the independent variables is varied while the other independent variables are held fixed</p></div><div id=fitting class="section level3"><h3>Fitting</h3><p>Fitting is the process of measuring how well a statistical model or process describes a data scientist’s observations pertaining to a recordset or experiment. These measures will attempt to point out the discrepancy between observed values and probable values. The probable values of a model or process are known as a distribution or a probability distribution. Therefore, a probability distribution fitting (or distribution fitting) is when the data scientist fits a
probability distribution to a series of data concerning the repeated measurement of a variable phenomenon.</p><p>The object of a data scientist performing a distribution fitting is to predict the probability or to forecast the frequency of, the occurrence of the phenomenon at a certain interval.</p></div><div id=categorical-data class="section level3"><h3>Categorical data</h3><p>Categorical variables are measured on nominal or ordinal measurement scales, In many ways qualitative variables are similar to categorical variables as both use either nominal or ordinal measurement scales.</p><p>Sometimes an observer may decide to record his/her observation using categories.
The type and number of categories depend upon the type of interaction and the observer’s choice about how to classify the observation. For example, passive/active (two categories); introvert/extrovert (two categories); always/sometimes/never (three categories); strongly agree/agree/uncertain/disagree/strongly disagree (five categories).</p><blockquote><p>Categorical data is displayed graphically by bar charts and pie charts.</p></blockquote><blockquote><p>Categorical data can take numerical values, but those numbers don’t have any mathematical meaning.</p></blockquote><blockquote><p>Chi-square test of goodness of fit can be applied to categorical variables</p></blockquote></div><div id=classification class="section level3"><h3>Classification</h3><p>Statistical classification of data is the process of identifying which category (discussed in the previous section) a data point, observation, or variable should be grouped into. The data science process that carries out a classification process is known as a classifier. Determining whether a book is fiction or non-fiction is a simple example
classification. An analysis of data about restaurants might lead to the classification of them among several genres.</p><p>Classification is a very broad (and very popular) category of supervised learning algorithms,with the goal of trying to identify a data point as belonging to some classification (spam or ham; male or female; animal, mineral or vegetable, and so on).
A multitude of algorithms for classification exists, including:</p><ul><li>k-nearest neighbor</li><li>Logistic regression</li><li>Naive Bayes classifier</li><li>Support Vector Machines</li><li>neural networks</li><li>Decision trees</li><li>Random forests</li></ul><blockquote><p>Accuracy metric is not a good idea for imbalanced class problems.</p></blockquote><blockquote><p>Precision and recall metrics are good for imbalanced class problems.</p></blockquote><blockquote><p>Linear Classifiers: Logistic Regression, Naive Bayes Classifier, Nearest Neighbor, Support Vector Machines,Decision Trees,Boosted Trees,Random Forest,Neural Networks</p></blockquote></div><div id=clustering class="section level3"><h3>Clustering</h3><p>Clustering is the process of dividing up the data occurrences into groups or homogeneous subsets of the dataset, not a predetermined set of groups as in classification but groups identified by the execution of the data science process based upon similarities that it found among the occurrences.</p><p>Objects in the same group (a group is also referred to as a cluster) are found to be more analogous (in some sense or another) to each other than to those objects found in other groups (or found in other clusters). The process of clustering is found to be very common in exploratory data mining and is also a common technique for statistical data analysis</p><p>There are two standard clustering strategies: partitioning methods and hierarchical clustering. K-means clustering is well-known and commonly used partitioning algorithm.</p><p>Cluster analysis is popular in many fields:</p><blockquote><p>If you want to invest in housing market, you can use clustering for identifying groups of houses according to their type, value and location.</p></blockquote><blockquote><p>In cancer research for classifying patients into subgroups according their gene expression profile. This can be useful for identifying the molecular profile of patients with good or bad prognostic, as well as for understanding the disease.</p></blockquote><blockquote><p>In marketing for market segmentation by identifying subgroups of customers with similar profiles and who might be receptive to a particular form of advertising.</p></blockquote></div><div id=statistical-comparison class="section level3"><h3>Statistical comparison</h3><p>A process of analysis to view the similarities or variances of two or more groups
or populations (or recordsets).</p><p>In statistics (data science), this process of comparing is a statistical technique to compare populations or recordsets.</p><p>The four major ways of comparing means from data that is assumed to be normally distributed are:</p><ol style=list-style-type:decimal><li><p>Independent Samples T-Test. Use the independent samples t-test when you want to compare means for two data sets that are independent from each other.</p></li><li><p>One sample T-Test. Choose this when you want to compare means between one data set and a specified constant (like the mean from a hypothetical normal distribution).</p></li><li><p>Paired Samples T-Test. Use this test if you have one group tested at two different times. In other words, you have two measurements on the same item, person, or thing.The groups are “paired” because there intrinsic connections between them (i.e. they are not independent). This comparison of means is often used for groups of patients before treatment and after treatment, or for students tested before remediation and after remediation.</p></li><li><p>One way Analysis of Variance (ANOVA). Although not really a test for comparison of means, ANOVA is the main option when you have more than two levels of independent variable. For example, if your independent variable was “brand of coffee” your levels might be Starbucks, Peets and Trader Joe’s. Use this test when you have a group of individuals randomly split into smaller groups and completing different tasks (like drinking different coffee).</p></li></ol><p>If you have non-normal data (or if you don’t know what distribution your data comes from), you can’t use any of the above tests for comparison of means. You must use a non-parametric test (non-parametric basically means that you don’t know the distributions’s parameters) for ex. Mann-Whitney U test and Wilcoxon Signed Rank</p></div><div id=coding class="section level3"><h3>Coding</h3><p>Coding or statistical coding is again a process that a data scientist will use to prepare data for analysis. In this process, both quantitative data values (such as income or years of education) and qualitative data (such as race or gender) are categorized or coded in a consistent way.</p><p>Coding is performed by a data scientist for various reasons such as follows:</p><ul><li><p>More effective for running statistical models</p></li><li><p>Computers understand the variables</p></li><li><p>Accountability–so the data scientist can run models blind, or without knowing what variables stand for, to reduce programming bias</p></li></ul></div><div id=distributions class="section level3"><h3>Distributions</h3><p>The distribution of a statistical recordset (or of a population) is a visualization showing all the possible values (or sometimes referred to as intervals) of the data and how often they occur. When a distribution of categorical data is created by a data scientist, it attempts to show the number or percentage of individuals in each group or category.</p><p>It is a visualization showing the probability of occurrence of different possible outcomes in an experiment.</p><p>Types of Distributions:</p><ol style=list-style-type:decimal><li>Bernoulli Distribution</li><li>Uniform Distribution</li><li>Binomial Distribution</li><li>Normal Distribution</li><li>Poisson Distribution</li><li>Exponential Distribution</li></ol></div><div id=data-mining class="section level3"><h3>Data mining</h3><p>Data minin, usually concerned with data relationships (or the potential relationships between points of data,
sometimes referred to as variables) and cognitive analysis.</p><p>To further define this term, we can mention that data mining is sometimes more simply referred to as
knowledge discovery or even just discovery, based upon processing through or analyzing data from
new or different viewpoints and summarizing it into valuable insights that can be used to increase
revenue, cuts costs, or both.</p><p>Using software dedicated to data mining is just one of several analytical approaches to data mining.
Although there are tools dedicated to this purpose (such as IBM Cognos BI and Planning Analytics,
Tableau, SAS, and so on.), data mining is all about the analysis process finding correlations or
patterns among dozens of fields in the data and that can be effectively accomplished using tools such
as MS Excel or any number of open source technologies.</p></div><div id=decision-trees class="section level3"><h3>Decision trees</h3><p>A statistical decision tree uses a diagram that looks like a tree. This structure attempts to represent
optional decision paths and a predicted outcome for each path selected. A data scientist will use a
decision tree to support, track, and model decision making and their possible consequences, including
chance event outcomes, resource costs, and utility. It is a common way to display the logic of a data
science process.</p></div><div id=machine-learning class="section level3"><h3>Machine learning</h3><p>Machine learning is one of the most intriguing and exciting areas of data science. It conjures all forms
of images around artificial intelligence which includes Neural Networks, Support Vector Machines
(SVMs), and so on.Fundamentally, we can describe the term machine learning as a method of training a computer to make
or improve predictions or behaviors based on data or, specifically, relationships within that data.
Continuing, machine learning is a process by which predictions are made based upon recognized
patterns identified within data, and additionally, it is the ability to continuously learn from the data’s
patterns, therefore continuingly making better predictions.</p><p>It is not uncommon for someone to mistake the process of machine learning for data mining, but data
mining focuses more on exploratory data analysis and is known as unsupervised learning.</p><p>Machine learning can be used to learn and establish baseline behavioral profiles for various entities
and then to find meaningful anomalies. Here is the exciting part: the process of machine learning (using data relationships to make
predictions) is known as predictive analytics.</p><p>Predictive analytics allow the data scientists to produce reliable, repeatable decisions and results
and uncover hidden insights through learning from historical relationships and trends in the data.</p></div><div id=munging-and-wrangling class="section level3"><h3>Munging and wrangling</h3><p>The terms munging and wrangling are buzzwords or jargon meant to describe one’s efforts to affect
the format of data, recordset, or file in some way in an effort to prepare the data for continued or
otherwise processing and/or evaluations.</p></div><div id=dimensionality-reduction class="section level3"><h3>Dimensionality reduction</h3><p>Dimensionality reduction is a family of techniques whose purpose is to convert data with a high number of dimensions into data with a lower number of dimensions. Used as a general term, this can mean either discarding dimensions entirely (such as feature selection), or to
create new individual dimensions that simultaneously represent multiple original dimensions,with some loss of resolution (such as feature extraction). Some algorithms that can be used for dimensionality reduction include:</p><ul><li>Various types of regressions</li><li>PCA</li><li>Image transformations (for example, converting an image to grayscale)</li><li>Stemming and lemmatization (in natural language processing)</li></ul></div><div id=optimization class="section level3"><h3>Optimization</h3><p>Optimization algorithms have the goal of selecting a set of parameters, or the values for a set of parameters, such that the cost or error of a system is minimized (alternatively, such that the reward of a system is maximized). Feature selection and feature extraction is actually a form of optimization; you are modifying parameters with the purpose of reducing dimensionality while preserving important data. In the most basic optimization technique, a brute-force search, you simply try every possible combination of parameters and select the
combination with the best results. In practice, most problems are complex enough that a brute-force search may take an unreasonable amount of time (that is, millions of years on a modern computer). Some optimization techniques include:</p><ul><li>A brute force search (also known as an exhaustive search)</li><li>Gradient descent</li><li>Simulated annealing</li><li>Genetic algorithms</li></ul></div><div id=natural-language-processing class="section level3"><h3>Natural language processing</h3><p>Natural language processing (NLP) is an entire field on its own and contains many techniques that are not considered in machine learning. However, NLP is often used in concert with ML algorithms, as the two fields combined are necessary to achieve generalized
artificial intelligence. Many ML classification algorithms operate on text rather than numbers (such as our spam filter), and in those situations, we rely on techniques from the field of NLP:stemming, in particular, is a quick and easy dimensionality reduction technique for text classifiers. Some NLP techniques relevant to ML include:</p><ul><li>Tokenization</li><li>String distance</li><li>Stemming or lemmatization</li><li>TF-IDF</li></ul></div><div id=image-processing class="section level3"><h3>Image processing</h3><p>Like NLP, image processing is its own field of study that has overlapped with ML but is not fully encompassed by ML. As with NLP, we may often use image processing techniques to reduce dimensionality before applying an ML algorithm to an image. Some image processing
techniques relevant to machine learning include:</p><ul><li>Edge detection</li><li>Scale invariant transformations</li><li>Color space transformations</li><li>Object detection</li><li>Recurrent neural networks</li></ul></div></div><div class=blog-tags><a href=https://laxmikants.github.io/tags/data-science/>Data Science</a>&nbsp;
<a href=https://laxmikants.github.io/tags/statistical-population/>Statistical Population</a>&nbsp;
<a href=https://laxmikants.github.io/tags/probability/>Probability</a>&nbsp;
<a href=https://laxmikants.github.io/tags/false-positives/>False Positives</a>&nbsp;
<a href=https://laxmikants.github.io/tags/statistical-inference/>Statistical Inference</a>&nbsp;</div><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f&amp;text=Data%20Science%20Terminology&amp;via=" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f&amp;title=Data%20Science%20Terminology" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f&amp;title=Data%20Science%20Terminology" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f&amp;title=Data%20Science%20Terminology" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2flaxmikants.github.io%2fpost%2fdata-science-terminology%2f&amp;description=Data%20Science%20Terminology" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section></article><ul class="pager blog-pager"><li class=previous><a href=https://laxmikants.github.io/post/up-and-running-with-blogdown/ data-toggle=tooltip data-placement=top title="Websites with blogdown">&larr; Previous Post</a></li><li class=next><a href=https://laxmikants.github.io/post/regression-in-ml/ data-toggle=tooltip data-placement=top title="Regression in ML">Next Post &rarr;</a></li></ul><div class=disqus-comments><button id=show-comments class="btn btn-default" type=button>Show <span class=disqus-comment-count data-disqus-url=https://laxmikants.github.io/post/data-science-terminology>comments</span></button><div id=disqus_thread></div><script type=text/javascript>var disqus_config=function(){this.page.url='https:\/\/laxmikants.github.io\/post\/data-science-terminology';};</script></div></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">&nbsp;&bull;&nbsp;</p><p class="credits theme-by text-muted"><a href=http://gohugo.io>Hugo v0.55.6</a> powered &nbsp;&bull;&nbsp; Theme by <a href=http://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a> adapted to <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script><script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script src=https://laxmikants.github.io/js/main.js></script><script src=https://laxmikants.github.io/js/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0");});</script><script>renderMathInElement(document.body);</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://laxmikants.github.io/js/load-photoswipe.js></script><script type=text/javascript>$(function(){$('#show-comments').on('click',function(){var disqus_shortname='lsoni';(function(){var disqus=document.createElement('script');disqus.type='text/javascript';disqus.async=true;disqus.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(disqus);})();$(this).hide();});});</script><script id=dsq-count-scr src=//lsoni.disqus.com/count.js async></script></body></html>